{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Researcher Name Extraction Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset statistics:\n",
    "\n",
    "| Data file  | Documents | Sentences | Tokens | Names |\n",
    "|------------|-----------|-----------|--------|-------|\n",
    "| Training   | 80        | 24728     | 110269 | 5822  |\n",
    "| Validation | 35        | 8743      | 36757  | 1788  |\n",
    "| Test       | 35        | 10399     | 44795  | 2723  |\n",
    "| Total      | 145       | 43870     | 191821 | 10333 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "sys.path.insert(1, os.path.realpath(os.path.pardir))\n",
    "\n",
    "from optparse import OptionParser\n",
    "from pathlib import Path\n",
    "from model.hmm import HiddenMarkov, load_dataset\n",
    "\n",
    "start_time = time.time()\n",
    "for name in ['train', 'valid', 'test']:\n",
    "    _, Y, T = load_dataset('../data/ner_on_html/' + name)\n",
    "    t = [[['O', 'B-PER', 'I-PER'][t__] for t__ in t_] for t_ in Y]\n",
    "    p = [[['O', 'B-PER', 'I-PER'][p__] for p__ in p_] for p_ in Y]\n",
    "    w = T\n",
    "    \n",
    "    with Path('../results/score/{}.preds.txt'.format(name)).open('wb') as f:\n",
    "        for words, preds, tags in zip(w, p, t):\n",
    "            f.write(b'\\n')\n",
    "            for word, pred, tag in zip(words, preds, tags):\n",
    "                f.write(' '.join([word, tag, pred]).encode() + b'\\n')\n",
    "\n",
    "!cd .. && ./eval.sh | grep processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "def plot_word_frequency(directory, color):\n",
    "    my_counter = Counter()\n",
    "    for fname in ['train', 'valid', 'test']:\n",
    "        with open(directory + '/' + fname) as f:\n",
    "            words = [line.strip().lower().split()[0] for line in f if len(line.strip()) > 0]\n",
    "            words = [w for w in words if w != '-docstart-']\n",
    "            my_counter.update(words)\n",
    "\n",
    "    data = [(key, my_counter[key]) for key in my_counter]    \n",
    "    data.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print([(i, x[1]) for i, x in enumerate(data)][:100])\n",
    "    plt.plot([x[1] for x in data][:100], color)\n",
    "    return data[:50]\n",
    "    \n",
    "plt.title('Word frequencies')\n",
    "data1 = plot_word_frequency('../data/conll2003', 'r')\n",
    "data2 = plot_word_frequency('../data/ner_on_html', 'b')\n",
    "\n",
    "print(' '.join([d[0] for d in data1[:10]]))\n",
    "print()\n",
    "print(' '.join([d[0] for d in data2[:10]]))\n",
    "\n",
    "for d1, d2 in zip(data1, data2):\n",
    "    print('%s & %d & %s & %d' % (d1[0], d1[1], d2[0], d2[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dython import nominal\n",
    "\n",
    "def load_raw_dataset(f):\n",
    "    with open(f, 'r', encoding='utf8') as f:\n",
    "        data = f.read().strip()\n",
    "        sentences = [s.split('\\n') for s in data.split('\\n\\n') if not s.startswith('-DOCSTART-')]\n",
    "        X = [t.split(' ') for s in sentences for t in s if len(s) > 0]\n",
    "        for i, s in enumerate(X):\n",
    "            X[i] = X[i][2:5] + X[i][7:]\n",
    "        return X\n",
    "\n",
    "X = load_raw_dataset('../data/ner_on_html/train')\n",
    "X += load_raw_dataset('../data/ner_on_html/valid')\n",
    "X += load_raw_dataset('../data/ner_on_html/test')\n",
    "\n",
    "data = {}\n",
    "data['words']         = [x[0 ] for x in X]\n",
    "data['exact_match']   = [int(x[1]) for x in X]\n",
    "data['partial_match'] = [int(x[2]) for x in X]\n",
    "data['email']         = [int(x[3]) for x in X]\n",
    "data['number']        = [int(x[4]) for x in X]\n",
    "data['honorific']     = [int(x[5]) for x in X] \n",
    "data['url']           = [int(x[6]) for x in X]\n",
    "data['capitalized']   = [int(x[7]) for x in X]\n",
    "data['punctuation']   = [int(x[8]) for x in X]\n",
    "data['html_tag']      = [x[9 ] for x in X]\n",
    "data['css_class']     = [x[10] for x in X]\n",
    "\n",
    "data['words'][0]\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "nominal.associations(df, nominal_columns=['words','html_tag', 'css_class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it: https://github.com/shakedzy/dython/issues/2\n",
    "\n",
    "Calculates Cramer's V statistic for categorical-categorical association.\n",
    "Uses correction from Bergsma and Wicher, Journal of the Korean Statistical Society 42 (2013): 323-328.\n",
    "This is a symmetric coefficient: V(x,y) = V(y,x)\n",
    "\n",
    "https://github.com/shakedzy/dython/blob/master/dython/nominal.py\n",
    "https://en.wikipedia.org/wiki/Cram%C3%A9r%27s_V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested cross-validation\n",
    "\n",
    "5-fold cross validation\n",
    "\n",
    "\n",
    "Partition the training data randomly in five folds\n",
    "\n",
    "Nested CV\n",
    "https://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html\n",
    "\n",
    "Common error with cross validation\n",
    "https://www.youtube.com/watch?v=S06JpVoNaA0\n",
    "\n",
    "https://www.kdnuggets.com/2017/08/dataiku-predictive-model-holdout-cross-validation.html\n",
    "\n",
    "https://www.datarobot.com/wiki/training-validation-holdout/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is split into 3 different files: train, valid, and test. Also, we provide 11 features alongside each token.\n",
    "\n",
    "| Feature                          | Type        |\n",
    "|----------------------------------|-------------|\n",
    "| Unaccented lowercase token       | Categorical |\n",
    "| Exact dictionary match           | Binary      |\n",
    "| Partial dictionary match         | Binary      |\n",
    "| Email                            | Binary      |\n",
    "| Number                           | Binary      |\n",
    "| Honorific (Mr., Mrs., Dr., etc.) | Binary      |\n",
    "| Matches a URL                    | Binary      |\n",
    "| Is capitalized                   | Binary      |\n",
    "| Is a punctuation sign            | Binary      |\n",
    "| HTML tag + parent                | Categorical |\n",
    "| CSS class                        | Categorical |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden Markov Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "sys.path.insert(1, os.path.realpath(os.path.pardir))\n",
    "\n",
    "from optparse import OptionParser\n",
    "from pathlib import Path\n",
    "from model.hmm import HiddenMarkov, load_dataset\n",
    "\n",
    "def test_hmm(timesteps, use_features, dataset):\n",
    "    start_time = time.time()\n",
    "    naive_bayes = timesteps == 0\n",
    "    if naive_bayes:\n",
    "        timesteps = 1\n",
    "        \n",
    "    print('Fitting...')\n",
    "    X1, Y1, T1 = load_dataset(dataset + '/train')\n",
    "    X2, Y2, T2 = load_dataset(dataset + '/valid')\n",
    "    X3, Y3, T3 = load_dataset(dataset + '/test')    \n",
    "    training_set = [x for x in zip(X1 + X2 + X3, Y1 + Y2 + Y3, T1 + T2 + T3)]\n",
    "\n",
    "    random.shuffle(training_set)\n",
    "    fold_size = len(training_set) // 5\n",
    "    \n",
    "    folds = []\n",
    "    for i in range(5):\n",
    "        start = i * fold_size\n",
    "        end = start + fold_size if (i < 4) else len(training_set)\n",
    "        folds.append(training_set[start:end])\n",
    "    print('Fold size:', fold_size)\n",
    "    \n",
    "    for i in range(5):\n",
    "        train = []        \n",
    "        for j in range(5):        \n",
    "            if i != j:\n",
    "                train = train + folds[j]\n",
    "                \n",
    "        map(list, zip(*train))\n",
    "        train_X, train_Y, train_T = [list(t) for t in zip(*train)]\n",
    "        \n",
    "        map(list, zip(*folds[i]))\n",
    "        test_X, test_Y, test_T = [list(t) for t in zip(*folds[i])]\n",
    "        \n",
    "        hmm = HiddenMarkov(timesteps, naive_bayes=naive_bayes, use_features=use_features, self_train=False)\n",
    "        hmm.fit(train_X, train_Y)\n",
    "\n",
    "        t = test_Y\n",
    "        p = hmm.predict(test_X)\n",
    "\n",
    "        t = [[['O', 'B-PER', 'I-PER'][t__] for t__ in t_] for t_ in t]\n",
    "        p = [[['O', 'B-PER', 'I-PER'][p__] for p__ in p_] for p_ in p]\n",
    "        w = test_T\n",
    "\n",
    "        name = 'fold_' + str(i)\n",
    "        print('Writing', name)\n",
    "        with Path('../results/score/{}.preds.txt'.format(name)).open('wb') as f:\n",
    "            for words, preds, tags in zip(w, p, t):\n",
    "                f.write(b'\\n')\n",
    "                for word, pred, tag in zip(words, preds, tags):\n",
    "                    f.write(' '.join([word, tag, pred]).encode() + b'\\n')\n",
    "\n",
    "    print('Elapsed time: %.4f' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_hmm(0, False, '../data/ner_on_html')\n",
    "\n",
    "!cd .. && ./eval_model.sh\n",
    "!mkdir -p ../results/cross_validation/nb\n",
    "!mv ../results/score/fold* ../results/cross_validation/nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, os.path.realpath(os.path.pardir))\n",
    "\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from model.estimator import Estimator\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Disable debug logs Tensorflow.\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "estimator = Estimator()\n",
    "estimator.set_dataset_params({\n",
    "    'datadir': '../data/ner_on_html',\n",
    "    'dataset_mode': 'sentences'    \n",
    "})\n",
    "estimator.train_cv()\n",
    "# estimator.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM-CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold size: 29\n",
      "Loss: 0.1017, Acc: 1.0000, Time: 121.6090, Step: 1000\n",
      "Loss: 0.0378, Acc: 1.0000, Time: 238.9198, Step: 2000\n",
      "Loss: 0.0001, Acc: 1.0000, Time: 359.0481, Step: 3000\n",
      "Loss: 0.0098, Acc: 1.0000, Time: 423.8942, Step: 3553\n",
      "fold_0 - Epoch 0, Precision: 0.9042, Recall: 0.9230, F1: 0.9135\n",
      "Loss: 0.0124, Acc: 1.0000, Time: 63.2519, Step: 836\n",
      "fold_0 - Epoch 0, Precision: 0.9511, Recall: 0.8532, F1: 0.8995\n",
      "Loss: 0.0028, Acc: 1.0000, Time: 117.8207, Step: 1000\n",
      "Loss: 0.0052, Acc: 1.0000, Time: 238.0059, Step: 2000\n",
      "Loss: 0.0018, Acc: 1.0000, Time: 353.4686, Step: 3000\n",
      "Loss: 0.0083, Acc: 1.0000, Time: 415.8655, Step: 3553\n",
      "fold_0 - Epoch 1, Precision: 0.9519, Recall: 0.9579, F1: 0.9549\n",
      "Loss: 0.0044, Acc: 1.0000, Time: 62.0387, Step: 836\n",
      "fold_0 - Epoch 1, Precision: 0.9280, Recall: 0.8030, F1: 0.8610\n",
      "Loss: 0.0006, Acc: 1.0000, Time: 117.5116, Step: 1000\n",
      "Loss: 0.0777, Acc: 1.0000, Time: 236.7794, Step: 2000\n",
      "Loss: 0.0996, Acc: 0.9714, Time: 354.4473, Step: 3000\n",
      "Loss: 0.0013, Acc: 1.0000, Time: 418.6432, Step: 3553\n",
      "fold_0 - Epoch 2, Precision: 0.9612, Recall: 0.9678, F1: 0.9645\n",
      "Loss: 0.0058, Acc: 1.0000, Time: 61.9507, Step: 836\n",
      "fold_0 - Epoch 2, Precision: 0.8933, Recall: 0.8942, F1: 0.8938\n",
      "Loss: 0.0381, Acc: 1.0000, Time: 115.6291, Step: 1000\n",
      "Loss: 0.4179, Acc: 0.9750, Time: 237.7659, Step: 2000\n",
      "Loss: 0.0020, Acc: 1.0000, Time: 353.1593, Step: 3000\n",
      "Loss: 0.1245, Acc: 0.9957, Time: 415.8285, Step: 3553\n",
      "fold_0 - Epoch 3, Precision: 0.9683, Recall: 0.9735, F1: 0.9709\n",
      "Loss: 0.0012, Acc: 1.0000, Time: 62.0451, Step: 836\n",
      "fold_0 - Epoch 3, Precision: 0.9138, Recall: 0.8624, F1: 0.8874\n",
      "Loss: 0.0001, Acc: 1.0000, Time: 115.2234, Step: 1000\n",
      "Loss: 0.0011, Acc: 1.0000, Time: 236.6070, Step: 2000\n",
      "Loss: 0.0357, Acc: 1.0000, Time: 353.2468, Step: 3000\n",
      "Loss: 0.0025, Acc: 1.0000, Time: 416.6289, Step: 3553\n",
      "fold_0 - Epoch 4, Precision: 0.9743, Recall: 0.9783, F1: 0.9763\n",
      "Loss: 0.0008, Acc: 1.0000, Time: 62.0527, Step: 836\n",
      "fold_0 - Epoch 4, Precision: 0.9170, Recall: 0.8677, F1: 0.8917\n",
      "Writing fold_0\n",
      "Loss: 0.1917, Acc: 0.9955, Time: 136.1281, Step: 1000\n",
      "Loss: 0.0174, Acc: 1.0000, Time: 262.3505, Step: 2000\n",
      "Loss: 0.0085, Acc: 1.0000, Time: 380.6413, Step: 3000\n",
      "Loss: 0.0000, Acc: 1.0000, Time: 420.3787, Step: 3338\n",
      "fold_1 - Epoch 0, Precision: 0.8642, Recall: 0.9098, F1: 0.8864\n",
      "Loss: 0.0010, Acc: 1.0000, Time: 69.6541, Step: 1000\n",
      "Loss: 0.0077, Acc: 1.0000, Time: 73.7256, Step: 1052\n",
      "fold_1 - Epoch 0, Precision: 0.9393, Recall: 0.8990, F1: 0.9187\n",
      "Loss: 0.0175, Acc: 1.0000, Time: 132.3835, Step: 1000\n",
      "Loss: 0.0404, Acc: 1.0000, Time: 258.5432, Step: 2000\n",
      "Loss: 0.0984, Acc: 0.9941, Time: 378.4161, Step: 3000\n",
      "Loss: 0.0018, Acc: 1.0000, Time: 418.6742, Step: 3338\n",
      "fold_1 - Epoch 1, Precision: 0.9501, Recall: 0.9643, F1: 0.9572\n",
      "Loss: 0.0045, Acc: 1.0000, Time: 68.7687, Step: 1000\n",
      "Loss: 0.0017, Acc: 1.0000, Time: 72.7986, Step: 1052\n",
      "fold_1 - Epoch 1, Precision: 0.9046, Recall: 0.9268, F1: 0.9156\n",
      "Loss: 0.0161, Acc: 1.0000, Time: 132.1847, Step: 1000\n",
      "Loss: 0.0003, Acc: 1.0000, Time: 259.1748, Step: 2000\n",
      "Loss: 0.1104, Acc: 0.9976, Time: 379.0688, Step: 3000\n",
      "Loss: -0.0000, Acc: 1.0000, Time: 422.0104, Step: 3338\n",
      "fold_1 - Epoch 2, Precision: 0.9580, Recall: 0.9685, F1: 0.9632\n",
      "Loss: 0.0000, Acc: 1.0000, Time: 68.8422, Step: 1000\n",
      "Loss: 0.0038, Acc: 1.0000, Time: 72.8829, Step: 1052\n",
      "fold_1 - Epoch 2, Precision: 0.9031, Recall: 0.9023, F1: 0.9027\n",
      "Loss: 0.0347, Acc: 1.0000, Time: 132.8114, Step: 1000\n",
      "Loss: 0.0065, Acc: 1.0000, Time: 257.4727, Step: 2000\n",
      "Loss: 0.0117, Acc: 1.0000, Time: 378.9053, Step: 3000\n",
      "Loss: 0.0282, Acc: 1.0000, Time: 420.6923, Step: 3338\n",
      "fold_1 - Epoch 3, Precision: 0.9647, Recall: 0.9727, F1: 0.9687\n",
      "Loss: 0.0002, Acc: 1.0000, Time: 68.8260, Step: 1000\n",
      "Loss: 0.0012, Acc: 1.0000, Time: 72.8579, Step: 1052\n",
      "fold_1 - Epoch 3, Precision: 0.9357, Recall: 0.9212, F1: 0.9284\n",
      "Loss: 0.0358, Acc: 1.0000, Time: 133.0295, Step: 1000\n",
      "Loss: 0.0004, Acc: 1.0000, Time: 259.3329, Step: 2000\n",
      "Loss: 0.0009, Acc: 1.0000, Time: 378.4286, Step: 3000\n",
      "Loss: 0.0049, Acc: 1.0000, Time: 419.3853, Step: 3338\n",
      "fold_1 - Epoch 4, Precision: 0.9704, Recall: 0.9766, F1: 0.9735\n",
      "Loss: 0.0000, Acc: 1.0000, Time: 68.8588, Step: 1000\n",
      "Loss: 0.0025, Acc: 1.0000, Time: 72.8936, Step: 1052\n",
      "fold_1 - Epoch 4, Precision: 0.9477, Recall: 0.8975, F1: 0.9219\n",
      "Writing fold_1\n",
      "Loss: 0.2368, Acc: 1.0000, Time: 129.1956, Step: 1000\n",
      "Loss: 0.0224, Acc: 1.0000, Time: 252.5272, Step: 2000\n",
      "Loss: 0.0006, Acc: 1.0000, Time: 370.9751, Step: 3000\n",
      "Loss: 0.0181, Acc: 1.0000, Time: 439.8942, Step: 3613\n",
      "fold_2 - Epoch 0, Precision: 0.8788, Recall: 0.9195, F1: 0.8987\n",
      "Loss: 0.0001, Acc: 1.0000, Time: 60.8611, Step: 777\n",
      "fold_2 - Epoch 0, Precision: 0.9338, Recall: 0.9194, F1: 0.9265\n",
      "Loss: 1.2003, Acc: 0.9846, Time: 126.8621, Step: 1000\n",
      "Loss: 0.0000, Acc: 1.0000, Time: 249.9091, Step: 2000\n",
      "Loss: 0.0387, Acc: 1.0000, Time: 368.0924, Step: 3000\n",
      "Loss: 0.3884, Acc: 0.9833, Time: 439.4336, Step: 3613\n",
      "fold_2 - Epoch 1, Precision: 0.9490, Recall: 0.9618, F1: 0.9554\n",
      "Loss: 0.0003, Acc: 1.0000, Time: 59.9655, Step: 777\n",
      "fold_2 - Epoch 1, Precision: 0.9224, Recall: 0.9306, F1: 0.9265\n",
      "Loss: 0.0052, Acc: 1.0000, Time: 125.9176, Step: 1000\n",
      "Loss: 0.0464, Acc: 1.0000, Time: 248.9024, Step: 2000\n",
      "Loss: 0.1382, Acc: 0.9929, Time: 365.8323, Step: 3000\n",
      "Loss: 0.0044, Acc: 1.0000, Time: 439.4390, Step: 3613\n",
      "fold_2 - Epoch 2, Precision: 0.9610, Recall: 0.9687, F1: 0.9648\n",
      "Loss: -0.0001, Acc: 1.0000, Time: 59.9451, Step: 777\n",
      "fold_2 - Epoch 2, Precision: 0.9401, Recall: 0.8838, F1: 0.9111\n",
      "Loss: 0.0079, Acc: 1.0000, Time: 125.0089, Step: 1000\n",
      "Loss: 0.0059, Acc: 1.0000, Time: 250.8999, Step: 2000\n",
      "Loss: 0.0004, Acc: 1.0000, Time: 367.4109, Step: 3000\n",
      "Loss: 0.0187, Acc: 1.0000, Time: 438.9260, Step: 3613\n",
      "fold_2 - Epoch 3, Precision: 0.9646, Recall: 0.9729, F1: 0.9687\n",
      "Loss: 0.0001, Acc: 1.0000, Time: 59.9517, Step: 777\n",
      "fold_2 - Epoch 3, Precision: 0.9395, Recall: 0.9028, F1: 0.9208\n",
      "Loss: 0.0026, Acc: 1.0000, Time: 124.7168, Step: 1000\n",
      "Loss: 0.0036, Acc: 1.0000, Time: 249.7115, Step: 2000\n",
      "Loss: 0.0022, Acc: 1.0000, Time: 366.8206, Step: 3000\n",
      "Loss: 0.0002, Acc: 1.0000, Time: 438.2268, Step: 3613\n",
      "fold_2 - Epoch 4, Precision: 0.9690, Recall: 0.9763, F1: 0.9726\n",
      "Loss: 0.0001, Acc: 1.0000, Time: 59.9477, Step: 777\n",
      "fold_2 - Epoch 4, Precision: 0.9319, Recall: 0.9324, F1: 0.9321\n",
      "Writing fold_2\n",
      "Loss: 0.3844, Acc: 0.9909, Time: 124.9523, Step: 1000\n",
      "Loss: 0.0172, Acc: 1.0000, Time: 246.5692, Step: 2000\n",
      "Loss: 0.0111, Acc: 1.0000, Time: 357.9151, Step: 3000\n",
      "Loss: 0.0125, Acc: 1.0000, Time: 430.7073, Step: 3632\n",
      "fold_3 - Epoch 0, Precision: 0.8805, Recall: 0.9210, F1: 0.9003\n",
      "Loss: 0.2438, Acc: 0.9733, Time: 62.6668, Step: 758\n",
      "fold_3 - Epoch 0, Precision: 0.7911, Recall: 0.8715, F1: 0.8293\n",
      "Loss: 0.0045, Acc: 1.0000, Time: 123.3609, Step: 1000\n",
      "Loss: 0.0102, Acc: 1.0000, Time: 241.7101, Step: 2000\n",
      "Loss: 0.0065, Acc: 1.0000, Time: 357.8901, Step: 3000\n",
      "Loss: 0.0022, Acc: 1.0000, Time: 431.0648, Step: 3632\n",
      "fold_3 - Epoch 1, Precision: 0.9576, Recall: 0.9668, F1: 0.9622\n",
      "Loss: 0.0606, Acc: 1.0000, Time: 61.7654, Step: 758\n",
      "fold_3 - Epoch 1, Precision: 0.8263, Recall: 0.8532, F1: 0.8396\n",
      "Loss: 0.0025, Acc: 1.0000, Time: 123.3228, Step: 1000\n",
      "Loss: 0.0016, Acc: 1.0000, Time: 242.2879, Step: 2000\n",
      "Loss: 0.0001, Acc: 1.0000, Time: 356.9221, Step: 3000\n",
      "Loss: 0.0320, Acc: 1.0000, Time: 429.8603, Step: 3632\n",
      "fold_3 - Epoch 2, Precision: 0.9657, Recall: 0.9735, F1: 0.9696\n",
      "Loss: 0.1210, Acc: 1.0000, Time: 61.8562, Step: 758\n",
      "fold_3 - Epoch 2, Precision: 0.8200, Recall: 0.8869, F1: 0.8521\n",
      "Loss: 0.1872, Acc: 0.9750, Time: 122.0061, Step: 1000\n",
      "Loss: 0.0034, Acc: 1.0000, Time: 242.1752, Step: 2000\n",
      "Loss: 0.0009, Acc: 1.0000, Time: 358.4532, Step: 3000\n",
      "Loss: 0.0023, Acc: 1.0000, Time: 429.5435, Step: 3632\n",
      "fold_3 - Epoch 3, Precision: 0.9729, Recall: 0.9802, F1: 0.9765\n",
      "Loss: 0.0032, Acc: 1.0000, Time: 61.7854, Step: 758\n",
      "fold_3 - Epoch 3, Precision: 0.8315, Recall: 0.8429, F1: 0.8372\n",
      "Loss: 0.0034, Acc: 1.0000, Time: 124.7511, Step: 1000\n",
      "Loss: 0.0051, Acc: 1.0000, Time: 242.6735, Step: 2000\n",
      "Loss: 0.0002, Acc: 1.0000, Time: 356.9884, Step: 3000\n",
      "Loss: 0.5286, Acc: 0.9200, Time: 430.3041, Step: 3632\n",
      "fold_3 - Epoch 4, Precision: 0.9733, Recall: 0.9821, F1: 0.9777\n",
      "Loss: 0.0004, Acc: 1.0000, Time: 61.8093, Step: 758\n",
      "fold_3 - Epoch 4, Precision: 0.8345, Recall: 0.8435, F1: 0.8390\n",
      "Writing fold_3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0643, Acc: 1.0000, Time: 123.6233, Step: 1000\n",
      "Loss: 0.0293, Acc: 1.0000, Time: 245.8858, Step: 2000\n",
      "Loss: 0.0194, Acc: 1.0000, Time: 367.9636, Step: 3000\n",
      "Loss: 0.8547, Acc: 0.8667, Time: 418.9395, Step: 3419\n",
      "fold_4 - Epoch 0, Precision: 0.8740, Recall: 0.9160, F1: 0.8945\n",
      "Loss: 0.0001, Acc: 1.0000, Time: 71.9694, Step: 971\n",
      "fold_4 - Epoch 0, Precision: 0.9024, Recall: 0.9431, F1: 0.9223\n",
      "Loss: 0.0643, Acc: 1.0000, Time: 122.6884, Step: 1000\n",
      "Loss: 0.0348, Acc: 1.0000, Time: 244.4384, Step: 2000\n",
      "Loss: 0.0010, Acc: 1.0000, Time: 365.9124, Step: 3000\n",
      "Loss: 0.0003, Acc: 1.0000, Time: 416.6621, Step: 3419\n",
      "fold_4 - Epoch 1, Precision: 0.9523, Recall: 0.9636, F1: 0.9579\n",
      "Loss: 0.0000, Acc: 1.0000, Time: 71.4247, Step: 971\n",
      "fold_4 - Epoch 1, Precision: 0.9475, Recall: 0.7862, F1: 0.8593\n",
      "Loss: 0.0708, Acc: 1.0000, Time: 121.0148, Step: 1000\n",
      "Loss: 0.0607, Acc: 1.0000, Time: 243.3112, Step: 2000\n",
      "Loss: 0.0224, Acc: 1.0000, Time: 366.4818, Step: 3000\n",
      "Loss: 0.0018, Acc: 1.0000, Time: 416.9944, Step: 3419\n",
      "fold_4 - Epoch 2, Precision: 0.9613, Recall: 0.9686, F1: 0.9649\n",
      "Loss: 0.0000, Acc: 1.0000, Time: 71.0544, Step: 971\n",
      "fold_4 - Epoch 2, Precision: 0.9029, Recall: 0.9159, F1: 0.9094\n",
      "Loss: 0.0020, Acc: 1.0000, Time: 122.2412, Step: 1000\n",
      "Loss: 0.0200, Acc: 1.0000, Time: 242.2239, Step: 2000\n",
      "Loss: 0.3360, Acc: 0.9733, Time: 365.3714, Step: 3000\n",
      "Loss: 0.0002, Acc: 1.0000, Time: 418.3601, Step: 3419\n",
      "fold_4 - Epoch 3, Precision: 0.9658, Recall: 0.9735, F1: 0.9696\n",
      "Loss: 0.0000, Acc: 1.0000, Time: 71.0964, Step: 971\n",
      "fold_4 - Epoch 3, Precision: 0.9279, Recall: 0.8123, F1: 0.8663\n",
      "Loss: 0.0109, Acc: 1.0000, Time: 122.6209, Step: 1000\n",
      "Loss: 0.0063, Acc: 1.0000, Time: 243.6861, Step: 2000\n",
      "Loss: 0.0004, Acc: 1.0000, Time: 366.0148, Step: 3000\n",
      "Loss: 0.0001, Acc: 1.0000, Time: 417.9257, Step: 3419\n",
      "fold_4 - Epoch 4, Precision: 0.9733, Recall: 0.9784, F1: 0.9758\n",
      "Loss: -0.0000, Acc: 1.0000, Time: 71.0174, Step: 971\n",
      "fold_4 - Epoch 4, Precision: 0.9229, Recall: 0.9144, F1: 0.9186\n",
      "Writing fold_4\n",
      "91.70%\t86.77%\t89.17%\t94.77%\t89.75%\t92.19%\t93.19%\t93.24%\t93.21%\t83.45%\t84.35%\t83.90%\t92.29%\t91.44%\t91.86%\t92.47%\t86.88%\t89.59%\t95.03%\t89.42%\t92.14%\t93.90%\t93.12%\t93.51%\t84.05%\t84.29%\t84.17%\t93.21%\t90.77%\t91.97%\t"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, os.path.realpath(os.path.pardir))\n",
    "\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from model.estimator import Estimator\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Disable debug logs Tensorflow.\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "estimator = Estimator()\n",
    "estimator.set_dataset_params({\n",
    "    'datadir': '../data/ner_on_html',\n",
    "    'dataset_mode': 'sentences',\n",
    "    \"model\": \"lstm_crf\",  \n",
    "    \"epochs\": 5,\n",
    "    \"batch_size\": 10,\n",
    "    \"use_features\": False,\n",
    "    \"word_embeddings\": \"elmo\",\n",
    "    \"char_representation\": \"lstm\",\n",
    "    \"decoder\": \"crf\",  \n",
    "    # \"loss\": \"cross_entropy\"\n",
    "})\n",
    "estimator.train_cv()\n",
    "\n",
    "!cd .. && ./eval_model.sh\n",
    "!mkdir -p ../results/cross_validation/lstm_crf_elmo\n",
    "!mv ../results/score/fold* ../results/cross_validation/lstm_crf_elmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold size: 29\n",
      "(35214, 300)\n",
      "Loss: 1.2083, Acc: 0.9759, Time: 72.0324, Step: 1000\n",
      "Loss: 0.0967, Acc: 1.0000, Time: 139.2430, Step: 2000\n",
      "Loss: 0.6713, Acc: 0.9818, Time: 201.1569, Step: 3000\n",
      "Loss: 0.0024, Acc: 1.0000, Time: 227.0417, Step: 3395\n",
      "fold_0 - Epoch 0, Precision: 0.8549, Recall: 0.8824, F1: 0.8684\n",
      "Loss: 0.1735, Acc: 1.0000, Time: 34.5421, Step: 995\n",
      "fold_0 - Epoch 0, Precision: 0.9307, Recall: 0.9481, F1: 0.9393\n",
      "Loss: 0.0007, Acc: 1.0000, Time: 70.0688, Step: 1000\n",
      "Loss: 0.2897, Acc: 0.9714, Time: 137.5691, Step: 2000\n",
      "Loss: 0.0082, Acc: 1.0000, Time: 201.5033, Step: 3000\n",
      "Loss: 0.0026, Acc: 1.0000, Time: 225.4529, Step: 3395\n",
      "fold_0 - Epoch 1, Precision: 0.9486, Recall: 0.9560, F1: 0.9523\n",
      "Loss: 0.0404, Acc: 1.0000, Time: 34.5108, Step: 995\n",
      "fold_0 - Epoch 1, Precision: 0.9346, Recall: 0.9527, F1: 0.9436\n",
      "Loss: 0.0011, Acc: 1.0000, Time: 70.6903, Step: 1000\n",
      "Loss: 0.0017, Acc: 1.0000, Time: 137.4134, Step: 2000\n",
      "Loss: 0.3458, Acc: 0.9750, Time: 199.6181, Step: 3000\n",
      "Loss: 0.0011, Acc: 1.0000, Time: 224.7109, Step: 3395\n",
      "fold_0 - Epoch 2, Precision: 0.9628, Recall: 0.9687, F1: 0.9657\n",
      "Loss: 0.2110, Acc: 0.9722, Time: 34.3194, Step: 995\n",
      "fold_0 - Epoch 2, Precision: 0.9239, Recall: 0.9601, F1: 0.9416\n",
      "Loss: 0.0015, Acc: 1.0000, Time: 69.9521, Step: 1000\n",
      "Loss: 0.0547, Acc: 1.0000, Time: 136.5182, Step: 2000\n",
      "Loss: 0.0083, Acc: 1.0000, Time: 200.0021, Step: 3000\n",
      "Loss: 0.0026, Acc: 1.0000, Time: 225.3206, Step: 3395\n",
      "fold_0 - Epoch 3, Precision: 0.9710, Recall: 0.9750, F1: 0.9730\n",
      "Loss: 0.0506, Acc: 1.0000, Time: 34.2702, Step: 995\n",
      "fold_0 - Epoch 3, Precision: 0.9294, Recall: 0.9539, F1: 0.9415\n",
      "Loss: 0.1812, Acc: 0.9944, Time: 69.9482, Step: 1000\n",
      "Loss: 1.1619, Acc: 0.9727, Time: 136.8810, Step: 2000\n",
      "Loss: 0.0787, Acc: 0.9909, Time: 200.6342, Step: 3000\n",
      "Loss: 0.0168, Acc: 1.0000, Time: 225.3643, Step: 3395\n",
      "fold_0 - Epoch 4, Precision: 0.9764, Recall: 0.9817, F1: 0.9790\n",
      "Loss: 0.6300, Acc: 0.9444, Time: 34.4470, Step: 995\n",
      "fold_0 - Epoch 4, Precision: 0.9410, Recall: 0.9512, F1: 0.9460\n",
      "Writing fold_0\n",
      "(35214, 300)\n",
      "Loss: 0.3439, Acc: 0.9857, Time: 72.9321, Step: 1000\n",
      "Loss: 0.4235, Acc: 0.9941, Time: 139.2603, Step: 2000\n",
      "Loss: 0.0308, Acc: 1.0000, Time: 202.5658, Step: 3000\n",
      "Loss: 0.0238, Acc: 1.0000, Time: 234.4805, Step: 3483\n",
      "fold_1 - Epoch 0, Precision: 0.7501, Recall: 0.8476, F1: 0.7959\n",
      "Loss: 0.0004, Acc: 1.0000, Time: 30.2696, Step: 907\n",
      "fold_1 - Epoch 0, Precision: 0.9329, Recall: 0.9181, F1: 0.9255\n",
      "Loss: 0.1618, Acc: 0.9957, Time: 71.4127, Step: 1000\n",
      "Loss: 0.1022, Acc: 0.9875, Time: 140.1033, Step: 2000\n",
      "Loss: 0.1300, Acc: 0.9667, Time: 203.5050, Step: 3000\n",
      "Loss: 0.0061, Acc: 1.0000, Time: 233.5622, Step: 3483\n",
      "fold_1 - Epoch 1, Precision: 0.9391, Recall: 0.9535, F1: 0.9463\n",
      "Loss: 0.0016, Acc: 1.0000, Time: 29.9114, Step: 907\n",
      "fold_1 - Epoch 1, Precision: 0.9446, Recall: 0.9378, F1: 0.9411\n",
      "Loss: 0.0465, Acc: 1.0000, Time: 69.6447, Step: 1000\n",
      "Loss: 0.0021, Acc: 1.0000, Time: 138.2807, Step: 2000\n",
      "Loss: 0.0010, Acc: 1.0000, Time: 203.2011, Step: 3000\n",
      "Loss: 0.0044, Acc: 1.0000, Time: 233.9783, Step: 3483\n",
      "fold_1 - Epoch 2, Precision: 0.9587, Recall: 0.9664, F1: 0.9625\n",
      "Loss: 0.0003, Acc: 1.0000, Time: 29.9029, Step: 907\n",
      "fold_1 - Epoch 2, Precision: 0.9634, Recall: 0.9454, F1: 0.9543\n",
      "Loss: 0.0040, Acc: 1.0000, Time: 71.7897, Step: 1000\n",
      "Loss: 0.0029, Acc: 1.0000, Time: 139.8371, Step: 2000\n",
      "Loss: 0.0069, Acc: 1.0000, Time: 204.5065, Step: 3000\n",
      "Loss: 0.0006, Acc: 1.0000, Time: 234.5533, Step: 3483\n",
      "fold_1 - Epoch 3, Precision: 0.9679, Recall: 0.9744, F1: 0.9712\n",
      "Loss: 0.0005, Acc: 1.0000, Time: 29.8964, Step: 907\n",
      "fold_1 - Epoch 3, Precision: 0.9505, Recall: 0.9196, F1: 0.9348\n",
      "Loss: 0.0249, Acc: 1.0000, Time: 71.0134, Step: 1000\n",
      "Loss: 0.0259, Acc: 1.0000, Time: 138.6288, Step: 2000\n",
      "Loss: 0.0010, Acc: 1.0000, Time: 203.6883, Step: 3000\n",
      "Loss: 0.0202, Acc: 1.0000, Time: 233.7486, Step: 3483\n",
      "fold_1 - Epoch 4, Precision: 0.9708, Recall: 0.9768, F1: 0.9738\n",
      "Loss: 0.0009, Acc: 1.0000, Time: 29.9499, Step: 907\n",
      "fold_1 - Epoch 4, Precision: 0.9596, Recall: 0.9435, F1: 0.9515\n",
      "Writing fold_1\n",
      "(35214, 300)\n",
      "Loss: 0.0940, Acc: 1.0000, Time: 68.8674, Step: 1000\n",
      "Loss: 0.0748, Acc: 1.0000, Time: 134.5772, Step: 2000\n",
      "Loss: 0.0319, Acc: 1.0000, Time: 198.5716, Step: 3000\n",
      "Loss: 0.0004, Acc: 1.0000, Time: 236.4111, Step: 3631\n",
      "fold_2 - Epoch 0, Precision: 0.8216, Recall: 0.8821, F1: 0.8508\n",
      "Loss: 0.0000, Acc: 1.0000, Time: 27.5565, Step: 759\n",
      "fold_2 - Epoch 0, Precision: 0.9175, Recall: 0.8990, F1: 0.9082\n",
      "Loss: 0.0073, Acc: 1.0000, Time: 67.9696, Step: 1000\n",
      "Loss: 0.0003, Acc: 1.0000, Time: 133.5203, Step: 2000\n",
      "Loss: 0.0093, Acc: 1.0000, Time: 195.6496, Step: 3000\n",
      "Loss: 0.0006, Acc: 1.0000, Time: 235.0855, Step: 3631\n",
      "fold_2 - Epoch 1, Precision: 0.9453, Recall: 0.9557, F1: 0.9505\n",
      "Loss: 0.0000, Acc: 1.0000, Time: 27.1664, Step: 759\n",
      "fold_2 - Epoch 1, Precision: 0.8986, Recall: 0.9172, F1: 0.9078\n",
      "Loss: 0.0011, Acc: 1.0000, Time: 68.0747, Step: 1000\n",
      "Loss: 0.0077, Acc: 1.0000, Time: 134.3159, Step: 2000\n",
      "Loss: 0.0347, Acc: 1.0000, Time: 196.8701, Step: 3000\n",
      "Loss: 0.0015, Acc: 1.0000, Time: 235.3485, Step: 3631\n",
      "fold_2 - Epoch 2, Precision: 0.9628, Recall: 0.9706, F1: 0.9667\n",
      "Loss: 0.0000, Acc: 1.0000, Time: 27.1268, Step: 759\n",
      "fold_2 - Epoch 2, Precision: 0.9086, Recall: 0.9212, F1: 0.9149\n",
      "Loss: 0.0016, Acc: 1.0000, Time: 67.8492, Step: 1000\n",
      "Loss: 0.0407, Acc: 1.0000, Time: 133.6564, Step: 2000\n",
      "Loss: 0.0009, Acc: 1.0000, Time: 197.2320, Step: 3000\n",
      "Loss: 0.0048, Acc: 1.0000, Time: 235.5919, Step: 3631\n",
      "fold_2 - Epoch 3, Precision: 0.9695, Recall: 0.9749, F1: 0.9722\n",
      "Loss: 0.0000, Acc: 1.0000, Time: 27.2195, Step: 759\n",
      "fold_2 - Epoch 3, Precision: 0.9074, Recall: 0.9079, F1: 0.9077\n",
      "Loss: 0.0028, Acc: 1.0000, Time: 68.0466, Step: 1000\n",
      "Loss: 0.0136, Acc: 1.0000, Time: 134.1937, Step: 2000\n",
      "Loss: 0.0181, Acc: 1.0000, Time: 196.1053, Step: 3000\n",
      "Loss: 0.0014, Acc: 1.0000, Time: 235.7103, Step: 3631\n",
      "fold_2 - Epoch 4, Precision: 0.9727, Recall: 0.9776, F1: 0.9751\n",
      "Loss: 0.0000, Acc: 1.0000, Time: 27.2181, Step: 759\n",
      "fold_2 - Epoch 4, Precision: 0.9162, Recall: 0.9212, F1: 0.9187\n",
      "Writing fold_2\n",
      "(35214, 300)\n",
      "Loss: 0.0524, Acc: 1.0000, Time: 72.3133, Step: 1000\n",
      "Loss: 0.0228, Acc: 1.0000, Time: 142.1807, Step: 2000\n",
      "Loss: 0.0466, Acc: 1.0000, Time: 205.5601, Step: 3000\n",
      "Loss: 0.2762, Acc: 0.9500, Time: 238.7533, Step: 3509\n",
      "fold_3 - Epoch 0, Precision: 0.8460, Recall: 0.8877, F1: 0.8664\n",
      "Loss: 0.0064, Acc: 1.0000, Time: 27.5774, Step: 881\n",
      "fold_3 - Epoch 0, Precision: 0.8109, Recall: 0.8387, F1: 0.8245\n",
      "Loss: 0.0046, Acc: 1.0000, Time: 71.1969, Step: 1000\n",
      "Loss: 0.0157, Acc: 1.0000, Time: 139.7575, Step: 2000\n",
      "Loss: 0.0245, Acc: 1.0000, Time: 205.5963, Step: 3000\n",
      "Loss: 0.0019, Acc: 1.0000, Time: 238.1678, Step: 3509\n",
      "fold_3 - Epoch 1, Precision: 0.9560, Recall: 0.9656, F1: 0.9608\n",
      "Loss: 0.0008, Acc: 1.0000, Time: 27.3981, Step: 881\n",
      "fold_3 - Epoch 1, Precision: 0.8526, Recall: 0.8420, F1: 0.8473\n",
      "Loss: 0.0070, Acc: 1.0000, Time: 70.9153, Step: 1000\n",
      "Loss: 0.0012, Acc: 1.0000, Time: 140.9354, Step: 2000\n",
      "Loss: 0.0448, Acc: 1.0000, Time: 206.8072, Step: 3000\n",
      "Loss: 0.0030, Acc: 1.0000, Time: 239.4400, Step: 3509\n",
      "fold_3 - Epoch 2, Precision: 0.9650, Recall: 0.9722, F1: 0.9686\n",
      "Loss: 0.0001, Acc: 1.0000, Time: 27.1717, Step: 881\n",
      "fold_3 - Epoch 2, Precision: 0.8406, Recall: 0.8480, F1: 0.8443\n",
      "Loss: 0.0388, Acc: 1.0000, Time: 70.5698, Step: 1000\n",
      "Loss: 0.0009, Acc: 1.0000, Time: 139.5989, Step: 2000\n",
      "Loss: 0.1151, Acc: 0.9800, Time: 205.7650, Step: 3000\n",
      "Loss: 0.0014, Acc: 1.0000, Time: 238.5241, Step: 3509\n",
      "fold_3 - Epoch 3, Precision: 0.9722, Recall: 0.9755, F1: 0.9739\n",
      "Loss: 0.0001, Acc: 1.0000, Time: 27.5060, Step: 881\n",
      "fold_3 - Epoch 3, Precision: 0.8377, Recall: 0.8747, F1: 0.8558\n",
      "Loss: 0.0856, Acc: 0.9867, Time: 71.2931, Step: 1000\n",
      "Loss: 0.0067, Acc: 1.0000, Time: 139.8553, Step: 2000\n",
      "Loss: 0.0079, Acc: 1.0000, Time: 204.4369, Step: 3000\n",
      "Loss: 0.0037, Acc: 1.0000, Time: 239.0452, Step: 3509\n",
      "fold_3 - Epoch 4, Precision: 0.9763, Recall: 0.9793, F1: 0.9778\n",
      "Loss: 0.0001, Acc: 1.0000, Time: 27.1597, Step: 881\n",
      "fold_3 - Epoch 4, Precision: 0.8434, Recall: 0.8365, F1: 0.8399\n",
      "Writing fold_3\n",
      "(35214, 300)\n",
      "Loss: 0.2226, Acc: 1.0000, Time: 71.5096, Step: 1000\n",
      "Loss: 0.0116, Acc: 1.0000, Time: 138.5507, Step: 2000\n",
      "Loss: 0.1398, Acc: 0.9875, Time: 201.4100, Step: 3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1035, Acc: 1.0000, Time: 234.7522, Step: 3537\n",
      "fold_4 - Epoch 0, Precision: 0.8973, Recall: 0.9085, F1: 0.9029\n",
      "Loss: 0.0011, Acc: 1.0000, Time: 27.8724, Step: 853\n",
      "fold_4 - Epoch 0, Precision: 0.8271, Recall: 0.9678, F1: 0.8919\n",
      "Loss: 0.0004, Acc: 1.0000, Time: 70.7192, Step: 1000\n",
      "Loss: 0.0260, Acc: 1.0000, Time: 135.8408, Step: 2000\n",
      "Loss: 0.1739, Acc: 0.9842, Time: 198.8692, Step: 3000\n",
      "Loss: 0.0014, Acc: 1.0000, Time: 233.4605, Step: 3537\n",
      "fold_4 - Epoch 1, Precision: 0.9545, Recall: 0.9620, F1: 0.9583\n",
      "Loss: 0.0004, Acc: 1.0000, Time: 27.3897, Step: 853\n",
      "fold_4 - Epoch 1, Precision: 0.8437, Recall: 0.9633, F1: 0.8996\n",
      "Loss: 0.0004, Acc: 1.0000, Time: 72.1640, Step: 1000\n",
      "Loss: 0.0015, Acc: 1.0000, Time: 136.4272, Step: 2000\n",
      "Loss: 0.0060, Acc: 1.0000, Time: 198.7079, Step: 3000\n",
      "Loss: 0.0009, Acc: 1.0000, Time: 233.3336, Step: 3537\n",
      "fold_4 - Epoch 2, Precision: 0.9672, Recall: 0.9742, F1: 0.9707\n",
      "Loss: 0.0000, Acc: 1.0000, Time: 27.4816, Step: 853\n",
      "fold_4 - Epoch 2, Precision: 0.8377, Recall: 0.9555, F1: 0.8928\n",
      "Loss: 0.0014, Acc: 1.0000, Time: 71.7895, Step: 1000\n",
      "Loss: 0.0002, Acc: 1.0000, Time: 138.8852, Step: 2000\n",
      "Loss: 0.0119, Acc: 1.0000, Time: 201.0406, Step: 3000\n",
      "Loss: 0.0005, Acc: 1.0000, Time: 234.5247, Step: 3537\n",
      "fold_4 - Epoch 3, Precision: 0.9739, Recall: 0.9782, F1: 0.9760\n",
      "Loss: 0.0000, Acc: 1.0000, Time: 27.3792, Step: 853\n",
      "fold_4 - Epoch 3, Precision: 0.8541, Recall: 0.9694, F1: 0.9081\n",
      "Loss: 0.0006, Acc: 1.0000, Time: 71.2871, Step: 1000\n",
      "Loss: 0.0000, Acc: 1.0000, Time: 136.5397, Step: 2000\n",
      "Loss: 0.0027, Acc: 1.0000, Time: 199.6072, Step: 3000\n",
      "Loss: 0.0017, Acc: 1.0000, Time: 233.4570, Step: 3537\n",
      "fold_4 - Epoch 4, Precision: 0.9788, Recall: 0.9813, F1: 0.9800\n",
      "Loss: 0.0000, Acc: 1.0000, Time: 27.4732, Step: 853\n",
      "fold_4 - Epoch 4, Precision: 0.8370, Recall: 0.9644, F1: 0.8962\n",
      "Writing fold_4\n",
      "94.10%\t95.12%\t94.60%\t95.96%\t94.35%\t95.15%\t91.62%\t92.12%\t91.87%\t84.34%\t83.65%\t83.99%\t83.70%\t96.44%\t89.62%\t94.11%\t94.81%\t94.46%\t96.33%\t94.21%\t95.26%\t92.22%\t92.22%\t92.22%\t90.08%\t83.11%\t86.45%\t84.54%\t96.39%\t90.08%\t"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, os.path.realpath(os.path.pardir))\n",
    "\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from model.estimator import Estimator\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Disable debug logs Tensorflow.\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "estimator = Estimator()\n",
    "estimator.set_dataset_params({\n",
    "    'datadir': '../data/ner_on_html',\n",
    "    'dataset_mode': 'sentences',\n",
    "    \"model\": \"lstm_crf\",  \n",
    "    \"epochs\": 5,\n",
    "    \"batch_size\": 10,\n",
    "    \"use_features\": False,\n",
    "    \"word_embeddings\": \"glove\",\n",
    "    \"char_representation\": \"lstm\",\n",
    "    \"decoder\": \"crf\",  \n",
    "    # \"loss\": \"cross_entropy\"\n",
    "})\n",
    "estimator.train_cv()\n",
    "\n",
    "!cd .. && ./eval_model.sh\n",
    "!mkdir -p ../results/cross_validation/lstm_crf_elmo\n",
    "!mv ../results/score/fold* ../results/cross_validation/lstm_crf_elmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_hub\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/64/3bba86ca49ef21a4add11a4d37e3f6cd05d2e61d207ebe26a8a96b340826/tensorflow_hub-0.6.0-py2.py3-none-any.whl (84kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 3.9MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub) (1.16.4)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub) (3.8.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/lib/python3/dist-packages (from tensorflow_hub) (1.11.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow_hub) (41.0.1)\n",
      "Installing collected packages: tensorflow-hub\n",
      "Successfully installed tensorflow-hub-0.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold size: 812\n",
      "(35214, 300)\n",
      "Loss: 5.4085, Acc: 0.9674, Time: 187.4245, Step: 1000\n",
      "Loss: 0.0660, Acc: 1.0000, Time: 370.4121, Step: 2000\n",
      "Loss: 0.5303, Acc: 1.0000, Time: 553.1166, Step: 3000\n",
      "Loss: 0.0626, Acc: 1.0000, Time: 598.8995, Step: 3251\n",
      "fold_0 - Epoch 0, Precision: 0.6763, Recall: 0.7535, F1: 0.7128\n",
      "Loss: 0.0447, Acc: 1.0000, Time: 96.2599, Step: 813\n",
      "fold_0 - Epoch 0, Precision: 0.8902, Recall: 0.9437, F1: 0.9162\n",
      "Loss: 1.9442, Acc: 0.9556, Time: 187.6508, Step: 1000\n",
      "Loss: 0.1932, Acc: 1.0000, Time: 369.7559, Step: 2000\n",
      "Loss: 0.2126, Acc: 1.0000, Time: 553.2094, Step: 3000\n",
      "Loss: 0.0522, Acc: 1.0000, Time: 598.0694, Step: 3251\n",
      "fold_0 - Epoch 1, Precision: 0.9042, Recall: 0.9136, F1: 0.9088\n",
      "Loss: 0.0196, Acc: 1.0000, Time: 95.8701, Step: 813\n",
      "fold_0 - Epoch 1, Precision: 0.9410, Recall: 0.9127, F1: 0.9266\n",
      "Loss: 0.0663, Acc: 1.0000, Time: 186.7542, Step: 1000\n",
      "Loss: 0.0623, Acc: 1.0000, Time: 369.2649, Step: 2000\n",
      "Loss: 4.6239, Acc: 0.9636, Time: 551.7218, Step: 3000\n",
      "Loss: 3.0582, Acc: 0.9600, Time: 597.8720, Step: 3251\n",
      "fold_0 - Epoch 2, Precision: 0.9356, Recall: 0.9367, F1: 0.9361\n",
      "Loss: 0.1963, Acc: 1.0000, Time: 95.9133, Step: 813\n",
      "fold_0 - Epoch 2, Precision: 0.9593, Recall: 0.9733, F1: 0.9663\n",
      "Loss: 0.0032, Acc: 1.0000, Time: 185.9139, Step: 1000\n",
      "Loss: 0.0288, Acc: 1.0000, Time: 364.8309, Step: 2000\n",
      "Loss: 0.0121, Acc: 1.0000, Time: 552.9167, Step: 3000\n",
      "Loss: 2.0200, Acc: 0.9767, Time: 598.2428, Step: 3251\n",
      "fold_0 - Epoch 3, Precision: 0.9463, Recall: 0.9440, F1: 0.9452\n",
      "Loss: 0.1457, Acc: 1.0000, Time: 95.9399, Step: 813\n",
      "fold_0 - Epoch 3, Precision: 0.9347, Recall: 0.9859, F1: 0.9596\n",
      "Loss: 0.7436, Acc: 1.0000, Time: 186.0689, Step: 1000\n",
      "Loss: 0.0161, Acc: 1.0000, Time: 371.6972, Step: 2000\n",
      "Loss: 0.0130, Acc: 1.0000, Time: 551.4035, Step: 3000\n",
      "Loss: 0.0143, Acc: 1.0000, Time: 598.5093, Step: 3251\n",
      "fold_0 - Epoch 4, Precision: 0.9486, Recall: 0.9479, F1: 0.9482\n",
      "Loss: 0.0071, Acc: 1.0000, Time: 96.1748, Step: 813\n",
      "fold_0 - Epoch 4, Precision: 0.9611, Recall: 0.9830, F1: 0.9719\n",
      "Writing fold_0\n",
      "(35214, 300)\n",
      "Loss: 3.0526, Acc: 0.9459, Time: 190.4093, Step: 1000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, os.path.realpath(os.path.pardir))\n",
    "\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from model.estimator import Estimator\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Disable debug logs Tensorflow.\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "estimator = Estimator()\n",
    "estimator.set_dataset_params({\n",
    "    'datadir': '../data/ner_on_html',\n",
    "    'dataset_mode': 'batch',\n",
    "    \"model\": \"html_attention\",  \n",
    "    \"epochs\": 5,\n",
    "    \"batch_size\": 1,\n",
    "    \"use_features\": False,\n",
    "    \"word_embeddings\": \"glove\",\n",
    "    \"char_representation\": \"lstm\",\n",
    "    \"decoder\": \"crf\",  \n",
    "    # \"loss\": \"cross_entropy\"\n",
    "})\n",
    "estimator.train_cv()\n",
    "\n",
    "!cd .. && ./eval_model.sh\n",
    "!mkdir -p ../results/cross_validation/hard_attention\n",
    "!mv ../results/score/fold* ../results/cross_validation/hard_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
