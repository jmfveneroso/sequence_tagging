{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Researcher Name Extraction Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset statistics:\n",
    "\n",
    "| Data file  | Documents | Sentences | Tokens | Names |\n",
    "|------------|-----------|-----------|--------|-------|\n",
    "| Training   | 80        | 24728     | 110269 | 5822  |\n",
    "| Validation | 35        | 8743      | 36757  | 1788  |\n",
    "| Test       | 35        | 10399     | 44795  | 2723  |\n",
    "| Total      | 145       | 43870     | 191821 | 10333 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "sys.path.insert(1, os.path.realpath(os.path.pardir))\n",
    "\n",
    "from optparse import OptionParser\n",
    "from pathlib import Path\n",
    "from model.hmm import HiddenMarkov, load_dataset\n",
    "\n",
    "start_time = time.time()\n",
    "for name in ['train', 'valid', 'test']:\n",
    "    _, Y, T = load_dataset('../data/ner_on_html/' + name)\n",
    "    t = [[['O', 'B-PER', 'I-PER'][t__] for t__ in t_] for t_ in Y]\n",
    "    p = [[['O', 'B-PER', 'I-PER'][p__] for p__ in p_] for p_ in Y]\n",
    "    w = T\n",
    "    \n",
    "    with Path('../results/score/{}.preds.txt'.format(name)).open('wb') as f:\n",
    "        for words, preds, tags in zip(w, p, t):\n",
    "            f.write(b'\\n')\n",
    "            for word, pred, tag in zip(words, preds, tags):\n",
    "                f.write(' '.join([word, tag, pred]).encode() + b'\\n')\n",
    "\n",
    "!cd .. && ./eval.sh | grep processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "def plot_word_frequency(directory, color):\n",
    "    my_counter = Counter()\n",
    "    for fname in ['train', 'valid', 'test']:\n",
    "        with open(directory + '/' + fname) as f:\n",
    "            words = [line.strip().lower().split()[0] for line in f if len(line.strip()) > 0]\n",
    "            words = [w for w in words if w != '-docstart-']\n",
    "            my_counter.update(words)\n",
    "\n",
    "    data = [(key, my_counter[key]) for key in my_counter]    \n",
    "    data.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print([(i, x[1]) for i, x in enumerate(data)][:100])\n",
    "    plt.plot([x[1] for x in data][:100], color)\n",
    "    return data[:50]\n",
    "    \n",
    "plt.title('Word frequencies')\n",
    "data1 = plot_word_frequency('../data/conll2003', 'r')\n",
    "data2 = plot_word_frequency('../data/ner_on_html', 'b')\n",
    "\n",
    "print(' '.join([d[0] for d in data1[:10]]))\n",
    "print()\n",
    "print(' '.join([d[0] for d in data2[:10]]))\n",
    "\n",
    "for d1, d2 in zip(data1, data2):\n",
    "    print('%s & %d & %s & %d' % (d1[0], d1[1], d2[0], d2[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['department', '0', '0', '0', '0', '0', '0', '1', '0', 'head.html', 'none'], ['of', '0', '1', '0', '0', '0', '0', '0', '0', 'head.html', 'none'], ['computer', '0', '0', '0', '0', '0', '0', '1', '0', 'head.html', 'none'], ['science', '0', '0', '0', '0', '0', '0', '1', '0', 'head.html', 'none'], ['and', '0', '1', '0', '0', '0', '0', '0', '0', 'head.html', 'none']]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from dython import nominal\n",
    "\n",
    "def load_raw_dataset(f):\n",
    "    with open(f, 'r', encoding='utf8') as f:\n",
    "        data = f.read().strip()\n",
    "        sentences = [s.split('\\n') for s in data.split('\\n\\n') if not s.startswith('-DOCSTART-')]\n",
    "        X = [t.split(' ') for s in sentences for t in s if len(s) > 0]\n",
    "        for i, s in enumerate(X):\n",
    "            X[i] = X[i][2:5] + X[i][7:]\n",
    "        return X\n",
    "\n",
    "X = load_raw_dataset('../data/ner_on_html/train')\n",
    "X += load_raw_dataset('../data/ner_on_html/valid')\n",
    "X += load_raw_dataset('../data/ner_on_html/test')\n",
    "print(X[:5])\n",
    "\n",
    "data = {}\n",
    "data['words']         = [x[0 ] for x in X]\n",
    "data['exact_match']   = [int(x[1]) for x in X]\n",
    "data['partial_match'] = [int(x[2]) for x in X]\n",
    "data['email']         = [int(x[3]) for x in X]\n",
    "data['number']        = [int(x[4]) for x in X]\n",
    "data['honorific']     = [int(x[5]) for x in X] \n",
    "data['url']           = [int(x[6]) for x in X]\n",
    "data['capitalized']   = [int(x[7]) for x in X]\n",
    "data['punctuation']   = [int(x[8]) for x in X]\n",
    "# data['html_tag']      = [x[9 ] for x in X]\n",
    "# data['css_class']     = [x[10] for x in X]\n",
    "\n",
    "data['words'][0]\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "nominal.associations(df, nominal_columns=['words'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it: https://github.com/shakedzy/dython/issues/2\n",
    "\n",
    "Calculates Cramer's V statistic for categorical-categorical association.\n",
    "Uses correction from Bergsma and Wicher, Journal of the Korean Statistical Society 42 (2013): 323-328.\n",
    "This is a symmetric coefficient: V(x,y) = V(y,x)\n",
    "\n",
    "https://github.com/shakedzy/dython/blob/master/dython/nominal.py\n",
    "https://en.wikipedia.org/wiki/Cram%C3%A9r%27s_V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested cross-validation\n",
    "\n",
    "5-fold cross validation\n",
    "\n",
    "\n",
    "Partition the training data randomly in five folds\n",
    "\n",
    "Nested CV\n",
    "https://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html\n",
    "\n",
    "Common error with cross validation\n",
    "https://www.youtube.com/watch?v=S06JpVoNaA0\n",
    "\n",
    "https://www.kdnuggets.com/2017/08/dataiku-predictive-model-holdout-cross-validation.html\n",
    "\n",
    "https://www.datarobot.com/wiki/training-validation-holdout/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is split into 3 different files: train, valid, and test. Also, we provide 11 features alongside each token.\n",
    "\n",
    "| Feature                          | Type        |\n",
    "|----------------------------------|-------------|\n",
    "| Unaccented lowercase token       | Categorical |\n",
    "| Exact dictionary match           | Binary      |\n",
    "| Partial dictionary match         | Binary      |\n",
    "| Email                            | Binary      |\n",
    "| Number                           | Binary      |\n",
    "| Honorific (Mr., Mrs., Dr., etc.) | Binary      |\n",
    "| Matches a URL                    | Binary      |\n",
    "| Is capitalized                   | Binary      |\n",
    "| Is a punctuation sign            | Binary      |\n",
    "| HTML tag + parent                | Categorical |\n",
    "| CSS class                        | Categorical |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden Markov Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "sys.path.insert(1, os.path.realpath(os.path.pardir))\n",
    "\n",
    "from optparse import OptionParser\n",
    "from pathlib import Path\n",
    "from model.hmm import HiddenMarkov, load_dataset\n",
    "\n",
    "def test_hmm(timesteps, use_features, dataset):\n",
    "    start_time = time.time()\n",
    "    naive_bayes = timesteps == 0\n",
    "    if naive_bayes:\n",
    "        timesteps = 1\n",
    "        \n",
    "    print('Fitting...')\n",
    "    X1, Y1, T1 = load_dataset(dataset + '/train')\n",
    "    X2, Y2, T2 = load_dataset(dataset + '/valid')\n",
    "    X3, Y3, T3 = load_dataset(dataset + '/test')    \n",
    "    training_set = [x for x in zip(X1 + X2 + X3, Y1 + Y2 + Y3, T1 + T2 + T3)]\n",
    "\n",
    "    random.shuffle(training_set)\n",
    "    fold_size = len(training_set) // 5\n",
    "    \n",
    "    folds = []\n",
    "    for i in range(5):\n",
    "        start = i * fold_size\n",
    "        end = start + fold_size if (i < 4) else len(training_set)\n",
    "        folds.append(training_set[start:end])\n",
    "    print('Fold size:', fold_size)\n",
    "    \n",
    "    for i in range(5):\n",
    "        train = []        \n",
    "        for j in range(5):        \n",
    "            if i != j:\n",
    "                train = train + folds[j]\n",
    "                \n",
    "        map(list, zip(*train))\n",
    "        train_X, train_Y, train_T = [list(t) for t in zip(*train)]\n",
    "        \n",
    "        map(list, zip(*folds[i]))\n",
    "        test_X, test_Y, test_T = [list(t) for t in zip(*folds[i])]\n",
    "        \n",
    "        hmm = HiddenMarkov(timesteps, naive_bayes=naive_bayes, use_features=use_features, self_train=False)\n",
    "        hmm.fit(train_X, train_Y)\n",
    "\n",
    "        t = test_Y\n",
    "        p = hmm.predict(test_X)\n",
    "\n",
    "        t = [[['O', 'B-PER', 'I-PER'][t__] for t__ in t_] for t_ in t]\n",
    "        p = [[['O', 'B-PER', 'I-PER'][p__] for p__ in p_] for p_ in p]\n",
    "        w = test_T\n",
    "\n",
    "        name = 'fold_' + str(i)\n",
    "        print('Writing', name)\n",
    "        with Path('../results/score/{}.preds.txt'.format(name)).open('wb') as f:\n",
    "            for words, preds, tags in zip(w, p, t):\n",
    "                f.write(b'\\n')\n",
    "                for word, pred, tag in zip(words, preds, tags):\n",
    "                    f.write(' '.join([word, tag, pred]).encode() + b'\\n')\n",
    "\n",
    "    print('Elapsed time: %.4f' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_hmm(0, False, '../data/ner_on_html')\n",
    "\n",
    "!cd .. && ./eval_model.sh\n",
    "!mkdir -p ../results/cross_validation/nb\n",
    "!mv ../results/score/fold* ../results/cross_validation/nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, os.path.realpath(os.path.pardir))\n",
    "\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from model.estimator import Estimator\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Disable debug logs Tensorflow.\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "estimator = Estimator()\n",
    "estimator.set_dataset_params({\n",
    "    'datadir': '../data/ner_on_html',\n",
    "    'dataset_mode': 'sentences'    \n",
    "})\n",
    "estimator.train_cv()\n",
    "# estimator.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM-CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold size: 29\n",
      "Loss: 0.1017, Acc: 1.0000, Time: 121.6090, Step: 1000\n",
      "Loss: 0.0378, Acc: 1.0000, Time: 238.9198, Step: 2000\n",
      "Loss: 0.0001, Acc: 1.0000, Time: 359.0481, Step: 3000\n",
      "Loss: 0.0098, Acc: 1.0000, Time: 423.8942, Step: 3553\n",
      "fold_0 - Epoch 0, Precision: 0.9042, Recall: 0.9230, F1: 0.9135\n",
      "Loss: 0.0124, Acc: 1.0000, Time: 63.2519, Step: 836\n",
      "fold_0 - Epoch 0, Precision: 0.9511, Recall: 0.8532, F1: 0.8995\n",
      "Loss: 0.0028, Acc: 1.0000, Time: 117.8207, Step: 1000\n",
      "Loss: 0.0052, Acc: 1.0000, Time: 238.0059, Step: 2000\n",
      "Loss: 0.0018, Acc: 1.0000, Time: 353.4686, Step: 3000\n",
      "Loss: 0.0083, Acc: 1.0000, Time: 415.8655, Step: 3553\n",
      "fold_0 - Epoch 1, Precision: 0.9519, Recall: 0.9579, F1: 0.9549\n",
      "Loss: 0.0044, Acc: 1.0000, Time: 62.0387, Step: 836\n",
      "fold_0 - Epoch 1, Precision: 0.9280, Recall: 0.8030, F1: 0.8610\n",
      "Loss: 0.0006, Acc: 1.0000, Time: 117.5116, Step: 1000\n",
      "Loss: 0.0777, Acc: 1.0000, Time: 236.7794, Step: 2000\n",
      "Loss: 0.0996, Acc: 0.9714, Time: 354.4473, Step: 3000\n",
      "Loss: 0.0013, Acc: 1.0000, Time: 418.6432, Step: 3553\n",
      "fold_0 - Epoch 2, Precision: 0.9612, Recall: 0.9678, F1: 0.9645\n",
      "Loss: 0.0058, Acc: 1.0000, Time: 61.9507, Step: 836\n",
      "fold_0 - Epoch 2, Precision: 0.8933, Recall: 0.8942, F1: 0.8938\n",
      "Loss: 0.0381, Acc: 1.0000, Time: 115.6291, Step: 1000\n",
      "Loss: 0.4179, Acc: 0.9750, Time: 237.7659, Step: 2000\n",
      "Loss: 0.0020, Acc: 1.0000, Time: 353.1593, Step: 3000\n",
      "Loss: 0.1245, Acc: 0.9957, Time: 415.8285, Step: 3553\n",
      "fold_0 - Epoch 3, Precision: 0.9683, Recall: 0.9735, F1: 0.9709\n",
      "Loss: 0.0012, Acc: 1.0000, Time: 62.0451, Step: 836\n",
      "fold_0 - Epoch 3, Precision: 0.9138, Recall: 0.8624, F1: 0.8874\n",
      "Loss: 0.0001, Acc: 1.0000, Time: 115.2234, Step: 1000\n",
      "Loss: 0.0011, Acc: 1.0000, Time: 236.6070, Step: 2000\n",
      "Loss: 0.0357, Acc: 1.0000, Time: 353.2468, Step: 3000\n",
      "Loss: 0.0025, Acc: 1.0000, Time: 416.6289, Step: 3553\n",
      "fold_0 - Epoch 4, Precision: 0.9743, Recall: 0.9783, F1: 0.9763\n",
      "Loss: 0.0008, Acc: 1.0000, Time: 62.0527, Step: 836\n",
      "fold_0 - Epoch 4, Precision: 0.9170, Recall: 0.8677, F1: 0.8917\n",
      "Writing fold_0\n",
      "Loss: 0.1917, Acc: 0.9955, Time: 136.1281, Step: 1000\n",
      "Loss: 0.0174, Acc: 1.0000, Time: 262.3505, Step: 2000\n",
      "Loss: 0.0085, Acc: 1.0000, Time: 380.6413, Step: 3000\n",
      "Loss: 0.0000, Acc: 1.0000, Time: 420.3787, Step: 3338\n",
      "fold_1 - Epoch 0, Precision: 0.8642, Recall: 0.9098, F1: 0.8864\n",
      "Loss: 0.0010, Acc: 1.0000, Time: 69.6541, Step: 1000\n",
      "Loss: 0.0077, Acc: 1.0000, Time: 73.7256, Step: 1052\n",
      "fold_1 - Epoch 0, Precision: 0.9393, Recall: 0.8990, F1: 0.9187\n",
      "Loss: 0.0175, Acc: 1.0000, Time: 132.3835, Step: 1000\n",
      "Loss: 0.0404, Acc: 1.0000, Time: 258.5432, Step: 2000\n",
      "Loss: 0.0984, Acc: 0.9941, Time: 378.4161, Step: 3000\n",
      "Loss: 0.0018, Acc: 1.0000, Time: 418.6742, Step: 3338\n",
      "fold_1 - Epoch 1, Precision: 0.9501, Recall: 0.9643, F1: 0.9572\n",
      "Loss: 0.0045, Acc: 1.0000, Time: 68.7687, Step: 1000\n",
      "Loss: 0.0017, Acc: 1.0000, Time: 72.7986, Step: 1052\n",
      "fold_1 - Epoch 1, Precision: 0.9046, Recall: 0.9268, F1: 0.9156\n",
      "Loss: 0.0161, Acc: 1.0000, Time: 132.1847, Step: 1000\n",
      "Loss: 0.0003, Acc: 1.0000, Time: 259.1748, Step: 2000\n",
      "Loss: 0.1104, Acc: 0.9976, Time: 379.0688, Step: 3000\n",
      "Loss: -0.0000, Acc: 1.0000, Time: 422.0104, Step: 3338\n",
      "fold_1 - Epoch 2, Precision: 0.9580, Recall: 0.9685, F1: 0.9632\n",
      "Loss: 0.0000, Acc: 1.0000, Time: 68.8422, Step: 1000\n",
      "Loss: 0.0038, Acc: 1.0000, Time: 72.8829, Step: 1052\n",
      "fold_1 - Epoch 2, Precision: 0.9031, Recall: 0.9023, F1: 0.9027\n",
      "Loss: 0.0347, Acc: 1.0000, Time: 132.8114, Step: 1000\n",
      "Loss: 0.0065, Acc: 1.0000, Time: 257.4727, Step: 2000\n",
      "Loss: 0.0117, Acc: 1.0000, Time: 378.9053, Step: 3000\n",
      "Loss: 0.0282, Acc: 1.0000, Time: 420.6923, Step: 3338\n",
      "fold_1 - Epoch 3, Precision: 0.9647, Recall: 0.9727, F1: 0.9687\n",
      "Loss: 0.0002, Acc: 1.0000, Time: 68.8260, Step: 1000\n",
      "Loss: 0.0012, Acc: 1.0000, Time: 72.8579, Step: 1052\n",
      "fold_1 - Epoch 3, Precision: 0.9357, Recall: 0.9212, F1: 0.9284\n",
      "Loss: 0.0358, Acc: 1.0000, Time: 133.0295, Step: 1000\n",
      "Loss: 0.0004, Acc: 1.0000, Time: 259.3329, Step: 2000\n",
      "Loss: 0.0009, Acc: 1.0000, Time: 378.4286, Step: 3000\n",
      "Loss: 0.0049, Acc: 1.0000, Time: 419.3853, Step: 3338\n",
      "fold_1 - Epoch 4, Precision: 0.9704, Recall: 0.9766, F1: 0.9735\n",
      "Loss: 0.0000, Acc: 1.0000, Time: 68.8588, Step: 1000\n",
      "Loss: 0.0025, Acc: 1.0000, Time: 72.8936, Step: 1052\n",
      "fold_1 - Epoch 4, Precision: 0.9477, Recall: 0.8975, F1: 0.9219\n",
      "Writing fold_1\n",
      "Loss: 0.2368, Acc: 1.0000, Time: 129.1956, Step: 1000\n",
      "Loss: 0.0224, Acc: 1.0000, Time: 252.5272, Step: 2000\n",
      "Loss: 0.0006, Acc: 1.0000, Time: 370.9751, Step: 3000\n",
      "Loss: 0.0181, Acc: 1.0000, Time: 439.8942, Step: 3613\n",
      "fold_2 - Epoch 0, Precision: 0.8788, Recall: 0.9195, F1: 0.8987\n",
      "Loss: 0.0001, Acc: 1.0000, Time: 60.8611, Step: 777\n",
      "fold_2 - Epoch 0, Precision: 0.9338, Recall: 0.9194, F1: 0.9265\n",
      "Loss: 1.2003, Acc: 0.9846, Time: 126.8621, Step: 1000\n",
      "Loss: 0.0000, Acc: 1.0000, Time: 249.9091, Step: 2000\n",
      "Loss: 0.0387, Acc: 1.0000, Time: 368.0924, Step: 3000\n",
      "Loss: 0.3884, Acc: 0.9833, Time: 439.4336, Step: 3613\n",
      "fold_2 - Epoch 1, Precision: 0.9490, Recall: 0.9618, F1: 0.9554\n",
      "Loss: 0.0003, Acc: 1.0000, Time: 59.9655, Step: 777\n",
      "fold_2 - Epoch 1, Precision: 0.9224, Recall: 0.9306, F1: 0.9265\n",
      "Loss: 0.0052, Acc: 1.0000, Time: 125.9176, Step: 1000\n",
      "Loss: 0.0464, Acc: 1.0000, Time: 248.9024, Step: 2000\n",
      "Loss: 0.1382, Acc: 0.9929, Time: 365.8323, Step: 3000\n",
      "Loss: 0.0044, Acc: 1.0000, Time: 439.4390, Step: 3613\n",
      "fold_2 - Epoch 2, Precision: 0.9610, Recall: 0.9687, F1: 0.9648\n",
      "Loss: -0.0001, Acc: 1.0000, Time: 59.9451, Step: 777\n",
      "fold_2 - Epoch 2, Precision: 0.9401, Recall: 0.8838, F1: 0.9111\n",
      "Loss: 0.0079, Acc: 1.0000, Time: 125.0089, Step: 1000\n",
      "Loss: 0.0059, Acc: 1.0000, Time: 250.8999, Step: 2000\n",
      "Loss: 0.0004, Acc: 1.0000, Time: 367.4109, Step: 3000\n",
      "Loss: 0.0187, Acc: 1.0000, Time: 438.9260, Step: 3613\n",
      "fold_2 - Epoch 3, Precision: 0.9646, Recall: 0.9729, F1: 0.9687\n",
      "Loss: 0.0001, Acc: 1.0000, Time: 59.9517, Step: 777\n",
      "fold_2 - Epoch 3, Precision: 0.9395, Recall: 0.9028, F1: 0.9208\n",
      "Loss: 0.0026, Acc: 1.0000, Time: 124.7168, Step: 1000\n",
      "Loss: 0.0036, Acc: 1.0000, Time: 249.7115, Step: 2000\n",
      "Loss: 0.0022, Acc: 1.0000, Time: 366.8206, Step: 3000\n",
      "Loss: 0.0002, Acc: 1.0000, Time: 438.2268, Step: 3613\n",
      "fold_2 - Epoch 4, Precision: 0.9690, Recall: 0.9763, F1: 0.9726\n",
      "Loss: 0.0001, Acc: 1.0000, Time: 59.9477, Step: 777\n",
      "fold_2 - Epoch 4, Precision: 0.9319, Recall: 0.9324, F1: 0.9321\n",
      "Writing fold_2\n",
      "Loss: 0.3844, Acc: 0.9909, Time: 124.9523, Step: 1000\n",
      "Loss: 0.0172, Acc: 1.0000, Time: 246.5692, Step: 2000\n",
      "Loss: 0.0111, Acc: 1.0000, Time: 357.9151, Step: 3000\n",
      "Loss: 0.0125, Acc: 1.0000, Time: 430.7073, Step: 3632\n",
      "fold_3 - Epoch 0, Precision: 0.8805, Recall: 0.9210, F1: 0.9003\n",
      "Loss: 0.2438, Acc: 0.9733, Time: 62.6668, Step: 758\n",
      "fold_3 - Epoch 0, Precision: 0.7911, Recall: 0.8715, F1: 0.8293\n",
      "Loss: 0.0045, Acc: 1.0000, Time: 123.3609, Step: 1000\n",
      "Loss: 0.0102, Acc: 1.0000, Time: 241.7101, Step: 2000\n",
      "Loss: 0.0065, Acc: 1.0000, Time: 357.8901, Step: 3000\n",
      "Loss: 0.0022, Acc: 1.0000, Time: 431.0648, Step: 3632\n",
      "fold_3 - Epoch 1, Precision: 0.9576, Recall: 0.9668, F1: 0.9622\n",
      "Loss: 0.0606, Acc: 1.0000, Time: 61.7654, Step: 758\n",
      "fold_3 - Epoch 1, Precision: 0.8263, Recall: 0.8532, F1: 0.8396\n",
      "Loss: 0.0025, Acc: 1.0000, Time: 123.3228, Step: 1000\n",
      "Loss: 0.0016, Acc: 1.0000, Time: 242.2879, Step: 2000\n",
      "Loss: 0.0001, Acc: 1.0000, Time: 356.9221, Step: 3000\n",
      "Loss: 0.0320, Acc: 1.0000, Time: 429.8603, Step: 3632\n",
      "fold_3 - Epoch 2, Precision: 0.9657, Recall: 0.9735, F1: 0.9696\n",
      "Loss: 0.1210, Acc: 1.0000, Time: 61.8562, Step: 758\n",
      "fold_3 - Epoch 2, Precision: 0.8200, Recall: 0.8869, F1: 0.8521\n",
      "Loss: 0.1872, Acc: 0.9750, Time: 122.0061, Step: 1000\n",
      "Loss: 0.0034, Acc: 1.0000, Time: 242.1752, Step: 2000\n",
      "Loss: 0.0009, Acc: 1.0000, Time: 358.4532, Step: 3000\n",
      "Loss: 0.0023, Acc: 1.0000, Time: 429.5435, Step: 3632\n",
      "fold_3 - Epoch 3, Precision: 0.9729, Recall: 0.9802, F1: 0.9765\n",
      "Loss: 0.0032, Acc: 1.0000, Time: 61.7854, Step: 758\n",
      "fold_3 - Epoch 3, Precision: 0.8315, Recall: 0.8429, F1: 0.8372\n",
      "Loss: 0.0034, Acc: 1.0000, Time: 124.7511, Step: 1000\n",
      "Loss: 0.0051, Acc: 1.0000, Time: 242.6735, Step: 2000\n",
      "Loss: 0.0002, Acc: 1.0000, Time: 356.9884, Step: 3000\n",
      "Loss: 0.5286, Acc: 0.9200, Time: 430.3041, Step: 3632\n",
      "fold_3 - Epoch 4, Precision: 0.9733, Recall: 0.9821, F1: 0.9777\n",
      "Loss: 0.0004, Acc: 1.0000, Time: 61.8093, Step: 758\n",
      "fold_3 - Epoch 4, Precision: 0.8345, Recall: 0.8435, F1: 0.8390\n",
      "Writing fold_3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0643, Acc: 1.0000, Time: 123.6233, Step: 1000\n",
      "Loss: 0.0293, Acc: 1.0000, Time: 245.8858, Step: 2000\n",
      "Loss: 0.0194, Acc: 1.0000, Time: 367.9636, Step: 3000\n",
      "Loss: 0.8547, Acc: 0.8667, Time: 418.9395, Step: 3419\n",
      "fold_4 - Epoch 0, Precision: 0.8740, Recall: 0.9160, F1: 0.8945\n",
      "Loss: 0.0001, Acc: 1.0000, Time: 71.9694, Step: 971\n",
      "fold_4 - Epoch 0, Precision: 0.9024, Recall: 0.9431, F1: 0.9223\n",
      "Loss: 0.0643, Acc: 1.0000, Time: 122.6884, Step: 1000\n",
      "Loss: 0.0348, Acc: 1.0000, Time: 244.4384, Step: 2000\n",
      "Loss: 0.0010, Acc: 1.0000, Time: 365.9124, Step: 3000\n",
      "Loss: 0.0003, Acc: 1.0000, Time: 416.6621, Step: 3419\n",
      "fold_4 - Epoch 1, Precision: 0.9523, Recall: 0.9636, F1: 0.9579\n",
      "Loss: 0.0000, Acc: 1.0000, Time: 71.4247, Step: 971\n",
      "fold_4 - Epoch 1, Precision: 0.9475, Recall: 0.7862, F1: 0.8593\n",
      "Loss: 0.0708, Acc: 1.0000, Time: 121.0148, Step: 1000\n",
      "Loss: 0.0607, Acc: 1.0000, Time: 243.3112, Step: 2000\n",
      "Loss: 0.0224, Acc: 1.0000, Time: 366.4818, Step: 3000\n",
      "Loss: 0.0018, Acc: 1.0000, Time: 416.9944, Step: 3419\n",
      "fold_4 - Epoch 2, Precision: 0.9613, Recall: 0.9686, F1: 0.9649\n",
      "Loss: 0.0000, Acc: 1.0000, Time: 71.0544, Step: 971\n",
      "fold_4 - Epoch 2, Precision: 0.9029, Recall: 0.9159, F1: 0.9094\n",
      "Loss: 0.0020, Acc: 1.0000, Time: 122.2412, Step: 1000\n",
      "Loss: 0.0200, Acc: 1.0000, Time: 242.2239, Step: 2000\n",
      "Loss: 0.3360, Acc: 0.9733, Time: 365.3714, Step: 3000\n",
      "Loss: 0.0002, Acc: 1.0000, Time: 418.3601, Step: 3419\n",
      "fold_4 - Epoch 3, Precision: 0.9658, Recall: 0.9735, F1: 0.9696\n",
      "Loss: 0.0000, Acc: 1.0000, Time: 71.0964, Step: 971\n",
      "fold_4 - Epoch 3, Precision: 0.9279, Recall: 0.8123, F1: 0.8663\n",
      "Loss: 0.0109, Acc: 1.0000, Time: 122.6209, Step: 1000\n",
      "Loss: 0.0063, Acc: 1.0000, Time: 243.6861, Step: 2000\n",
      "Loss: 0.0004, Acc: 1.0000, Time: 366.0148, Step: 3000\n",
      "Loss: 0.0001, Acc: 1.0000, Time: 417.9257, Step: 3419\n",
      "fold_4 - Epoch 4, Precision: 0.9733, Recall: 0.9784, F1: 0.9758\n",
      "Loss: -0.0000, Acc: 1.0000, Time: 71.0174, Step: 971\n",
      "fold_4 - Epoch 4, Precision: 0.9229, Recall: 0.9144, F1: 0.9186\n",
      "Writing fold_4\n",
      "91.70%\t86.77%\t89.17%\t94.77%\t89.75%\t92.19%\t93.19%\t93.24%\t93.21%\t83.45%\t84.35%\t83.90%\t92.29%\t91.44%\t91.86%\t92.47%\t86.88%\t89.59%\t95.03%\t89.42%\t92.14%\t93.90%\t93.12%\t93.51%\t84.05%\t84.29%\t84.17%\t93.21%\t90.77%\t91.97%\t"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, os.path.realpath(os.path.pardir))\n",
    "\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from model.estimator import Estimator\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Disable debug logs Tensorflow.\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "estimator = Estimator()\n",
    "estimator.set_dataset_params({\n",
    "    'datadir': '../data/ner_on_html',\n",
    "    'dataset_mode': 'sentences',\n",
    "    \"model\": \"lstm_crf\",  \n",
    "    \"epochs\": 5,\n",
    "    \"batch_size\": 10,\n",
    "    \"use_features\": False,\n",
    "    \"word_embeddings\": \"elmo\",\n",
    "    \"char_representation\": \"lstm\",\n",
    "    \"decoder\": \"crf\",  \n",
    "    # \"loss\": \"cross_entropy\"\n",
    "})\n",
    "estimator.train_cv()\n",
    "\n",
    "!cd .. && ./eval_model.sh\n",
    "!mkdir -p ../results/cross_validation/lstm_crf_elmo\n",
    "!mv ../results/score/fold* ../results/cross_validation/lstm_crf_elmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold size: 29\n",
      "(35214, 300)\n",
      "Loss: 1.2083, Acc: 0.9759, Time: 72.0324, Step: 1000\n",
      "Loss: 0.0967, Acc: 1.0000, Time: 139.2430, Step: 2000\n",
      "Loss: 0.6713, Acc: 0.9818, Time: 201.1569, Step: 3000\n",
      "Loss: 0.0024, Acc: 1.0000, Time: 227.0417, Step: 3395\n",
      "fold_0 - Epoch 0, Precision: 0.8549, Recall: 0.8824, F1: 0.8684\n",
      "Loss: 0.1735, Acc: 1.0000, Time: 34.5421, Step: 995\n",
      "fold_0 - Epoch 0, Precision: 0.9307, Recall: 0.9481, F1: 0.9393\n",
      "Loss: 0.0007, Acc: 1.0000, Time: 70.0688, Step: 1000\n",
      "Loss: 0.2897, Acc: 0.9714, Time: 137.5691, Step: 2000\n",
      "Loss: 0.0082, Acc: 1.0000, Time: 201.5033, Step: 3000\n",
      "Loss: 0.0026, Acc: 1.0000, Time: 225.4529, Step: 3395\n",
      "fold_0 - Epoch 1, Precision: 0.9486, Recall: 0.9560, F1: 0.9523\n",
      "Loss: 0.0404, Acc: 1.0000, Time: 34.5108, Step: 995\n",
      "fold_0 - Epoch 1, Precision: 0.9346, Recall: 0.9527, F1: 0.9436\n",
      "Loss: 0.0011, Acc: 1.0000, Time: 70.6903, Step: 1000\n",
      "Loss: 0.0017, Acc: 1.0000, Time: 137.4134, Step: 2000\n",
      "Loss: 0.3458, Acc: 0.9750, Time: 199.6181, Step: 3000\n",
      "Loss: 0.0011, Acc: 1.0000, Time: 224.7109, Step: 3395\n",
      "fold_0 - Epoch 2, Precision: 0.9628, Recall: 0.9687, F1: 0.9657\n",
      "Loss: 0.2110, Acc: 0.9722, Time: 34.3194, Step: 995\n",
      "fold_0 - Epoch 2, Precision: 0.9239, Recall: 0.9601, F1: 0.9416\n",
      "Loss: 0.0015, Acc: 1.0000, Time: 69.9521, Step: 1000\n",
      "Loss: 0.0547, Acc: 1.0000, Time: 136.5182, Step: 2000\n",
      "Loss: 0.0083, Acc: 1.0000, Time: 200.0021, Step: 3000\n",
      "Loss: 0.0026, Acc: 1.0000, Time: 225.3206, Step: 3395\n",
      "fold_0 - Epoch 3, Precision: 0.9710, Recall: 0.9750, F1: 0.9730\n",
      "Loss: 0.0506, Acc: 1.0000, Time: 34.2702, Step: 995\n",
      "fold_0 - Epoch 3, Precision: 0.9294, Recall: 0.9539, F1: 0.9415\n",
      "Loss: 0.1812, Acc: 0.9944, Time: 69.9482, Step: 1000\n",
      "Loss: 1.1619, Acc: 0.9727, Time: 136.8810, Step: 2000\n",
      "Loss: 0.0787, Acc: 0.9909, Time: 200.6342, Step: 3000\n",
      "Loss: 0.0168, Acc: 1.0000, Time: 225.3643, Step: 3395\n",
      "fold_0 - Epoch 4, Precision: 0.9764, Recall: 0.9817, F1: 0.9790\n",
      "Loss: 0.6300, Acc: 0.9444, Time: 34.4470, Step: 995\n",
      "fold_0 - Epoch 4, Precision: 0.9410, Recall: 0.9512, F1: 0.9460\n",
      "Writing fold_0\n",
      "(35214, 300)\n",
      "Loss: 0.3439, Acc: 0.9857, Time: 72.9321, Step: 1000\n",
      "Loss: 0.4235, Acc: 0.9941, Time: 139.2603, Step: 2000\n",
      "Loss: 0.0308, Acc: 1.0000, Time: 202.5658, Step: 3000\n",
      "Loss: 0.0238, Acc: 1.0000, Time: 234.4805, Step: 3483\n",
      "fold_1 - Epoch 0, Precision: 0.7501, Recall: 0.8476, F1: 0.7959\n",
      "Loss: 0.0004, Acc: 1.0000, Time: 30.2696, Step: 907\n",
      "fold_1 - Epoch 0, Precision: 0.9329, Recall: 0.9181, F1: 0.9255\n",
      "Loss: 0.1618, Acc: 0.9957, Time: 71.4127, Step: 1000\n",
      "Loss: 0.1022, Acc: 0.9875, Time: 140.1033, Step: 2000\n",
      "Loss: 0.1300, Acc: 0.9667, Time: 203.5050, Step: 3000\n",
      "Loss: 0.0061, Acc: 1.0000, Time: 233.5622, Step: 3483\n",
      "fold_1 - Epoch 1, Precision: 0.9391, Recall: 0.9535, F1: 0.9463\n",
      "Loss: 0.0016, Acc: 1.0000, Time: 29.9114, Step: 907\n",
      "fold_1 - Epoch 1, Precision: 0.9446, Recall: 0.9378, F1: 0.9411\n",
      "Loss: 0.0465, Acc: 1.0000, Time: 69.6447, Step: 1000\n",
      "Loss: 0.0021, Acc: 1.0000, Time: 138.2807, Step: 2000\n",
      "Loss: 0.0010, Acc: 1.0000, Time: 203.2011, Step: 3000\n",
      "Loss: 0.0044, Acc: 1.0000, Time: 233.9783, Step: 3483\n",
      "fold_1 - Epoch 2, Precision: 0.9587, Recall: 0.9664, F1: 0.9625\n",
      "Loss: 0.0003, Acc: 1.0000, Time: 29.9029, Step: 907\n",
      "fold_1 - Epoch 2, Precision: 0.9634, Recall: 0.9454, F1: 0.9543\n",
      "Loss: 0.0040, Acc: 1.0000, Time: 71.7897, Step: 1000\n",
      "Loss: 0.0029, Acc: 1.0000, Time: 139.8371, Step: 2000\n",
      "Loss: 0.0069, Acc: 1.0000, Time: 204.5065, Step: 3000\n",
      "Loss: 0.0006, Acc: 1.0000, Time: 234.5533, Step: 3483\n",
      "fold_1 - Epoch 3, Precision: 0.9679, Recall: 0.9744, F1: 0.9712\n",
      "Loss: 0.0005, Acc: 1.0000, Time: 29.8964, Step: 907\n",
      "fold_1 - Epoch 3, Precision: 0.9505, Recall: 0.9196, F1: 0.9348\n",
      "Loss: 0.0249, Acc: 1.0000, Time: 71.0134, Step: 1000\n",
      "Loss: 0.0259, Acc: 1.0000, Time: 138.6288, Step: 2000\n",
      "Loss: 0.0010, Acc: 1.0000, Time: 203.6883, Step: 3000\n",
      "Loss: 0.0202, Acc: 1.0000, Time: 233.7486, Step: 3483\n",
      "fold_1 - Epoch 4, Precision: 0.9708, Recall: 0.9768, F1: 0.9738\n",
      "Loss: 0.0009, Acc: 1.0000, Time: 29.9499, Step: 907\n",
      "fold_1 - Epoch 4, Precision: 0.9596, Recall: 0.9435, F1: 0.9515\n",
      "Writing fold_1\n",
      "(35214, 300)\n",
      "Loss: 0.0940, Acc: 1.0000, Time: 68.8674, Step: 1000\n",
      "Loss: 0.0748, Acc: 1.0000, Time: 134.5772, Step: 2000\n",
      "Loss: 0.0319, Acc: 1.0000, Time: 198.5716, Step: 3000\n",
      "Loss: 0.0004, Acc: 1.0000, Time: 236.4111, Step: 3631\n",
      "fold_2 - Epoch 0, Precision: 0.8216, Recall: 0.8821, F1: 0.8508\n",
      "Loss: 0.0000, Acc: 1.0000, Time: 27.5565, Step: 759\n",
      "fold_2 - Epoch 0, Precision: 0.9175, Recall: 0.8990, F1: 0.9082\n",
      "Loss: 0.0073, Acc: 1.0000, Time: 67.9696, Step: 1000\n",
      "Loss: 0.0003, Acc: 1.0000, Time: 133.5203, Step: 2000\n",
      "Loss: 0.0093, Acc: 1.0000, Time: 195.6496, Step: 3000\n",
      "Loss: 0.0006, Acc: 1.0000, Time: 235.0855, Step: 3631\n",
      "fold_2 - Epoch 1, Precision: 0.9453, Recall: 0.9557, F1: 0.9505\n",
      "Loss: 0.0000, Acc: 1.0000, Time: 27.1664, Step: 759\n",
      "fold_2 - Epoch 1, Precision: 0.8986, Recall: 0.9172, F1: 0.9078\n",
      "Loss: 0.0011, Acc: 1.0000, Time: 68.0747, Step: 1000\n",
      "Loss: 0.0077, Acc: 1.0000, Time: 134.3159, Step: 2000\n",
      "Loss: 0.0347, Acc: 1.0000, Time: 196.8701, Step: 3000\n",
      "Loss: 0.0015, Acc: 1.0000, Time: 235.3485, Step: 3631\n",
      "fold_2 - Epoch 2, Precision: 0.9628, Recall: 0.9706, F1: 0.9667\n",
      "Loss: 0.0000, Acc: 1.0000, Time: 27.1268, Step: 759\n",
      "fold_2 - Epoch 2, Precision: 0.9086, Recall: 0.9212, F1: 0.9149\n",
      "Loss: 0.0016, Acc: 1.0000, Time: 67.8492, Step: 1000\n",
      "Loss: 0.0407, Acc: 1.0000, Time: 133.6564, Step: 2000\n",
      "Loss: 0.0009, Acc: 1.0000, Time: 197.2320, Step: 3000\n",
      "Loss: 0.0048, Acc: 1.0000, Time: 235.5919, Step: 3631\n",
      "fold_2 - Epoch 3, Precision: 0.9695, Recall: 0.9749, F1: 0.9722\n",
      "Loss: 0.0000, Acc: 1.0000, Time: 27.2195, Step: 759\n",
      "fold_2 - Epoch 3, Precision: 0.9074, Recall: 0.9079, F1: 0.9077\n",
      "Loss: 0.0028, Acc: 1.0000, Time: 68.0466, Step: 1000\n",
      "Loss: 0.0136, Acc: 1.0000, Time: 134.1937, Step: 2000\n",
      "Loss: 0.0181, Acc: 1.0000, Time: 196.1053, Step: 3000\n",
      "Loss: 0.0014, Acc: 1.0000, Time: 235.7103, Step: 3631\n",
      "fold_2 - Epoch 4, Precision: 0.9727, Recall: 0.9776, F1: 0.9751\n",
      "Loss: 0.0000, Acc: 1.0000, Time: 27.2181, Step: 759\n",
      "fold_2 - Epoch 4, Precision: 0.9162, Recall: 0.9212, F1: 0.9187\n",
      "Writing fold_2\n",
      "(35214, 300)\n",
      "Loss: 0.0524, Acc: 1.0000, Time: 72.3133, Step: 1000\n",
      "Loss: 0.0228, Acc: 1.0000, Time: 142.1807, Step: 2000\n",
      "Loss: 0.0466, Acc: 1.0000, Time: 205.5601, Step: 3000\n",
      "Loss: 0.2762, Acc: 0.9500, Time: 238.7533, Step: 3509\n",
      "fold_3 - Epoch 0, Precision: 0.8460, Recall: 0.8877, F1: 0.8664\n",
      "Loss: 0.0064, Acc: 1.0000, Time: 27.5774, Step: 881\n",
      "fold_3 - Epoch 0, Precision: 0.8109, Recall: 0.8387, F1: 0.8245\n",
      "Loss: 0.0046, Acc: 1.0000, Time: 71.1969, Step: 1000\n",
      "Loss: 0.0157, Acc: 1.0000, Time: 139.7575, Step: 2000\n",
      "Loss: 0.0245, Acc: 1.0000, Time: 205.5963, Step: 3000\n",
      "Loss: 0.0019, Acc: 1.0000, Time: 238.1678, Step: 3509\n",
      "fold_3 - Epoch 1, Precision: 0.9560, Recall: 0.9656, F1: 0.9608\n",
      "Loss: 0.0008, Acc: 1.0000, Time: 27.3981, Step: 881\n",
      "fold_3 - Epoch 1, Precision: 0.8526, Recall: 0.8420, F1: 0.8473\n",
      "Loss: 0.0070, Acc: 1.0000, Time: 70.9153, Step: 1000\n",
      "Loss: 0.0012, Acc: 1.0000, Time: 140.9354, Step: 2000\n",
      "Loss: 0.0448, Acc: 1.0000, Time: 206.8072, Step: 3000\n",
      "Loss: 0.0030, Acc: 1.0000, Time: 239.4400, Step: 3509\n",
      "fold_3 - Epoch 2, Precision: 0.9650, Recall: 0.9722, F1: 0.9686\n",
      "Loss: 0.0001, Acc: 1.0000, Time: 27.1717, Step: 881\n",
      "fold_3 - Epoch 2, Precision: 0.8406, Recall: 0.8480, F1: 0.8443\n",
      "Loss: 0.0388, Acc: 1.0000, Time: 70.5698, Step: 1000\n",
      "Loss: 0.0009, Acc: 1.0000, Time: 139.5989, Step: 2000\n",
      "Loss: 0.1151, Acc: 0.9800, Time: 205.7650, Step: 3000\n",
      "Loss: 0.0014, Acc: 1.0000, Time: 238.5241, Step: 3509\n",
      "fold_3 - Epoch 3, Precision: 0.9722, Recall: 0.9755, F1: 0.9739\n",
      "Loss: 0.0001, Acc: 1.0000, Time: 27.5060, Step: 881\n",
      "fold_3 - Epoch 3, Precision: 0.8377, Recall: 0.8747, F1: 0.8558\n",
      "Loss: 0.0856, Acc: 0.9867, Time: 71.2931, Step: 1000\n",
      "Loss: 0.0067, Acc: 1.0000, Time: 139.8553, Step: 2000\n",
      "Loss: 0.0079, Acc: 1.0000, Time: 204.4369, Step: 3000\n",
      "Loss: 0.0037, Acc: 1.0000, Time: 239.0452, Step: 3509\n",
      "fold_3 - Epoch 4, Precision: 0.9763, Recall: 0.9793, F1: 0.9778\n",
      "Loss: 0.0001, Acc: 1.0000, Time: 27.1597, Step: 881\n",
      "fold_3 - Epoch 4, Precision: 0.8434, Recall: 0.8365, F1: 0.8399\n",
      "Writing fold_3\n",
      "(35214, 300)\n",
      "Loss: 0.2226, Acc: 1.0000, Time: 71.5096, Step: 1000\n",
      "Loss: 0.0116, Acc: 1.0000, Time: 138.5507, Step: 2000\n",
      "Loss: 0.1398, Acc: 0.9875, Time: 201.4100, Step: 3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1035, Acc: 1.0000, Time: 234.7522, Step: 3537\n",
      "fold_4 - Epoch 0, Precision: 0.8973, Recall: 0.9085, F1: 0.9029\n",
      "Loss: 0.0011, Acc: 1.0000, Time: 27.8724, Step: 853\n",
      "fold_4 - Epoch 0, Precision: 0.8271, Recall: 0.9678, F1: 0.8919\n",
      "Loss: 0.0004, Acc: 1.0000, Time: 70.7192, Step: 1000\n",
      "Loss: 0.0260, Acc: 1.0000, Time: 135.8408, Step: 2000\n",
      "Loss: 0.1739, Acc: 0.9842, Time: 198.8692, Step: 3000\n",
      "Loss: 0.0014, Acc: 1.0000, Time: 233.4605, Step: 3537\n",
      "fold_4 - Epoch 1, Precision: 0.9545, Recall: 0.9620, F1: 0.9583\n",
      "Loss: 0.0004, Acc: 1.0000, Time: 27.3897, Step: 853\n",
      "fold_4 - Epoch 1, Precision: 0.8437, Recall: 0.9633, F1: 0.8996\n",
      "Loss: 0.0004, Acc: 1.0000, Time: 72.1640, Step: 1000\n",
      "Loss: 0.0015, Acc: 1.0000, Time: 136.4272, Step: 2000\n",
      "Loss: 0.0060, Acc: 1.0000, Time: 198.7079, Step: 3000\n",
      "Loss: 0.0009, Acc: 1.0000, Time: 233.3336, Step: 3537\n",
      "fold_4 - Epoch 2, Precision: 0.9672, Recall: 0.9742, F1: 0.9707\n",
      "Loss: 0.0000, Acc: 1.0000, Time: 27.4816, Step: 853\n",
      "fold_4 - Epoch 2, Precision: 0.8377, Recall: 0.9555, F1: 0.8928\n",
      "Loss: 0.0014, Acc: 1.0000, Time: 71.7895, Step: 1000\n",
      "Loss: 0.0002, Acc: 1.0000, Time: 138.8852, Step: 2000\n",
      "Loss: 0.0119, Acc: 1.0000, Time: 201.0406, Step: 3000\n",
      "Loss: 0.0005, Acc: 1.0000, Time: 234.5247, Step: 3537\n",
      "fold_4 - Epoch 3, Precision: 0.9739, Recall: 0.9782, F1: 0.9760\n",
      "Loss: 0.0000, Acc: 1.0000, Time: 27.3792, Step: 853\n",
      "fold_4 - Epoch 3, Precision: 0.8541, Recall: 0.9694, F1: 0.9081\n",
      "Loss: 0.0006, Acc: 1.0000, Time: 71.2871, Step: 1000\n",
      "Loss: 0.0000, Acc: 1.0000, Time: 136.5397, Step: 2000\n",
      "Loss: 0.0027, Acc: 1.0000, Time: 199.6072, Step: 3000\n",
      "Loss: 0.0017, Acc: 1.0000, Time: 233.4570, Step: 3537\n",
      "fold_4 - Epoch 4, Precision: 0.9788, Recall: 0.9813, F1: 0.9800\n",
      "Loss: 0.0000, Acc: 1.0000, Time: 27.4732, Step: 853\n",
      "fold_4 - Epoch 4, Precision: 0.8370, Recall: 0.9644, F1: 0.8962\n",
      "Writing fold_4\n",
      "94.10%\t95.12%\t94.60%\t95.96%\t94.35%\t95.15%\t91.62%\t92.12%\t91.87%\t84.34%\t83.65%\t83.99%\t83.70%\t96.44%\t89.62%\t94.11%\t94.81%\t94.46%\t96.33%\t94.21%\t95.26%\t92.22%\t92.22%\t92.22%\t90.08%\t83.11%\t86.45%\t84.54%\t96.39%\t90.08%\t"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, os.path.realpath(os.path.pardir))\n",
    "\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from model.estimator import Estimator\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Disable debug logs Tensorflow.\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "estimator = Estimator()\n",
    "estimator.set_dataset_params({\n",
    "    'datadir': '../data/ner_on_html',\n",
    "    'dataset_mode': 'sentences',\n",
    "    \"model\": \"lstm_crf\",  \n",
    "    \"epochs\": 5,\n",
    "    \"batch_size\": 10,\n",
    "    \"use_features\": False,\n",
    "    \"word_embeddings\": \"glove\",\n",
    "    \"char_representation\": \"lstm\",\n",
    "    \"decoder\": \"crf\",  \n",
    "    # \"loss\": \"cross_entropy\"\n",
    "})\n",
    "estimator.train_cv()\n",
    "\n",
    "!cd .. && ./eval_model.sh\n",
    "!mkdir -p ../results/cross_validation/lstm_crf_elmo\n",
    "!mv ../results/score/fold* ../results/cross_validation/lstm_crf_elmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_hub\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/64/3bba86ca49ef21a4add11a4d37e3f6cd05d2e61d207ebe26a8a96b340826/tensorflow_hub-0.6.0-py2.py3-none-any.whl (84kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 3.9MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub) (1.16.4)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub) (3.8.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/lib/python3/dist-packages (from tensorflow_hub) (1.11.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow_hub) (41.0.1)\n",
      "Installing collected packages: tensorflow-hub\n",
      "Successfully installed tensorflow-hub-0.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold size: 29\n",
      "(35214, 300)\n",
      "Loss: 1.9628, Acc: 0.9744, Time: 98.0547, Step: 1000\n",
      "Loss: 2.6747, Acc: 0.9787, Time: 193.7262, Step: 2000\n",
      "Loss: 0.0388, Acc: 1.0000, Time: 294.3540, Step: 3000\n",
      "Loss: 0.0649, Acc: 1.0000, Time: 317.3380, Step: 3242\n",
      "fold_0 - Epoch 0, Precision: 0.7888, Recall: 0.7978, F1: 0.7933\n",
      "Loss: 0.1288, Acc: 1.0000, Time: 12.4614, Step: 750\n",
      "fold_0 - Epoch 0, Precision: 0.8771, Recall: 0.9227, F1: 0.8993\n",
      "Loss: 0.2960, Acc: 1.0000, Time: 115.3201, Step: 1000\n",
      "Loss: 0.8341, Acc: 0.9828, Time: 226.1763, Step: 2000\n",
      "Loss: 0.0795, Acc: 1.0000, Time: 337.5121, Step: 3000\n",
      "Loss: 0.1602, Acc: 1.0000, Time: 362.9861, Step: 3242\n",
      "fold_0 - Epoch 1, Precision: 0.9189, Recall: 0.9247, F1: 0.9218\n",
      "Loss: 0.0850, Acc: 1.0000, Time: 12.0796, Step: 750\n",
      "fold_0 - Epoch 1, Precision: 0.8820, Recall: 0.9000, F1: 0.8909\n",
      "Loss: 0.0241, Acc: 1.0000, Time: 100.8367, Step: 1000\n",
      "Loss: 0.0329, Acc: 1.0000, Time: 199.1742, Step: 2000\n",
      "Loss: 0.5482, Acc: 1.0000, Time: 299.4331, Step: 3000\n",
      "Loss: 0.0084, Acc: 1.0000, Time: 324.3930, Step: 3242\n",
      "fold_0 - Epoch 2, Precision: 0.9321, Recall: 0.9307, F1: 0.9314\n",
      "Loss: 0.0062, Acc: 1.0000, Time: 12.3298, Step: 750\n",
      "fold_0 - Epoch 2, Precision: 0.9124, Recall: 0.9094, F1: 0.9109\n",
      "Loss: 3.0521, Acc: 0.9683, Time: 109.3306, Step: 1000\n",
      "Loss: 0.1990, Acc: 1.0000, Time: 207.4110, Step: 2000\n",
      "Loss: 0.0053, Acc: 1.0000, Time: 304.2654, Step: 3000\n",
      "Loss: 0.1203, Acc: 1.0000, Time: 327.6428, Step: 3242\n",
      "fold_0 - Epoch 3, Precision: 0.9413, Recall: 0.9425, F1: 0.9419\n",
      "Loss: 0.0056, Acc: 1.0000, Time: 12.5110, Step: 750\n",
      "fold_0 - Epoch 3, Precision: 0.9124, Recall: 0.9155, F1: 0.9140\n",
      "Loss: 0.2956, Acc: 1.0000, Time: 110.0750, Step: 1000\n",
      "Loss: 0.0385, Acc: 1.0000, Time: 216.6274, Step: 2000\n",
      "Loss: 0.0192, Acc: 1.0000, Time: 329.3500, Step: 3000\n",
      "Loss: 0.0337, Acc: 1.0000, Time: 353.2608, Step: 3242\n",
      "fold_0 - Epoch 4, Precision: 0.9502, Recall: 0.9478, F1: 0.9490\n",
      "Loss: 0.0073, Acc: 1.0000, Time: 12.1599, Step: 750\n",
      "fold_0 - Epoch 4, Precision: 0.8957, Recall: 0.9110, F1: 0.9033\n",
      "Writing fold_0\n",
      "(35214, 300)\n",
      "Loss: 1.1362, Acc: 1.0000, Time: 121.3327, Step: 1000\n",
      "Loss: 1.5423, Acc: 1.0000, Time: 223.5925, Step: 2000\n",
      "Loss: 5.4782, Acc: 0.9697, Time: 323.8819, Step: 3000\n",
      "Loss: 0.3661, Acc: 1.0000, Time: 348.2637, Step: 3253\n",
      "fold_1 - Epoch 0, Precision: 0.7395, Recall: 0.7835, F1: 0.7609\n",
      "Loss: 0.0086, Acc: 1.0000, Time: 12.8981, Step: 739\n",
      "fold_1 - Epoch 0, Precision: 0.8667, Recall: 0.8600, F1: 0.8633\n",
      "Loss: 0.1101, Acc: 1.0000, Time: 99.7369, Step: 1000\n",
      "Loss: 1.0387, Acc: 0.9846, Time: 195.1877, Step: 2000\n",
      "Loss: 0.0332, Acc: 1.0000, Time: 305.7371, Step: 3000\n",
      "Loss: 0.0538, Acc: 1.0000, Time: 332.2374, Step: 3253\n",
      "fold_1 - Epoch 1, Precision: 0.9156, Recall: 0.9189, F1: 0.9172\n",
      "Loss: 0.0114, Acc: 1.0000, Time: 12.8945, Step: 739\n",
      "fold_1 - Epoch 1, Precision: 0.9089, Recall: 0.9109, F1: 0.9099\n",
      "Loss: 0.0447, Acc: 1.0000, Time: 114.1040, Step: 1000\n",
      "Loss: 0.4427, Acc: 1.0000, Time: 218.9714, Step: 2000\n",
      "Loss: 4.8485, Acc: 0.9333, Time: 320.3177, Step: 3000\n",
      "Loss: 0.4096, Acc: 1.0000, Time: 344.5432, Step: 3253\n",
      "fold_1 - Epoch 2, Precision: 0.9317, Recall: 0.9340, F1: 0.9329\n",
      "Loss: 0.0123, Acc: 1.0000, Time: 12.5011, Step: 739\n",
      "fold_1 - Epoch 2, Precision: 0.8898, Recall: 0.9355, F1: 0.9120\n",
      "Loss: 0.0379, Acc: 1.0000, Time: 100.8045, Step: 1000\n",
      "Loss: 1.4170, Acc: 0.9909, Time: 189.1583, Step: 2000\n",
      "Loss: 0.4293, Acc: 1.0000, Time: 290.3277, Step: 3000\n",
      "Loss: 0.0981, Acc: 1.0000, Time: 316.5643, Step: 3253\n",
      "fold_1 - Epoch 3, Precision: 0.9429, Recall: 0.9410, F1: 0.9419\n",
      "Loss: 0.0005, Acc: 1.0000, Time: 12.9821, Step: 739\n",
      "fold_1 - Epoch 3, Precision: 0.9055, Recall: 0.9060, F1: 0.9057\n",
      "Loss: 0.0538, Acc: 1.0000, Time: 111.4077, Step: 1000\n",
      "Loss: 0.1453, Acc: 1.0000, Time: 215.7870, Step: 2000\n",
      "Loss: 0.0663, Acc: 1.0000, Time: 312.5061, Step: 3000\n",
      "Loss: 1.3232, Acc: 0.9615, Time: 339.6611, Step: 3253\n",
      "fold_1 - Epoch 4, Precision: 0.9476, Recall: 0.9466, F1: 0.9471\n",
      "Loss: 0.0016, Acc: 1.0000, Time: 12.7462, Step: 739\n",
      "fold_1 - Epoch 4, Precision: 0.9303, Recall: 0.8688, F1: 0.8985\n",
      "Writing fold_1\n",
      "(35214, 300)\n",
      "Loss: 1.1350, Acc: 0.9839, Time: 99.1010, Step: 1000\n",
      "Loss: 1.7180, Acc: 1.0000, Time: 191.7350, Step: 2000\n",
      "Loss: 0.2609, Acc: 1.0000, Time: 282.9640, Step: 3000\n",
      "Loss: 1.8933, Acc: 0.9559, Time: 313.9116, Step: 3345\n",
      "fold_2 - Epoch 0, Precision: 0.8459, Recall: 0.8209, F1: 0.8332\n",
      "Loss: 0.3079, Acc: 1.0000, Time: 9.4203, Step: 647\n",
      "fold_2 - Epoch 0, Precision: 0.9004, Recall: 0.9270, F1: 0.9135\n",
      "Loss: 6.4413, Acc: 0.9508, Time: 94.9502, Step: 1000\n",
      "Loss: 0.0723, Acc: 1.0000, Time: 190.0919, Step: 2000\n",
      "Loss: 8.2814, Acc: 0.8947, Time: 280.3317, Step: 3000\n",
      "Loss: 0.3227, Acc: 1.0000, Time: 312.5674, Step: 3345\n",
      "fold_2 - Epoch 1, Precision: 0.9221, Recall: 0.9207, F1: 0.9214\n",
      "Loss: 0.2166, Acc: 1.0000, Time: 9.2544, Step: 647\n",
      "fold_2 - Epoch 1, Precision: 0.8876, Recall: 0.9184, F1: 0.9027\n",
      "Loss: 0.2759, Acc: 1.0000, Time: 101.3191, Step: 1000\n",
      "Loss: 3.5211, Acc: 0.9889, Time: 199.5289, Step: 2000\n",
      "Loss: 0.0609, Acc: 1.0000, Time: 297.8917, Step: 3000\n",
      "Loss: 1.5330, Acc: 0.9710, Time: 332.4033, Step: 3345\n",
      "fold_2 - Epoch 2, Precision: 0.9376, Recall: 0.9398, F1: 0.9387\n",
      "Loss: 0.3367, Acc: 1.0000, Time: 9.2922, Step: 647\n",
      "fold_2 - Epoch 2, Precision: 0.8692, Recall: 0.9270, F1: 0.8972\n",
      "Loss: 0.2452, Acc: 1.0000, Time: 100.8632, Step: 1000\n",
      "Loss: 0.1058, Acc: 1.0000, Time: 200.6092, Step: 2000\n",
      "Loss: 1.7985, Acc: 0.9677, Time: 301.6583, Step: 3000\n",
      "Loss: 0.6743, Acc: 1.0000, Time: 334.8365, Step: 3345\n",
      "fold_2 - Epoch 3, Precision: 0.9490, Recall: 0.9466, F1: 0.9478\n",
      "Loss: 0.1187, Acc: 1.0000, Time: 9.2636, Step: 647\n",
      "fold_2 - Epoch 3, Precision: 0.8900, Recall: 0.9176, F1: 0.9036\n",
      "Loss: 1.2404, Acc: 0.9783, Time: 103.1690, Step: 1000\n",
      "Loss: 0.0753, Acc: 1.0000, Time: 204.2211, Step: 2000\n",
      "Loss: 0.3593, Acc: 1.0000, Time: 304.9896, Step: 3000\n",
      "Loss: 0.0018, Acc: 1.0000, Time: 338.7688, Step: 3345\n",
      "fold_2 - Epoch 4, Precision: 0.9510, Recall: 0.9502, F1: 0.9506\n",
      "Loss: 0.0936, Acc: 1.0000, Time: 9.3301, Step: 647\n",
      "fold_2 - Epoch 4, Precision: 0.8970, Recall: 0.8938, F1: 0.8954\n",
      "Writing fold_2\n",
      "(35214, 300)\n",
      "Loss: 0.8986, Acc: 1.0000, Time: 93.5493, Step: 1000\n",
      "Loss: 0.5431, Acc: 1.0000, Time: 181.9042, Step: 2000\n",
      "Loss: 1.7583, Acc: 0.9785, Time: 259.2326, Step: 2865\n",
      "fold_3 - Epoch 0, Precision: 0.7742, Recall: 0.7737, F1: 0.7739\n",
      "Loss: 0.6302, Acc: 1.0000, Time: 17.0335, Step: 1000\n",
      "Loss: 2.3951, Acc: 0.9057, Time: 19.1329, Step: 1127\n",
      "fold_3 - Epoch 0, Precision: 0.8765, Recall: 0.9331, F1: 0.9039\n",
      "Loss: 0.1338, Acc: 1.0000, Time: 89.9092, Step: 1000\n",
      "Loss: 0.3709, Acc: 1.0000, Time: 177.1498, Step: 2000\n",
      "Loss: 0.4136, Acc: 1.0000, Time: 253.2291, Step: 2865\n",
      "fold_3 - Epoch 1, Precision: 0.9079, Recall: 0.9085, F1: 0.9082\n",
      "Loss: 0.0466, Acc: 1.0000, Time: 16.9216, Step: 1000\n",
      "Loss: 3.1180, Acc: 0.9245, Time: 19.0591, Step: 1127\n",
      "fold_3 - Epoch 1, Precision: 0.9138, Recall: 0.9366, F1: 0.9251\n",
      "Loss: 0.0316, Acc: 1.0000, Time: 91.1187, Step: 1000\n",
      "Loss: 0.9205, Acc: 1.0000, Time: 181.3256, Step: 2000\n",
      "Loss: 0.0503, Acc: 1.0000, Time: 260.8980, Step: 2865\n",
      "fold_3 - Epoch 2, Precision: 0.9256, Recall: 0.9291, F1: 0.9273\n",
      "Loss: 0.0677, Acc: 1.0000, Time: 16.9737, Step: 1000\n",
      "Loss: 0.0966, Acc: 1.0000, Time: 19.1814, Step: 1127\n",
      "fold_3 - Epoch 2, Precision: 0.9278, Recall: 0.9477, F1: 0.9376\n",
      "Loss: 0.3614, Acc: 1.0000, Time: 103.9195, Step: 1000\n",
      "Loss: 0.7547, Acc: 0.9804, Time: 204.9379, Step: 2000\n",
      "Loss: 0.0605, Acc: 1.0000, Time: 301.2785, Step: 2865\n",
      "fold_3 - Epoch 3, Precision: 0.9351, Recall: 0.9362, F1: 0.9357\n",
      "Loss: 0.0223, Acc: 1.0000, Time: 17.6767, Step: 1000\n",
      "Loss: 0.7144, Acc: 1.0000, Time: 20.0235, Step: 1127\n",
      "fold_3 - Epoch 3, Precision: 0.9378, Recall: 0.9372, F1: 0.9375\n",
      "Loss: 0.5144, Acc: 1.0000, Time: 105.4300, Step: 1000\n",
      "Loss: 0.0233, Acc: 1.0000, Time: 200.0894, Step: 2000\n",
      "Loss: 0.0204, Acc: 1.0000, Time: 286.0475, Step: 2865\n",
      "fold_3 - Epoch 4, Precision: 0.9433, Recall: 0.9437, F1: 0.9435\n",
      "Loss: 0.0096, Acc: 1.0000, Time: 18.0887, Step: 1000\n",
      "Loss: 0.0367, Acc: 1.0000, Time: 20.2745, Step: 1127\n",
      "fold_3 - Epoch 4, Precision: 0.9428, Recall: 0.9417, F1: 0.9423\n",
      "Writing fold_3\n",
      "(35214, 300)\n",
      "Loss: 0.3291, Acc: 1.0000, Time: 95.2402, Step: 1000\n",
      "Loss: 0.6310, Acc: 1.0000, Time: 187.3563, Step: 2000\n",
      "Loss: 0.7148, Acc: 1.0000, Time: 282.3789, Step: 3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4971, Acc: 1.0000, Time: 307.8103, Step: 3260\n",
      "fold_4 - Epoch 0, Precision: 0.7559, Recall: 0.7878, F1: 0.7715\n",
      "Loss: 0.0005, Acc: 1.0000, Time: 13.1281, Step: 732\n",
      "fold_4 - Epoch 0, Precision: 0.8590, Recall: 0.9570, F1: 0.9054\n",
      "Loss: 0.3392, Acc: 1.0000, Time: 98.5181, Step: 1000\n",
      "Loss: 0.1683, Acc: 1.0000, Time: 194.2214, Step: 2000\n",
      "Loss: 0.2473, Acc: 1.0000, Time: 285.5459, Step: 3000\n",
      "Loss: 0.1999, Acc: 1.0000, Time: 309.0835, Step: 3260\n",
      "fold_4 - Epoch 1, Precision: 0.9267, Recall: 0.9306, F1: 0.9286\n",
      "Loss: 0.0001, Acc: 1.0000, Time: 12.9377, Step: 732\n",
      "fold_4 - Epoch 1, Precision: 0.8683, Recall: 0.9556, F1: 0.9099\n",
      "Loss: 0.5255, Acc: 1.0000, Time: 95.9114, Step: 1000\n",
      "Loss: 0.0238, Acc: 1.0000, Time: 191.3354, Step: 2000\n",
      "Loss: 0.4579, Acc: 1.0000, Time: 290.1121, Step: 3000\n",
      "Loss: 0.4949, Acc: 1.0000, Time: 315.1501, Step: 3260\n",
      "fold_4 - Epoch 2, Precision: 0.9453, Recall: 0.9448, F1: 0.9451\n",
      "Loss: 0.0011, Acc: 1.0000, Time: 13.4170, Step: 732\n",
      "fold_4 - Epoch 2, Precision: 0.8565, Recall: 0.9603, F1: 0.9054\n",
      "Loss: 0.0365, Acc: 1.0000, Time: 96.6071, Step: 1000\n",
      "Loss: 0.1340, Acc: 1.0000, Time: 198.8077, Step: 2000\n",
      "Loss: 0.0244, Acc: 1.0000, Time: 296.1829, Step: 3000\n",
      "Loss: 0.0192, Acc: 1.0000, Time: 324.0485, Step: 3260\n",
      "fold_4 - Epoch 3, Precision: 0.9496, Recall: 0.9476, F1: 0.9486\n",
      "Loss: 0.0003, Acc: 1.0000, Time: 14.0401, Step: 732\n",
      "fold_4 - Epoch 3, Precision: 0.8403, Recall: 0.9640, F1: 0.8979\n",
      "Loss: 0.0288, Acc: 1.0000, Time: 98.5594, Step: 1000\n",
      "Loss: 0.0166, Acc: 1.0000, Time: 192.2245, Step: 2000\n",
      "Loss: 0.0573, Acc: 1.0000, Time: 286.7612, Step: 3000\n",
      "Loss: 0.2791, Acc: 1.0000, Time: 311.2573, Step: 3260\n",
      "fold_4 - Epoch 4, Precision: 0.9520, Recall: 0.9506, F1: 0.9513\n",
      "Loss: 0.0003, Acc: 1.0000, Time: 13.5665, Step: 732\n",
      "fold_4 - Epoch 4, Precision: 0.8615, Recall: 0.9448, F1: 0.9012\n",
      "Writing fold_4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, os.path.realpath(os.path.pardir))\n",
    "\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from model.estimator import Estimator\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Disable debug logs Tensorflow.\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "estimator = Estimator()\n",
    "estimator.set_dataset_params({\n",
    "    'datadir': '../data/ner_on_html',\n",
    "    'dataset_mode': 'batch',\n",
    "    \"model\": \"html_attention\",  \n",
    "    \"epochs\": 5,\n",
    "    \"batch_size\": 1,\n",
    "    \"use_features\": False,\n",
    "    \"word_embeddings\": \"glove\",\n",
    "    \"char_representation\": \"lstm\",\n",
    "    \"decoder\": \"crf\",  \n",
    "    # \"loss\": \"cross_entropy\"\n",
    "})\n",
    "estimator.train_cv()\n",
    "\n",
    "# !cd .. && ./eval_model.sh\n",
    "# !mkdir -p ../results/cross_validation/hard_attention\n",
    "# !mv ../results/score/fold* ../results/cross_validation/hard_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.57%\t91.10%\t90.33%\t93.03%\t86.88%\t89.85%\t89.70%\t89.38%\t89.54%\t94.28%\t94.17%\t94.23%\t86.15%\t94.48%\t90.12%\t91.86%\t91.05%\t91.45%\t94.91%\t86.60%\t90.57%\t89.96%\t88.73%\t89.34%\t94.42%\t93.91%\t94.17%\t86.18%\t94.48%\t90.14%\t"
     ]
    }
   ],
   "source": [
    "!cd .. && ./eval_model.sh\n",
    "!mkdir -p ../results/cross_validation/hard_attention\n",
    "!mv ../results/score/fold* ../results/cross_validation/hard_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold size: 29\n",
      "(35214, 300)\n",
      "Loss: 2.8710, Acc: 0.9804, Time: 145.5309, Step: 1000\n",
      "Loss: 2.9154, Acc: 0.9841, Time: 278.7191, Step: 2000\n",
      "Loss: 0.1704, Acc: 1.0000, Time: 410.0929, Step: 3000\n",
      "Loss: 3.1611, Acc: 0.9683, Time: 448.5400, Step: 3298\n",
      "fold_0 - Epoch 0, Precision: 0.7853, Recall: 0.7334, F1: 0.7585\n",
      "Loss: 0.1966, Acc: 1.0000, Time: 13.4433, Step: 695\n",
      "fold_0 - Epoch 0, Precision: 0.8785, Recall: 0.8316, F1: 0.8544\n",
      "Loss: 0.7676, Acc: 1.0000, Time: 127.4067, Step: 1000\n",
      "Loss: 0.1115, Acc: 1.0000, Time: 256.2757, Step: 2000\n",
      "Loss: 0.3519, Acc: 1.0000, Time: 384.1930, Step: 3000\n",
      "Loss: 0.3518, Acc: 1.0000, Time: 419.2217, Step: 3298\n",
      "fold_0 - Epoch 1, Precision: 0.8883, Recall: 0.8886, F1: 0.8884\n",
      "Loss: 0.8136, Acc: 1.0000, Time: 13.9908, Step: 695\n",
      "fold_0 - Epoch 1, Precision: 0.8700, Recall: 0.8545, F1: 0.8622\n",
      "Loss: 1.3705, Acc: 1.0000, Time: 131.3167, Step: 1000\n",
      "Loss: 0.0074, Acc: 1.0000, Time: 258.5795, Step: 2000\n",
      "Loss: 0.1804, Acc: 1.0000, Time: 380.0249, Step: 3000\n",
      "Loss: 1.7701, Acc: 0.9792, Time: 423.7911, Step: 3298\n",
      "fold_0 - Epoch 2, Precision: 0.9101, Recall: 0.9094, F1: 0.9097\n",
      "Loss: 0.2488, Acc: 1.0000, Time: 14.4116, Step: 695\n",
      "fold_0 - Epoch 2, Precision: 0.9187, Recall: 0.8037, F1: 0.8573\n",
      "Loss: 0.0166, Acc: 1.0000, Time: 120.4702, Step: 1000\n",
      "Loss: 3.7410, Acc: 0.9592, Time: 242.6393, Step: 2000\n",
      "Loss: 0.6420, Acc: 1.0000, Time: 366.4115, Step: 3000\n",
      "Loss: 0.2109, Acc: 1.0000, Time: 404.2183, Step: 3298\n",
      "fold_0 - Epoch 3, Precision: 0.9219, Recall: 0.9207, F1: 0.9213\n",
      "Loss: 0.0437, Acc: 1.0000, Time: 14.6746, Step: 695\n",
      "fold_0 - Epoch 3, Precision: 0.8828, Recall: 0.8659, F1: 0.8743\n",
      "Loss: 0.6115, Acc: 1.0000, Time: 125.3371, Step: 1000\n",
      "Loss: 3.3753, Acc: 0.9818, Time: 239.1984, Step: 2000\n",
      "Loss: 0.3551, Acc: 1.0000, Time: 352.4161, Step: 3000\n",
      "Loss: 1.0251, Acc: 1.0000, Time: 385.4629, Step: 3298\n",
      "fold_0 - Epoch 4, Precision: 0.9249, Recall: 0.9256, F1: 0.9252\n",
      "Loss: 0.6633, Acc: 1.0000, Time: 13.5123, Step: 695\n",
      "fold_0 - Epoch 4, Precision: 0.8303, Recall: 0.8609, F1: 0.8453\n",
      "Writing fold_0\n",
      "(35214, 300)\n",
      "Loss: 3.1536, Acc: 0.9787, Time: 130.7835, Step: 1000\n",
      "Loss: 10.1813, Acc: 0.9200, Time: 261.6357, Step: 2000\n",
      "Loss: 1.4249, Acc: 0.9592, Time: 392.9357, Step: 3000\n",
      "Loss: 0.3615, Acc: 1.0000, Time: 443.3104, Step: 3373\n",
      "fold_1 - Epoch 0, Precision: 0.7263, Recall: 0.7671, F1: 0.7461\n",
      "Loss: 0.0000, Acc: 1.0000, Time: 15.7585, Step: 620\n",
      "fold_1 - Epoch 0, Precision: 0.8384, Recall: 0.9157, F1: 0.8753\n",
      "Loss: 0.2027, Acc: 1.0000, Time: 134.1767, Step: 1000\n",
      "Loss: 4.5310, Acc: 0.9636, Time: 268.0438, Step: 2000\n",
      "Loss: 0.8506, Acc: 1.0000, Time: 394.0750, Step: 3000\n",
      "Loss: 0.5916, Acc: 1.0000, Time: 438.1272, Step: 3373\n",
      "fold_1 - Epoch 1, Precision: 0.9079, Recall: 0.9182, F1: 0.9130\n",
      "Loss: -0.0000, Acc: 1.0000, Time: 16.0779, Step: 620\n",
      "fold_1 - Epoch 1, Precision: 0.8436, Recall: 0.9459, F1: 0.8918\n",
      "Loss: 0.7116, Acc: 1.0000, Time: 127.9479, Step: 1000\n",
      "Loss: 0.4484, Acc: 1.0000, Time: 245.5360, Step: 2000\n",
      "Loss: 0.3807, Acc: 1.0000, Time: 363.0376, Step: 3000\n",
      "Loss: 0.2479, Acc: 1.0000, Time: 403.6941, Step: 3373\n",
      "fold_1 - Epoch 2, Precision: 0.9207, Recall: 0.9282, F1: 0.9244\n",
      "Loss: -0.0000, Acc: 1.0000, Time: 15.3924, Step: 620\n",
      "fold_1 - Epoch 2, Precision: 0.8132, Recall: 0.9271, F1: 0.8664\n",
      "Loss: 0.0490, Acc: 1.0000, Time: 113.5254, Step: 1000\n",
      "Loss: 0.6528, Acc: 1.0000, Time: 226.8676, Step: 2000\n",
      "Loss: 0.1011, Acc: 1.0000, Time: 344.0914, Step: 3000\n",
      "Loss: 1.0034, Acc: 0.9524, Time: 388.8905, Step: 3373\n",
      "fold_1 - Epoch 3, Precision: 0.9317, Recall: 0.9416, F1: 0.9366\n",
      "Loss: 0.0000, Acc: 1.0000, Time: 16.0542, Step: 620\n",
      "fold_1 - Epoch 3, Precision: 0.8448, Recall: 0.9237, F1: 0.8825\n",
      "Loss: 0.0297, Acc: 1.0000, Time: 125.2862, Step: 1000\n",
      "Loss: 0.6158, Acc: 1.0000, Time: 247.5101, Step: 2000\n",
      "Loss: 14.5114, Acc: 0.9839, Time: 367.5898, Step: 3000\n",
      "Loss: 0.1435, Acc: 1.0000, Time: 412.8812, Step: 3373\n",
      "fold_1 - Epoch 4, Precision: 0.9290, Recall: 0.9326, F1: 0.9308\n",
      "Loss: -0.0000, Acc: 1.0000, Time: 17.6921, Step: 620\n",
      "fold_1 - Epoch 4, Precision: 0.8103, Recall: 0.9100, F1: 0.8573\n",
      "Writing fold_1\n",
      "(35214, 300)\n",
      "Loss: 1.1791, Acc: 0.9848, Time: 132.1337, Step: 1000\n",
      "Loss: 1.5212, Acc: 1.0000, Time: 260.2724, Step: 2000\n",
      "Loss: 1.0691, Acc: 1.0000, Time: 385.1200, Step: 3000\n",
      "Loss: 0.2751, Acc: 1.0000, Time: 401.7599, Step: 3126\n",
      "fold_2 - Epoch 0, Precision: 0.7675, Recall: 0.6910, F1: 0.7273\n",
      "Loss: 0.1554, Acc: 1.0000, Time: 17.9548, Step: 867\n",
      "fold_2 - Epoch 0, Precision: 0.9150, Recall: 0.9002, F1: 0.9076\n",
      "Loss: 0.2963, Acc: 1.0000, Time: 136.8711, Step: 1000\n",
      "Loss: 0.7856, Acc: 1.0000, Time: 267.6123, Step: 2000\n",
      "Loss: 0.5659, Acc: 1.0000, Time: 391.4098, Step: 3000\n",
      "Loss: 1.5723, Acc: 0.9683, Time: 409.5301, Step: 3126\n",
      "fold_2 - Epoch 1, Precision: 0.8909, Recall: 0.8830, F1: 0.8870\n",
      "Loss: 0.1420, Acc: 1.0000, Time: 18.3593, Step: 867\n",
      "fold_2 - Epoch 1, Precision: 0.9290, Recall: 0.9341, F1: 0.9316\n",
      "Loss: 3.9808, Acc: 0.9492, Time: 143.7773, Step: 1000\n",
      "Loss: 1.9459, Acc: 0.9828, Time: 284.7366, Step: 2000\n",
      "Loss: 0.4403, Acc: 1.0000, Time: 421.1699, Step: 3000\n",
      "Loss: 0.1155, Acc: 1.0000, Time: 437.5401, Step: 3126\n",
      "fold_2 - Epoch 2, Precision: 0.9105, Recall: 0.9111, F1: 0.9108\n",
      "Loss: 0.0287, Acc: 1.0000, Time: 17.0626, Step: 867\n",
      "fold_2 - Epoch 2, Precision: 0.9168, Recall: 0.9381, F1: 0.9273\n",
      "Loss: 0.4351, Acc: 1.0000, Time: 141.7775, Step: 1000\n",
      "Loss: 0.6577, Acc: 1.0000, Time: 279.0725, Step: 2000\n",
      "Loss: 0.3931, Acc: 1.0000, Time: 417.3944, Step: 3000\n",
      "Loss: 2.2889, Acc: 0.9535, Time: 434.7214, Step: 3126\n",
      "fold_2 - Epoch 3, Precision: 0.9178, Recall: 0.9183, F1: 0.9181\n",
      "Loss: 0.1371, Acc: 1.0000, Time: 17.2310, Step: 867\n",
      "fold_2 - Epoch 3, Precision: 0.9289, Recall: 0.9322, F1: 0.9305\n",
      "Loss: 0.4703, Acc: 1.0000, Time: 143.0962, Step: 1000\n",
      "Loss: 0.0785, Acc: 1.0000, Time: 279.7176, Step: 2000\n",
      "Loss: 0.8190, Acc: 1.0000, Time: 420.6034, Step: 3000\n",
      "Loss: 0.5449, Acc: 1.0000, Time: 437.6611, Step: 3126\n",
      "fold_2 - Epoch 4, Precision: 0.9288, Recall: 0.9329, F1: 0.9308\n",
      "Loss: 0.0274, Acc: 1.0000, Time: 17.8148, Step: 867\n",
      "fold_2 - Epoch 4, Precision: 0.9178, Recall: 0.9507, F1: 0.9340\n",
      "Writing fold_2\n",
      "(35214, 300)\n",
      "Loss: 14.6711, Acc: 0.8913, Time: 134.9065, Step: 1000\n",
      "Loss: 2.7414, Acc: 1.0000, Time: 264.0216, Step: 2000\n",
      "Loss: 5.6990, Acc: 0.9434, Time: 393.1315, Step: 3000\n",
      "Loss: 8.2228, Acc: 0.9333, Time: 430.7207, Step: 3196\n",
      "fold_3 - Epoch 0, Precision: 0.6053, Recall: 0.6959, F1: 0.6474\n",
      "Loss: 6.7256, Acc: 0.9756, Time: 24.1630, Step: 797\n",
      "fold_3 - Epoch 0, Precision: 0.9331, Recall: 0.9334, F1: 0.9333\n",
      "Loss: 1.2435, Acc: 1.0000, Time: 190.1001, Step: 1000\n",
      "Loss: 0.5232, Acc: 1.0000, Time: 374.7922, Step: 2000\n",
      "Loss: 0.2181, Acc: 1.0000, Time: 557.0154, Step: 3000\n",
      "Loss: 0.4667, Acc: 1.0000, Time: 592.0081, Step: 3196\n",
      "fold_3 - Epoch 1, Precision: 0.8924, Recall: 0.9119, F1: 0.9021\n",
      "Loss: 8.1472, Acc: 0.9756, Time: 16.9766, Step: 797\n",
      "fold_3 - Epoch 1, Precision: 0.9099, Recall: 0.9190, F1: 0.9144\n",
      "Loss: 0.0630, Acc: 1.0000, Time: 133.6588, Step: 1000\n",
      "Loss: 0.0830, Acc: 1.0000, Time: 257.6769, Step: 2000\n",
      "Loss: 0.6211, Acc: 1.0000, Time: 381.4905, Step: 3000\n",
      "Loss: 1.2197, Acc: 0.9500, Time: 404.0503, Step: 3196\n",
      "fold_3 - Epoch 2, Precision: 0.9103, Recall: 0.9224, F1: 0.9163\n",
      "Loss: 6.0888, Acc: 0.9756, Time: 14.9898, Step: 797\n",
      "fold_3 - Epoch 2, Precision: 0.9167, Recall: 0.9504, F1: 0.9332\n",
      "Loss: 1.5999, Acc: 1.0000, Time: 126.0915, Step: 1000\n",
      "Loss: 0.1680, Acc: 1.0000, Time: 252.4230, Step: 2000\n",
      "Loss: 0.3351, Acc: 1.0000, Time: 381.8111, Step: 3000\n",
      "Loss: 0.8293, Acc: 1.0000, Time: 407.4783, Step: 3196\n",
      "fold_3 - Epoch 3, Precision: 0.9158, Recall: 0.9289, F1: 0.9223\n",
      "Loss: 7.9492, Acc: 0.9756, Time: 15.5722, Step: 797\n",
      "fold_3 - Epoch 3, Precision: 0.9193, Recall: 0.9413, F1: 0.9301\n",
      "Loss: 0.3292, Acc: 1.0000, Time: 133.9342, Step: 1000\n",
      "Loss: 0.3043, Acc: 1.0000, Time: 258.4260, Step: 2000\n",
      "Loss: 0.1224, Acc: 1.0000, Time: 387.6067, Step: 3000\n",
      "Loss: 0.0001, Acc: 1.0000, Time: 414.3701, Step: 3196\n",
      "fold_3 - Epoch 4, Precision: 0.9325, Recall: 0.9438, F1: 0.9381\n",
      "Loss: 5.7597, Acc: 0.9756, Time: 16.5382, Step: 797\n",
      "fold_3 - Epoch 4, Precision: 0.9114, Recall: 0.9529, F1: 0.9317\n",
      "Writing fold_3\n",
      "(35214, 300)\n",
      "Loss: 1.7866, Acc: 1.0000, Time: 133.5341, Step: 1000\n",
      "Loss: 7.6642, Acc: 0.9206, Time: 264.2156, Step: 2000\n",
      "Loss: 0.8173, Acc: 1.0000, Time: 391.6082, Step: 2976\n",
      "fold_4 - Epoch 0, Precision: 0.6987, Recall: 0.7568, F1: 0.7266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1400, Acc: 1.0000, Time: 17.1708, Step: 1000\n",
      "Loss: 0.0426, Acc: 1.0000, Time: 17.4268, Step: 1017\n",
      "fold_4 - Epoch 0, Precision: 0.8827, Recall: 0.9409, F1: 0.9109\n",
      "Loss: 0.1817, Acc: 1.0000, Time: 128.1843, Step: 1000\n",
      "Loss: 0.2908, Acc: 1.0000, Time: 246.7436, Step: 2000\n",
      "Loss: 0.3685, Acc: 1.0000, Time: 359.9161, Step: 2976\n",
      "fold_4 - Epoch 1, Precision: 0.8979, Recall: 0.9121, F1: 0.9050\n",
      "Loss: 0.0713, Acc: 1.0000, Time: 16.5894, Step: 1000\n",
      "Loss: 0.1997, Acc: 1.0000, Time: 16.8548, Step: 1017\n",
      "fold_4 - Epoch 1, Precision: 0.8514, Recall: 0.9453, F1: 0.8959\n",
      "Loss: 1.3602, Acc: 0.9808, Time: 121.3681, Step: 1000\n",
      "Loss: 0.4690, Acc: 1.0000, Time: 238.7000, Step: 2000\n",
      "Loss: 3.2894, Acc: 0.9600, Time: 353.1877, Step: 2976\n",
      "fold_4 - Epoch 2, Precision: 0.9156, Recall: 0.9203, F1: 0.9180\n",
      "Loss: 0.0891, Acc: 1.0000, Time: 16.9082, Step: 1000\n",
      "Loss: 0.0509, Acc: 1.0000, Time: 17.1852, Step: 1017\n",
      "fold_4 - Epoch 2, Precision: 0.9057, Recall: 0.9429, F1: 0.9239\n",
      "Loss: 2.9725, Acc: 0.9839, Time: 124.1410, Step: 1000\n",
      "Loss: 0.2808, Acc: 1.0000, Time: 241.8311, Step: 2000\n",
      "Loss: 0.1341, Acc: 1.0000, Time: 362.4855, Step: 2976\n",
      "fold_4 - Epoch 3, Precision: 0.9291, Recall: 0.9347, F1: 0.9319\n",
      "Loss: 0.1708, Acc: 1.0000, Time: 16.6451, Step: 1000\n",
      "Loss: 0.0806, Acc: 1.0000, Time: 16.9082, Step: 1017\n",
      "fold_4 - Epoch 3, Precision: 0.9102, Recall: 0.9399, F1: 0.9248\n",
      "Loss: 0.1500, Acc: 1.0000, Time: 124.9317, Step: 1000\n",
      "Loss: 0.7881, Acc: 0.9787, Time: 251.5088, Step: 2000\n",
      "Loss: 0.1010, Acc: 1.0000, Time: 368.2102, Step: 2976\n",
      "fold_4 - Epoch 4, Precision: 0.9314, Recall: 0.9358, F1: 0.9336\n",
      "Loss: 0.0538, Acc: 1.0000, Time: 17.5490, Step: 1000\n",
      "Loss: 0.0156, Acc: 1.0000, Time: 17.8338, Step: 1017\n",
      "fold_4 - Epoch 4, Precision: 0.9071, Recall: 0.9438, F1: 0.9251\n",
      "Writing fold_4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, os.path.realpath(os.path.pardir))\n",
    "\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from model.estimator import Estimator\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Disable debug logs Tensorflow.\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "estimator = Estimator()\n",
    "estimator.set_dataset_params({\n",
    "    'datadir': '../data/ner_on_html',\n",
    "    'dataset_mode': 'batch',\n",
    "    \"model\": \"self_attention\",  \n",
    "    \"epochs\": 5,\n",
    "    \"batch_size\": 1,\n",
    "    \"use_features\": False,\n",
    "    \"word_embeddings\": \"glove\",\n",
    "    \"char_representation\": \"lstm\",\n",
    "    \"decoder\": \"crf\",  \n",
    "    # \"loss\": \"cross_entropy\"\n",
    "})\n",
    "estimator.train_cv()\n",
    "\n",
    "# !cd .. && ./eval_model.sh\n",
    "# !mkdir -p ../results/cross_validation/hard_attention\n",
    "# !mv ../results/score/fold* ../results/cross_validation/hard_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold size: 29\n",
      "Loss: 0.4476, Acc: 0.9750, Time: 40.9480, Step: 1000\n",
      "Loss: 0.6539, Acc: 0.9563, Time: 76.7476, Step: 2000\n",
      "Loss: 0.2555, Acc: 1.0000, Time: 110.4496, Step: 3000\n",
      "Loss: 0.0941, Acc: 1.0000, Time: 123.1724, Step: 3389\n",
      "fold_0 - Epoch 0, Precision: 0.4090, Recall: 0.3734, F1: 0.3904\n",
      "Loss: 0.1137, Acc: 1.0000, Time: 17.0826, Step: 999\n",
      "fold_0 - Epoch 0, Precision: 0.6378, Recall: 0.6644, F1: 0.6508\n",
      "Loss: 0.2650, Acc: 0.9700, Time: 40.7268, Step: 1000\n",
      "Loss: 0.0236, Acc: 1.0000, Time: 77.4675, Step: 2000\n",
      "Loss: 0.0064, Acc: 1.0000, Time: 112.3181, Step: 3000\n",
      "Loss: 0.0589, Acc: 1.0000, Time: 125.1860, Step: 3389\n",
      "fold_0 - Epoch 1, Precision: 0.9313, Recall: 0.9540, F1: 0.9425\n",
      "Loss: 0.0495, Acc: 1.0000, Time: 17.2057, Step: 999\n",
      "fold_0 - Epoch 1, Precision: 0.6592, Recall: 0.5996, F1: 0.6280\n",
      "Writing fold_0\n",
      "Loss: 0.4229, Acc: 0.9700, Time: 42.2542, Step: 1000\n",
      "Loss: 0.1556, Acc: 1.0000, Time: 80.5992, Step: 2000\n",
      "Loss: 0.1160, Acc: 1.0000, Time: 116.2057, Step: 3000\n",
      "Loss: 0.4291, Acc: 1.0000, Time: 137.5265, Step: 3638\n",
      "fold_1 - Epoch 0, Precision: 0.7850, Recall: 0.5769, F1: 0.6650\n",
      "Loss: 0.8156, Acc: 0.9259, Time: 12.7640, Step: 750\n",
      "fold_1 - Epoch 0, Precision: 0.7309, Recall: 0.6699, F1: 0.6991\n",
      "Loss: 0.0041, Acc: 1.0000, Time: 42.3191, Step: 1000\n",
      "Loss: 0.0130, Acc: 1.0000, Time: 78.4748, Step: 2000\n",
      "Loss: 0.0062, Acc: 1.0000, Time: 113.2784, Step: 3000\n",
      "Loss: 0.0133, Acc: 1.0000, Time: 134.5219, Step: 3638\n",
      "fold_1 - Epoch 1, Precision: 0.9271, Recall: 0.9353, F1: 0.9312\n",
      "Loss: 1.0973, Acc: 0.9259, Time: 12.6794, Step: 750\n",
      "fold_1 - Epoch 1, Precision: 0.6566, Recall: 0.6933, F1: 0.6744\n",
      "Writing fold_1\n",
      "Loss: 0.2975, Acc: 0.9833, Time: 41.7416, Step: 1000\n",
      "Loss: 0.2424, Acc: 1.0000, Time: 78.6372, Step: 2000\n",
      "Loss: 0.3515, Acc: 1.0000, Time: 111.7677, Step: 3000\n",
      "Loss: 0.1661, Acc: 1.0000, Time: 125.8727, Step: 3431\n",
      "fold_2 - Epoch 0, Precision: 0.7588, Recall: 0.5127, F1: 0.6120\n",
      "Loss: 0.6837, Acc: 1.0000, Time: 17.4161, Step: 957\n",
      "fold_2 - Epoch 0, Precision: 0.7616, Recall: 0.6765, F1: 0.7165\n",
      "Loss: 0.4312, Acc: 0.9950, Time: 40.9726, Step: 1000\n",
      "Loss: 0.0500, Acc: 1.0000, Time: 77.4213, Step: 2000\n",
      "Loss: 0.0102, Acc: 1.0000, Time: 110.8379, Step: 3000\n",
      "Loss: 0.2775, Acc: 0.9524, Time: 124.8702, Step: 3431\n",
      "fold_2 - Epoch 1, Precision: 0.9225, Recall: 0.9378, F1: 0.9301\n",
      "Loss: 0.8457, Acc: 0.9659, Time: 17.0838, Step: 957\n",
      "fold_2 - Epoch 1, Precision: 0.8240, Recall: 0.6261, F1: 0.7115\n",
      "Writing fold_2\n",
      "Loss: 0.7716, Acc: 0.9875, Time: 41.9965, Step: 1000\n",
      "Loss: 0.1537, Acc: 1.0000, Time: 78.1296, Step: 2000\n",
      "Loss: 0.0459, Acc: 1.0000, Time: 112.1983, Step: 3000\n",
      "Loss: 0.0126, Acc: 1.0000, Time: 124.8530, Step: 3387\n",
      "fold_3 - Epoch 0, Precision: 0.6771, Recall: 0.5678, F1: 0.6177\n",
      "Loss: 0.3516, Acc: 1.0000, Time: 17.6173, Step: 1000\n",
      "Loss: 0.3516, Acc: 1.0000, Time: 17.6208, Step: 1001\n",
      "fold_3 - Epoch 0, Precision: 0.7493, Recall: 0.6565, F1: 0.6998\n",
      "Loss: 0.2631, Acc: 0.9846, Time: 41.5719, Step: 1000\n",
      "Loss: 0.1701, Acc: 0.9857, Time: 79.0399, Step: 2000\n",
      "Loss: 0.0218, Acc: 1.0000, Time: 111.6107, Step: 3000\n",
      "Loss: 0.0312, Acc: 1.0000, Time: 124.7463, Step: 3387\n",
      "fold_3 - Epoch 1, Precision: 0.9322, Recall: 0.9371, F1: 0.9347\n",
      "Loss: 0.3366, Acc: 0.9653, Time: 17.4925, Step: 1000\n",
      "Loss: 0.3366, Acc: 0.9653, Time: 17.4960, Step: 1001\n",
      "fold_3 - Epoch 1, Precision: 0.6902, Recall: 0.6998, F1: 0.6950\n",
      "Writing fold_3\n",
      "Loss: 0.6810, Acc: 0.9895, Time: 42.6090, Step: 1000\n",
      "Loss: 0.2891, Acc: 1.0000, Time: 78.1220, Step: 2000\n",
      "Loss: 0.1688, Acc: 1.0000, Time: 112.3424, Step: 3000\n",
      "Loss: 0.1288, Acc: 1.0000, Time: 136.1142, Step: 3703\n",
      "fold_4 - Epoch 0, Precision: 0.7462, Recall: 0.5291, F1: 0.6192\n",
      "Loss: 1.3031, Acc: 0.8333, Time: 11.0130, Step: 685\n",
      "fold_4 - Epoch 0, Precision: 0.6620, Recall: 0.7506, F1: 0.7035\n",
      "Loss: 0.0209, Acc: 1.0000, Time: 41.2685, Step: 1000\n",
      "Loss: 0.0136, Acc: 1.0000, Time: 77.1410, Step: 2000\n",
      "Loss: 0.0198, Acc: 1.0000, Time: 112.4402, Step: 3000\n",
      "Loss: 0.0123, Acc: 1.0000, Time: 136.8971, Step: 3703\n",
      "fold_4 - Epoch 1, Precision: 0.9247, Recall: 0.9371, F1: 0.9308\n",
      "Loss: 1.4543, Acc: 0.8333, Time: 14.0063, Step: 685\n",
      "fold_4 - Epoch 1, Precision: 0.5927, Recall: 0.7808, F1: 0.6738\n",
      "Writing fold_4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, os.path.realpath(os.path.pardir))\n",
    "\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from model.estimator import Estimator\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Disable debug logs Tensorflow.\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "estimator = Estimator()\n",
    "estimator.set_dataset_params({\n",
    "    'datadir': '../data/ner_on_html',\n",
    "    'dataset_mode': 'sentences',\n",
    "    \"model\": \"maxent\",  \n",
    "    \"epochs\": 2,\n",
    "    \"batch_size\": 10,\n",
    "    \"use_features\": False,\n",
    "    \"word_embeddings\": \"none\",\n",
    "    \"char_representation\": \"none\",\n",
    "    \"decoder\": \"crf\",  \n",
    "    # \"loss\": \"cross_entropy\"\n",
    "})\n",
    "estimator.train_cv()\n",
    "\n",
    "# !cd .. && ./eval_model.sh\n",
    "# !mkdir -p ../results/cross_validation/hard_attention\n",
    "# !mv ../results/score/fold* ../results/cross_validation/hard_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.92%\t59.96%\t62.80%\t65.66%\t69.33%\t67.44%\t82.40%\t62.61%\t71.15%\t69.02%\t69.98%\t69.50%\t59.27%\t78.08%\t67.38%\t74.55%\t59.75%\t66.33%\t73.71%\t72.58%\t73.14%\t85.68%\t62.57%\t72.32%\t83.17%\t73.13%\t77.83%\t65.36%\t78.31%\t71.25%\t"
     ]
    }
   ],
   "source": [
    "!cd .. && ./eval_model.sh\n",
    "!mkdir -p ../results/cross_validation/crf_no_features\n",
    "!mv ../results/score/fold* ../results/cross_validation/crf_no_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold size: 29\n",
      "(35214, 300)\n",
      "Loss: -0.9013, Acc: 0.9848, Time: 95.5340, Step: 1000\n",
      "Loss: -0.8711, Acc: 0.9737, Time: 181.9080, Step: 2000\n",
      "Loss: -0.9090, Acc: 1.0000, Time: 267.7814, Step: 3000\n",
      "Loss: -0.9089, Acc: 1.0000, Time: 275.9861, Step: 3082\n",
      "fold_0 - Epoch 0, Precision: 0.6881, Recall: 0.7469, F1: 0.7163\n",
      "Loss: -0.0000, Acc: 1.0000, Time: 10.9029, Step: 909\n",
      "fold_0 - Epoch 0, Precision: 0.8048, Recall: 0.8867, F1: 0.8437\n",
      "Loss: -0.9058, Acc: 1.0000, Time: 84.5633, Step: 1000\n",
      "Loss: -0.7721, Acc: 0.9773, Time: 171.6340, Step: 2000\n",
      "Loss: -0.8778, Acc: 0.9623, Time: 255.0988, Step: 3000\n",
      "Loss: -0.9056, Acc: 1.0000, Time: 262.4011, Step: 3082\n",
      "fold_0 - Epoch 1, Precision: 0.8308, Recall: 0.8586, F1: 0.8445\n",
      "Loss: -0.0000, Acc: 1.0000, Time: 9.9280, Step: 909\n",
      "fold_0 - Epoch 1, Precision: 0.8225, Recall: 0.9265, F1: 0.8714\n",
      "Loss: -0.8851, Acc: 0.9821, Time: 96.4785, Step: 1000\n",
      "Loss: -0.8716, Acc: 0.9718, Time: 191.9247, Step: 2000\n",
      "Loss: -0.0000, Acc: 1.0000, Time: 281.1797, Step: 3000\n",
      "Loss: -0.9091, Acc: 1.0000, Time: 287.8632, Step: 3082\n",
      "fold_0 - Epoch 2, Precision: 0.8553, Recall: 0.8766, F1: 0.8658\n",
      "Loss: -0.0000, Acc: 1.0000, Time: 9.9020, Step: 909\n",
      "fold_0 - Epoch 2, Precision: 0.8358, Recall: 0.9095, F1: 0.8711\n",
      "Writing fold_0\n",
      "(35214, 300)\n",
      "Loss: -0.0000, Acc: 1.0000, Time: 90.8524, Step: 1000\n",
      "Loss: -0.7491, Acc: 0.9412, Time: 181.6142, Step: 2000\n",
      "Loss: -0.8600, Acc: 0.9647, Time: 266.7602, Step: 3000\n",
      "Loss: -0.9090, Acc: 1.0000, Time: 293.1134, Step: 3326\n",
      "fold_1 - Epoch 0, Precision: 0.7075, Recall: 0.7564, F1: 0.7311\n",
      "Loss: -0.6624, Acc: 0.9630, Time: 7.8730, Step: 665\n",
      "fold_1 - Epoch 0, Precision: 0.8344, Recall: 0.8643, F1: 0.8491\n",
      "Loss: -0.8762, Acc: 0.9714, Time: 85.0752, Step: 1000\n",
      "Loss: -0.9091, Acc: 1.0000, Time: 166.0689, Step: 2000\n",
      "Loss: -0.9091, Acc: 1.0000, Time: 247.9813, Step: 3000\n",
      "Loss: -0.6356, Acc: 0.9872, Time: 274.4358, Step: 3326\n",
      "fold_1 - Epoch 1, Precision: 0.8249, Recall: 0.8596, F1: 0.8419\n",
      "Loss: -0.6951, Acc: 0.9722, Time: 7.6487, Step: 665\n",
      "fold_1 - Epoch 1, Precision: 0.8676, Recall: 0.8939, F1: 0.8806\n",
      "Loss: -0.9091, Acc: 1.0000, Time: 83.8688, Step: 1000\n",
      "Loss: -0.9086, Acc: 1.0000, Time: 165.4837, Step: 2000\n",
      "Loss: -0.9090, Acc: 1.0000, Time: 245.8932, Step: 3000\n",
      "Loss: -0.9091, Acc: 1.0000, Time: 271.6190, Step: 3326\n",
      "fold_1 - Epoch 2, Precision: 0.8580, Recall: 0.8796, F1: 0.8687\n",
      "Loss: -0.6857, Acc: 0.9722, Time: 7.7214, Step: 665\n",
      "fold_1 - Epoch 2, Precision: 0.8832, Recall: 0.8850, F1: 0.8841\n",
      "Writing fold_1\n",
      "(35214, 300)\n",
      "Loss: -0.5944, Acc: 0.9487, Time: 84.4380, Step: 1000\n",
      "Loss: -0.9090, Acc: 1.0000, Time: 165.3979, Step: 2000\n",
      "Loss: -0.8835, Acc: 0.9863, Time: 245.9552, Step: 3000\n",
      "Loss: -0.9091, Acc: 1.0000, Time: 250.6407, Step: 3061\n",
      "fold_2 - Epoch 0, Precision: 0.7101, Recall: 0.7516, F1: 0.7303\n",
      "Loss: -0.8773, Acc: 0.9846, Time: 9.3609, Step: 930\n",
      "fold_2 - Epoch 0, Precision: 0.7503, Recall: 0.8447, F1: 0.7947\n",
      "Loss: -0.8797, Acc: 0.9688, Time: 84.1170, Step: 1000\n",
      "Loss: -0.9023, Acc: 1.0000, Time: 165.4162, Step: 2000\n",
      "Loss: -0.9088, Acc: 1.0000, Time: 245.6074, Step: 3000\n",
      "Loss: -0.6531, Acc: 0.9759, Time: 250.6207, Step: 3061\n",
      "fold_2 - Epoch 1, Precision: 0.8316, Recall: 0.8635, F1: 0.8472\n",
      "Loss: -0.8949, Acc: 1.0000, Time: 9.3294, Step: 930\n",
      "fold_2 - Epoch 1, Precision: 0.7428, Recall: 0.8648, F1: 0.7992\n",
      "Loss: -0.9090, Acc: 1.0000, Time: 93.2060, Step: 1000\n",
      "Loss: -0.8911, Acc: 0.9828, Time: 182.0623, Step: 2000\n",
      "Loss: -0.9090, Acc: 1.0000, Time: 270.0142, Step: 3000\n",
      "Loss: -0.9091, Acc: 1.0000, Time: 274.9950, Step: 3061\n",
      "fold_2 - Epoch 2, Precision: 0.8519, Recall: 0.8795, F1: 0.8655\n",
      "Loss: -0.9091, Acc: 1.0000, Time: 9.4396, Step: 930\n",
      "fold_2 - Epoch 2, Precision: 0.7735, Recall: 0.8246, F1: 0.7983\n",
      "Writing fold_2\n",
      "(35214, 300)\n",
      "Loss: -0.9008, Acc: 1.0000, Time: 82.8193, Step: 1000\n",
      "Loss: -0.9082, Acc: 1.0000, Time: 160.4943, Step: 2000\n",
      "Loss: -0.9091, Acc: 1.0000, Time: 237.8822, Step: 3000\n",
      "Loss: -0.9091, Acc: 1.0000, Time: 259.6269, Step: 3280\n",
      "fold_3 - Epoch 0, Precision: 0.7054, Recall: 0.7493, F1: 0.7267\n",
      "Loss: -0.9003, Acc: 1.0000, Time: 8.2095, Step: 711\n",
      "fold_3 - Epoch 0, Precision: 0.8672, Recall: 0.8711, F1: 0.8691\n",
      "Loss: -0.9049, Acc: 1.0000, Time: 81.3093, Step: 1000\n",
      "Loss: -0.9090, Acc: 1.0000, Time: 159.4428, Step: 2000\n",
      "Loss: -0.8922, Acc: 0.9865, Time: 238.1718, Step: 3000\n",
      "Loss: -0.9091, Acc: 1.0000, Time: 261.7967, Step: 3280\n",
      "fold_3 - Epoch 1, Precision: 0.8310, Recall: 0.8561, F1: 0.8434\n",
      "Loss: -0.8939, Acc: 0.9767, Time: 8.0938, Step: 711\n",
      "fold_3 - Epoch 1, Precision: 0.8653, Recall: 0.8452, F1: 0.8551\n",
      "Loss: -0.7143, Acc: 0.9886, Time: 85.9244, Step: 1000\n",
      "Loss: -0.9088, Acc: 1.0000, Time: 169.0886, Step: 2000\n",
      "Loss: -0.8333, Acc: 0.9818, Time: 252.1776, Step: 3000\n",
      "Loss: -0.9091, Acc: 1.0000, Time: 276.0913, Step: 3280\n",
      "fold_3 - Epoch 2, Precision: 0.8592, Recall: 0.8773, F1: 0.8682\n",
      "Loss: -0.9091, Acc: 1.0000, Time: 8.1379, Step: 711\n",
      "fold_3 - Epoch 2, Precision: 0.8888, Recall: 0.9184, F1: 0.9034\n",
      "Writing fold_3\n",
      "(35214, 300)\n",
      "Loss: -0.9064, Acc: 1.0000, Time: 88.3095, Step: 1000\n",
      "Loss: -0.8910, Acc: 0.9882, Time: 174.3789, Step: 2000\n",
      "Loss: -0.8565, Acc: 0.9773, Time: 258.6469, Step: 3000\n",
      "Loss: -0.8412, Acc: 0.9623, Time: 275.8524, Step: 3212\n",
      "fold_4 - Epoch 0, Precision: 0.7189, Recall: 0.7501, F1: 0.7341\n",
      "Loss: -0.0000, Acc: 1.0000, Time: 8.8106, Step: 779\n",
      "fold_4 - Epoch 0, Precision: 0.7448, Recall: 0.7838, F1: 0.7638\n",
      "Loss: -0.8507, Acc: 0.9149, Time: 80.4098, Step: 1000\n",
      "Loss: -0.8521, Acc: 0.9706, Time: 157.9090, Step: 2000\n",
      "Loss: -0.9084, Acc: 1.0000, Time: 236.0697, Step: 3000\n",
      "Loss: -0.9090, Acc: 1.0000, Time: 252.7961, Step: 3212\n",
      "fold_4 - Epoch 1, Precision: 0.8350, Recall: 0.8579, F1: 0.8463\n",
      "Loss: -0.0000, Acc: 1.0000, Time: 8.8419, Step: 779\n",
      "fold_4 - Epoch 1, Precision: 0.7724, Recall: 0.8142, F1: 0.7928\n",
      "Loss: -0.0000, Acc: 1.0000, Time: 89.7919, Step: 1000\n",
      "Loss: -0.9085, Acc: 1.0000, Time: 175.8496, Step: 2000\n",
      "Loss: -0.9028, Acc: 1.0000, Time: 262.0040, Step: 3000\n",
      "Loss: -0.9091, Acc: 1.0000, Time: 280.6250, Step: 3212\n",
      "fold_4 - Epoch 2, Precision: 0.8724, Recall: 0.8925, F1: 0.8823\n",
      "Loss: -0.0000, Acc: 1.0000, Time: 8.9319, Step: 779\n",
      "fold_4 - Epoch 2, Precision: 0.7775, Recall: 0.8164, F1: 0.7965\n",
      "Writing fold_4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, os.path.realpath(os.path.pardir))\n",
    "\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from model.estimator import Estimator\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Disable debug logs Tensorflow.\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "estimator = Estimator()\n",
    "estimator.set_dataset_params({\n",
    "    'datadir': '../data/ner_on_html',\n",
    "    'dataset_mode': 'batch',\n",
    "    \"model\": \"lstm_crf\",  \n",
    "    \"epochs\": 3,\n",
    "    \"batch_size\": 1,\n",
    "    \"use_features\": False,\n",
    "    \"word_embeddings\": \"glove\",\n",
    "    \"char_representation\": \"lstm\",\n",
    "    \"decoder\": \"logits\",  \n",
    "    \"loss\": \"f1\",\n",
    "    \"f_score_alpha\": 0.1,  \n",
    "})\n",
    "estimator.train_cv()\n",
    "\n",
    "!cd .. && ./eval_model.sh\n",
    "!mkdir -p ../results/cross_validation/f_01\n",
    "!mv ../results/score/fold* ../results/cross_validation/f_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold size: 29\n",
      "(35214, 300)\n",
      "Loss: -0.5101, Acc: 0.9649, Time: 81.6209, Step: 1000\n",
      "Loss: -0.5212, Acc: 0.9111, Time: 159.4853, Step: 2000\n",
      "Loss: -0.6249, Acc: 1.0000, Time: 238.1862, Step: 3000\n",
      "Loss: -0.6181, Acc: 1.0000, Time: 259.1383, Step: 3275\n",
      "fold_0 - Epoch 0, Precision: 0.7134, Recall: 0.8638, F1: 0.7814\n",
      "Loss: -0.0000, Acc: 0.8750, Time: 8.7896, Step: 716\n",
      "fold_0 - Epoch 0, Precision: 0.7824, Recall: 0.9112, F1: 0.8419\n",
      "Loss: -0.6250, Acc: 1.0000, Time: 80.5892, Step: 1000\n",
      "Loss: -0.6250, Acc: 1.0000, Time: 157.0350, Step: 2000\n",
      "Loss: -0.5756, Acc: 0.9583, Time: 234.3863, Step: 3000\n",
      "Loss: -0.6241, Acc: 1.0000, Time: 255.0493, Step: 3275\n",
      "fold_0 - Epoch 1, Precision: 0.8429, Recall: 0.9518, F1: 0.8940\n",
      "Loss: -0.0000, Acc: 0.9375, Time: 8.7127, Step: 716\n",
      "fold_0 - Epoch 1, Precision: 0.8361, Recall: 0.9059, F1: 0.8696\n",
      "Loss: -0.5881, Acc: 0.9683, Time: 81.2054, Step: 1000\n",
      "Loss: -0.6250, Acc: 1.0000, Time: 157.5964, Step: 2000\n",
      "Loss: -0.5909, Acc: 0.9851, Time: 233.9046, Step: 3000\n",
      "Loss: -0.6250, Acc: 1.0000, Time: 255.1702, Step: 3275\n",
      "fold_0 - Epoch 2, Precision: 0.8660, Recall: 0.9659, F1: 0.9133\n",
      "Loss: -0.0000, Acc: 0.9375, Time: 8.7490, Step: 716\n",
      "fold_0 - Epoch 2, Precision: 0.7893, Recall: 0.8920, F1: 0.8375\n",
      "Writing fold_0\n",
      "(35214, 300)\n",
      "Loss: -0.5807, Acc: 0.9130, Time: 86.4621, Step: 1000\n",
      "Loss: -0.6231, Acc: 1.0000, Time: 167.6637, Step: 2000\n",
      "Loss: -0.6250, Acc: 1.0000, Time: 251.7452, Step: 3000\n",
      "Loss: -0.0000, Acc: 1.0000, Time: 274.9471, Step: 3287\n",
      "fold_1 - Epoch 0, Precision: 0.7157, Recall: 0.8589, F1: 0.7808\n",
      "Loss: -0.0000, Acc: 1.0000, Time: 7.1468, Step: 704\n",
      "fold_1 - Epoch 0, Precision: 0.8564, Recall: 0.9205, F1: 0.8873\n",
      "Loss: -0.6250, Acc: 1.0000, Time: 84.4186, Step: 1000\n",
      "Loss: -0.6243, Acc: 1.0000, Time: 164.1150, Step: 2000\n",
      "Loss: -0.6246, Acc: 1.0000, Time: 244.3965, Step: 3000\n",
      "Loss: -0.5388, Acc: 0.9200, Time: 268.5418, Step: 3287\n",
      "fold_1 - Epoch 1, Precision: 0.8483, Recall: 0.9519, F1: 0.8971\n",
      "Loss: -0.0000, Acc: 0.9474, Time: 7.1063, Step: 704\n",
      "fold_1 - Epoch 1, Precision: 0.8480, Recall: 0.9199, F1: 0.8825\n",
      "Loss: -0.6250, Acc: 1.0000, Time: 82.2915, Step: 1000\n",
      "Loss: -0.6250, Acc: 1.0000, Time: 162.2249, Step: 2000\n",
      "Loss: -0.0000, Acc: 0.9302, Time: 241.5837, Step: 3000\n",
      "Loss: -0.6250, Acc: 1.0000, Time: 264.3509, Step: 3287\n",
      "fold_1 - Epoch 2, Precision: 0.8800, Recall: 0.9653, F1: 0.9207\n",
      "Loss: -0.0000, Acc: 1.0000, Time: 8.6207, Step: 704\n",
      "fold_1 - Epoch 2, Precision: 0.8510, Recall: 0.9530, F1: 0.8991\n",
      "Writing fold_1\n",
      "(35214, 300)\n",
      "Loss: -0.5567, Acc: 0.8936, Time: 85.1195, Step: 1000\n",
      "Loss: -0.5661, Acc: 0.9706, Time: 166.4128, Step: 2000\n",
      "Loss: -0.6250, Acc: 1.0000, Time: 247.0351, Step: 3000\n",
      "Loss: -0.6197, Acc: 1.0000, Time: 264.5097, Step: 3219\n",
      "fold_2 - Epoch 0, Precision: 0.7158, Recall: 0.8439, F1: 0.7746\n",
      "Loss: -0.6001, Acc: 0.9714, Time: 8.0021, Step: 772\n",
      "fold_2 - Epoch 0, Precision: 0.7374, Recall: 0.9121, F1: 0.8155\n",
      "Loss: -0.5344, Acc: 0.9677, Time: 87.7838, Step: 1000\n",
      "Loss: -0.6250, Acc: 1.0000, Time: 174.4085, Step: 2000\n",
      "Loss: -0.6250, Acc: 1.0000, Time: 260.3967, Step: 3000\n",
      "Loss: -0.5209, Acc: 0.9375, Time: 279.0382, Step: 3219\n",
      "fold_2 - Epoch 1, Precision: 0.8489, Recall: 0.9434, F1: 0.8937\n",
      "Loss: -0.6060, Acc: 0.9714, Time: 7.9660, Step: 772\n",
      "fold_2 - Epoch 1, Precision: 0.8140, Recall: 0.9558, F1: 0.8792\n",
      "Loss: -0.6250, Acc: 1.0000, Time: 84.5124, Step: 1000\n",
      "Loss: -0.6247, Acc: 1.0000, Time: 166.3809, Step: 2000\n",
      "Loss: -0.6250, Acc: 1.0000, Time: 246.4592, Step: 3000\n",
      "Loss: -0.6250, Acc: 1.0000, Time: 263.9348, Step: 3219\n",
      "fold_2 - Epoch 2, Precision: 0.8767, Recall: 0.9599, F1: 0.9165\n",
      "Loss: -0.6000, Acc: 0.9714, Time: 7.9799, Step: 772\n",
      "fold_2 - Epoch 2, Precision: 0.7612, Recall: 0.9075, F1: 0.8279\n",
      "Writing fold_2\n",
      "(35214, 300)\n",
      "Loss: -0.5833, Acc: 0.9750, Time: 91.6430, Step: 1000\n",
      "Loss: -0.6202, Acc: 1.0000, Time: 181.7173, Step: 2000\n",
      "Loss: -0.6232, Acc: 1.0000, Time: 263.6105, Step: 2918\n",
      "fold_3 - Epoch 0, Precision: 0.7033, Recall: 0.8418, F1: 0.7664\n",
      "Loss: -0.6229, Acc: 1.0000, Time: 10.9379, Step: 1000\n",
      "Loss: -0.3167, Acc: 0.8462, Time: 11.7477, Step: 1073\n",
      "fold_3 - Epoch 0, Precision: 0.7369, Recall: 0.8542, F1: 0.7912\n",
      "Loss: -0.6123, Acc: 0.9636, Time: 93.3628, Step: 1000\n",
      "Loss: -0.6209, Acc: 1.0000, Time: 183.4116, Step: 2000\n",
      "Loss: -0.5454, Acc: 0.9375, Time: 265.0307, Step: 2918\n",
      "fold_3 - Epoch 1, Precision: 0.8475, Recall: 0.9469, F1: 0.8944\n",
      "Loss: -0.6249, Acc: 1.0000, Time: 10.7448, Step: 1000\n",
      "Loss: -0.3571, Acc: 0.8846, Time: 11.5595, Step: 1073\n",
      "fold_3 - Epoch 1, Precision: 0.7900, Recall: 0.8804, F1: 0.8328\n",
      "Loss: -0.0000, Acc: 1.0000, Time: 83.9408, Step: 1000\n",
      "Loss: -0.5360, Acc: 0.9459, Time: 166.4818, Step: 2000\n",
      "Loss: -0.6250, Acc: 1.0000, Time: 241.8265, Step: 2918\n",
      "fold_3 - Epoch 2, Precision: 0.8736, Recall: 0.9579, F1: 0.9138\n",
      "Loss: -0.6250, Acc: 1.0000, Time: 10.8274, Step: 1000\n",
      "Loss: -0.3571, Acc: 0.8846, Time: 11.6337, Step: 1073\n",
      "fold_3 - Epoch 2, Precision: 0.8412, Recall: 0.9096, F1: 0.8741\n",
      "Writing fold_3\n",
      "(35214, 300)\n",
      "Loss: -0.6106, Acc: 0.9828, Time: 90.8006, Step: 1000\n",
      "Loss: -0.6118, Acc: 1.0000, Time: 178.5744, Step: 2000\n",
      "Loss: -0.6024, Acc: 0.9815, Time: 267.0485, Step: 3000\n",
      "Loss: -0.5899, Acc: 0.9783, Time: 289.2249, Step: 3262\n",
      "fold_4 - Epoch 0, Precision: 0.6983, Recall: 0.8370, F1: 0.7614\n",
      "Loss: -0.0000, Acc: 0.2500, Time: 9.0296, Step: 729\n",
      "fold_4 - Epoch 0, Precision: 0.7750, Recall: 0.9223, F1: 0.8422\n",
      "Loss: -0.6009, Acc: 0.9444, Time: 91.9414, Step: 1000\n",
      "Loss: -0.6205, Acc: 1.0000, Time: 180.2904, Step: 2000\n",
      "Loss: -0.6249, Acc: 1.0000, Time: 268.1819, Step: 3000\n",
      "Loss: -0.6250, Acc: 1.0000, Time: 290.8286, Step: 3262\n",
      "fold_4 - Epoch 1, Precision: 0.8531, Recall: 0.9457, F1: 0.8970\n",
      "Loss: -0.0000, Acc: 0.2500, Time: 8.9546, Step: 729\n",
      "fold_4 - Epoch 1, Precision: 0.8048, Recall: 0.9288, F1: 0.8624\n",
      "Loss: -0.6217, Acc: 1.0000, Time: 89.8053, Step: 1000\n",
      "Loss: -0.6216, Acc: 1.0000, Time: 176.3553, Step: 2000\n",
      "Loss: -0.5734, Acc: 0.9508, Time: 262.3499, Step: 3000\n",
      "Loss: -0.5858, Acc: 0.9444, Time: 285.5004, Step: 3262\n",
      "fold_4 - Epoch 2, Precision: 0.8942, Recall: 0.9623, F1: 0.9270\n",
      "Loss: -0.0000, Acc: 0.2500, Time: 9.6136, Step: 729\n",
      "fold_4 - Epoch 2, Precision: 0.8239, Recall: 0.9648, F1: 0.8888\n",
      "Writing fold_4\n",
      "78.93%\t89.20%\t83.75%\t85.10%\t95.30%\t89.91%\t76.12%\t90.75%\t82.79%\t84.12%\t90.96%\t87.41%\t82.39%\t96.48%\t88.88%\t86.90%\t88.86%\t87.87%\t90.16%\t94.70%\t92.38%\t83.44%\t90.65%\t86.90%\t88.72%\t90.51%\t89.60%\t85.95%\t96.48%\t90.91%\t"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, os.path.realpath(os.path.pardir))\n",
    "\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from model.estimator import Estimator\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Disable debug logs Tensorflow.\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "estimator = Estimator()\n",
    "estimator.set_dataset_params({\n",
    "    'datadir': '../data/ner_on_html',\n",
    "    'dataset_mode': 'batch',\n",
    "    \"model\": \"lstm_crf\",  \n",
    "    \"epochs\": 3,\n",
    "    \"batch_size\": 1,\n",
    "    \"use_features\": False,\n",
    "    \"word_embeddings\": \"glove\",\n",
    "    \"char_representation\": \"lstm\",\n",
    "    \"decoder\": \"logits\",  \n",
    "    \"loss\": \"f1\",\n",
    "    \"f_score_alpha\": 0.6,  \n",
    "})\n",
    "estimator.train_cv()\n",
    "\n",
    "!cd .. && ./eval_model.sh\n",
    "!mkdir -p ../results/cross_validation/f_06\n",
    "!mv ../results/score/fold* ../results/cross_validation/f_06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, os.path.realpath(os.path.pardir))\n",
    "\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from model.estimator import Estimator\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Disable debug logs Tensorflow.\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "print('wtf')\n",
    "estimator = Estimator()\n",
    "estimator.set_dataset_params({\n",
    "    'datadir': '../data/ner_on_html',\n",
    "    'dataset_mode': 'batch',\n",
    "    \"model\": \"lstm_crf\",  \n",
    "    \"epochs\": 3,\n",
    "    \"batch_size\": 1,\n",
    "    \"use_features\": False,\n",
    "    \"word_embeddings\": \"glove\",\n",
    "    \"char_representation\": \"lstm\",\n",
    "    \"decoder\": \"logits\",  \n",
    "    \"loss\": \"f1\",\n",
    "    \"f_score_alpha\": 0.7,  \n",
    "})\n",
    "estimator.train_cv()\n",
    "\n",
    "print('wtf')\n",
    "!cd .. && ./eval_model.sh\n",
    "!mkdir -p ../results/cross_validation/f_07\n",
    "!mv ../results/score/fold* ../results/cross_validation/f_07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, os.path.realpath(os.path.pardir))\n",
    "\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from model.estimator import Estimator\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Disable debug logs Tensorflow.\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "estimator = Estimator()\n",
    "estimator.set_dataset_params({\n",
    "    'datadir': '../data/ner_on_html',\n",
    "    'dataset_mode': 'batch',\n",
    "    \"model\": \"lstm_crf\",  \n",
    "    \"epochs\": 3,\n",
    "    \"batch_size\": 1,\n",
    "    \"use_features\": False,\n",
    "    \"word_embeddings\": \"glove\",\n",
    "    \"char_representation\": \"lstm\",\n",
    "    \"decoder\": \"logits\",  \n",
    "    \"loss\": \"f1\",\n",
    "    \"f_score_alpha\": 0.8,  \n",
    "})\n",
    "estimator.train_cv()\n",
    "\n",
    "!cd .. && ./eval_model.sh\n",
    "!mkdir -p ../results/cross_validation/f_08\n",
    "!mv ../results/score/fold* ../results/cross_validation/f_08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, os.path.realpath(os.path.pardir))\n",
    "\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from model.estimator import Estimator\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Disable debug logs Tensorflow.\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "estimator = Estimator()\n",
    "estimator.set_dataset_params({\n",
    "    'datadir': '../data/ner_on_html',\n",
    "    'dataset_mode': 'batch',\n",
    "    \"model\": \"lstm_crf\",  \n",
    "    \"epochs\": 3,\n",
    "    \"batch_size\": 1,\n",
    "    \"use_features\": False,\n",
    "    \"word_embeddings\": \"glove\",\n",
    "    \"char_representation\": \"lstm\",\n",
    "    \"decoder\": \"logits\",  \n",
    "    \"loss\": \"f1\",\n",
    "    \"f_score_alpha\": 0.9,  \n",
    "})\n",
    "estimator.train_cv()\n",
    "\n",
    "!cd .. && ./eval_model.sh\n",
    "!mkdir -p ../results/cross_validation/f_09\n",
    "!mv ../results/score/fold* ../results/cross_validation/f_09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dython\n",
      "  Downloading https://files.pythonhosted.org/packages/ce/ff/9a4c29dbb79598ebcc40dec8c198da9c262177744119c9241c81c731d5c1/dython-0.2.0-py3-none-any.whl\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from dython) (1.16.4)\n",
      "Collecting seaborn (from dython)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/76/220ba4420459d9c4c9c9587c6ce607bf56c25b3d3d2de62056efe482dadc/seaborn-0.9.0-py3-none-any.whl (208kB)\n",
      "\u001b[K     |████████████████████████████████| 215kB 3.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from dython) (0.25.1)\n",
      "Collecting matplotlib (from dython)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/4f/dd381ecf6c6ab9bcdaa8ea912e866dedc6e696756156d8ecc087e20817e2/matplotlib-3.1.1-cp36-cp36m-manylinux1_x86_64.whl (13.1MB)\n",
      "\u001b[K     |████████████████████████████████| 13.1MB 5.9MB/s eta 0:00:01    |██▋                             | 1.1MB 5.9MB/s eta 0:00:03     |███▊                            | 1.5MB 5.9MB/s eta 0:00:02     |███████████████▊                | 6.4MB 5.9MB/s eta 0:00:02     |██████████████████▍             | 7.6MB 5.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scikit-learn (from dython)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/c5/d2238762d780dde84a20b8c761f563fe882b88c5a5fb03c056547c442a19/scikit_learn-0.21.3-cp36-cp36m-manylinux1_x86_64.whl (6.7MB)\n",
      "\u001b[K     |████████████████████████████████| 6.7MB 29.8MB/s eta 0:00:01     |█▎                              | 256kB 29.8MB/s eta 0:00:01     |██████████████▋                 | 3.0MB 29.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy (from dython)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/50/a552a5aff252ae915f522e44642bb49a7b7b31677f9580cfd11bcc869976/scipy-1.3.1-cp36-cp36m-manylinux1_x86_64.whl (25.2MB)\n",
      "\u001b[K     |████████████████████████████████| 25.2MB 8.7MB/s eta 0:00:01    |█████                           | 3.9MB 8.7MB/s eta 0:00:03     |█████████▎                      | 7.3MB 8.7MB/s eta 0:00:03     |██████████████████████▋         | 17.8MB 8.7MB/s eta 0:00:01��██████████████████████████▊ | 24.2MB 8.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->dython) (2019.2)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->dython) (2.8.0)\n",
      "Collecting cycler>=0.10 (from matplotlib->dython)\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib->dython)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/a1/5742b56282449b1c0968197f63eae486eca2c35dcd334bab75ad524e0de1/kiwisolver-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (90kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 26.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 (from matplotlib->dython)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/fa/0160cd525c62d7abd076a070ff02b2b94de589f1a9789774f17d7c54058e/pyparsing-2.4.2-py2.py3-none-any.whl (65kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 31.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting joblib>=0.11 (from scikit-learn->dython)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl (278kB)\n",
      "\u001b[K     |████████████████████████████████| 286kB 49.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.6.1->pandas->dython) (1.11.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->dython) (41.0.1)\n",
      "Installing collected packages: cycler, kiwisolver, pyparsing, matplotlib, scipy, seaborn, joblib, scikit-learn, dython\n",
      "Successfully installed cycler-0.10.0 dython-0.2.0 joblib-0.13.2 kiwisolver-1.1.0 matplotlib-3.1.1 pyparsing-2.4.2 scikit-learn-0.21.3 scipy-1.3.1 seaborn-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install dython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
