{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Researcher Name Extraction Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset statistics:\n",
    "\n",
    "| Data file  | Documents | Sentences | Tokens | Names |\n",
    "|------------|-----------|-----------|--------|-------|\n",
    "| Training   | 80        | 24728     | 110269 | 5822  |\n",
    "| Validation | 35        | 8743      | 36757  | 1788  |\n",
    "| Test       | 35        | 10399     | 44795  | 2723  |\n",
    "| Total      | 145       | 43870     | 191821 | 10333 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "sys.path.insert(1, os.path.realpath(os.path.pardir))\n",
    "\n",
    "from optparse import OptionParser\n",
    "from pathlib import Path\n",
    "from model.hmm import HiddenMarkov, load_dataset\n",
    "\n",
    "start_time = time.time()\n",
    "for name in ['train', 'valid', 'test']:\n",
    "    _, Y, T = load_dataset('../data/ner_on_html/' + name)\n",
    "    t = [[['O', 'B-PER', 'I-PER'][t__] for t__ in t_] for t_ in Y]\n",
    "    p = [[['O', 'B-PER', 'I-PER'][p__] for p__ in p_] for p_ in Y]\n",
    "    w = T\n",
    "    \n",
    "    with Path('../results/score/{}.preds.txt'.format(name)).open('wb') as f:\n",
    "        for words, preds, tags in zip(w, p, t):\n",
    "            f.write(b'\\n')\n",
    "            for word, pred, tag in zip(words, preds, tags):\n",
    "                f.write(' '.join([word, tag, pred]).encode() + b'\\n')\n",
    "\n",
    "!cd .. && ./eval.sh | grep processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "def plot_word_frequency(directory, color):\n",
    "    my_counter = Counter()\n",
    "    for fname in ['train', 'valid', 'test']:\n",
    "        with open(directory + '/' + fname) as f:\n",
    "            words = [line.strip().lower().split()[0] for line in f if len(line.strip()) > 0]\n",
    "            words = [w for w in words if w != '-docstart-']\n",
    "            my_counter.update(words)\n",
    "\n",
    "    data = [(key, my_counter[key]) for key in my_counter]    \n",
    "    data.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print([(i, x[1]) for i, x in enumerate(data)][:100])\n",
    "    plt.plot([x[1] for x in data][:100], color)\n",
    "    return data[:50]\n",
    "    \n",
    "plt.title('Word frequencies')\n",
    "data1 = plot_word_frequency('../data/conll2003', 'r')\n",
    "data2 = plot_word_frequency('../data/ner_on_html', 'b')\n",
    "\n",
    "print(' '.join([d[0] for d in data1[:10]]))\n",
    "print()\n",
    "print(' '.join([d[0] for d in data2[:10]]))\n",
    "\n",
    "for d1, d2 in zip(data1, data2):\n",
    "    print('%s & %d & %s & %d' % (d1[0], d1[1], d2[0], d2[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dython import nominal\n",
    "\n",
    "def load_raw_dataset(f):\n",
    "    with open(f, 'r', encoding='utf8') as f:\n",
    "        data = f.read().strip()\n",
    "        sentences = [s.split('\\n') for s in data.split('\\n\\n') if not s.startswith('-DOCSTART-')]\n",
    "        X = [t.split(' ') for s in sentences for t in s if len(s) > 0]\n",
    "        for i, s in enumerate(X):\n",
    "            X[i] = X[i][2:5] + X[i][7:]\n",
    "        return X\n",
    "\n",
    "X = load_raw_dataset('../data/ner_on_html/train')\n",
    "X += load_raw_dataset('../data/ner_on_html/valid')\n",
    "X += load_raw_dataset('../data/ner_on_html/test')\n",
    "\n",
    "data = {}\n",
    "data['words']         = [x[0 ] for x in X]\n",
    "data['exact_match']   = [int(x[1]) for x in X]\n",
    "data['partial_match'] = [int(x[2]) for x in X]\n",
    "data['email']         = [int(x[3]) for x in X]\n",
    "data['number']        = [int(x[4]) for x in X]\n",
    "data['honorific']     = [int(x[5]) for x in X] \n",
    "data['url']           = [int(x[6]) for x in X]\n",
    "data['capitalized']   = [int(x[7]) for x in X]\n",
    "data['punctuation']   = [int(x[8]) for x in X]\n",
    "data['html_tag']      = [x[9 ] for x in X]\n",
    "data['css_class']     = [x[10] for x in X]\n",
    "\n",
    "data['words'][0]\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "nominal.associations(df, nominal_columns=['words','html_tag', 'css_class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it: https://github.com/shakedzy/dython/issues/2\n",
    "\n",
    "Calculates Cramer's V statistic for categorical-categorical association.\n",
    "Uses correction from Bergsma and Wicher, Journal of the Korean Statistical Society 42 (2013): 323-328.\n",
    "This is a symmetric coefficient: V(x,y) = V(y,x)\n",
    "\n",
    "https://github.com/shakedzy/dython/blob/master/dython/nominal.py\n",
    "https://en.wikipedia.org/wiki/Cram%C3%A9r%27s_V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested cross-validation\n",
    "\n",
    "5-fold cross validation\n",
    "\n",
    "\n",
    "Partition the training data randomly in five folds\n",
    "\n",
    "Nested CV\n",
    "https://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html\n",
    "\n",
    "Common error with cross validation\n",
    "https://www.youtube.com/watch?v=S06JpVoNaA0\n",
    "\n",
    "https://www.kdnuggets.com/2017/08/dataiku-predictive-model-holdout-cross-validation.html\n",
    "\n",
    "https://www.datarobot.com/wiki/training-validation-holdout/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is split into 3 different files: train, valid, and test. Also, we provide 11 features alongside each token.\n",
    "\n",
    "| Feature                          | Type        |\n",
    "|----------------------------------|-------------|\n",
    "| Unaccented lowercase token       | Categorical |\n",
    "| Exact dictionary match           | Binary      |\n",
    "| Partial dictionary match         | Binary      |\n",
    "| Email                            | Binary      |\n",
    "| Number                           | Binary      |\n",
    "| Honorific (Mr., Mrs., Dr., etc.) | Binary      |\n",
    "| Matches a URL                    | Binary      |\n",
    "| Is capitalized                   | Binary      |\n",
    "| Is a punctuation sign            | Binary      |\n",
    "| HTML tag + parent                | Categorical |\n",
    "| CSS class                        | Categorical |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden Markov Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "sys.path.insert(1, os.path.realpath(os.path.pardir))\n",
    "\n",
    "from optparse import OptionParser\n",
    "from pathlib import Path\n",
    "from model.hmm import HiddenMarkov, load_dataset\n",
    "\n",
    "def test_hmm(timesteps, use_features, self_train, dataset):\n",
    "    start_time = time.time()\n",
    "    naive_bayes = timesteps == 0\n",
    "    if naive_bayes:\n",
    "        timesteps = 1\n",
    "        \n",
    "    print('Fitting...')\n",
    "    X1, Y1, T1 = load_dataset(dataset + '/train')\n",
    "    X2, Y2, T2 = load_dataset(dataset + '/valid')\n",
    "    X3, Y3, T3 = load_dataset(dataset + '/test')\n",
    "    \n",
    "    training_set = [x for x in zip(X1 + X2 + X3, Y1 + Y2 + Y3, T1 + T2 + T3)]\n",
    "\n",
    "    documents = []\n",
    "    for p in training_set:     \n",
    "        if p[0][0][0] == '-DOCSTART-':\n",
    "            documents.append([])\n",
    "        else:\n",
    "            documents[len(documents)-1].append(p)\n",
    "\n",
    "    random.shuffle(documents)\n",
    "    fold_size = len(documents) // 5\n",
    "    \n",
    "    folds = []\n",
    "    for i in range(5):\n",
    "        start = i * fold_size\n",
    "        end = start + fold_size if (i < 4) else len(documents)\n",
    "        folds.append(documents[start:end])\n",
    "    print('Fold size:', fold_size)\n",
    "\n",
    "    \"\"\"\n",
    "    random.shuffle(training_set)\n",
    "    fold_size = len(training_set) // 5\n",
    "    \n",
    "    folds = []\n",
    "    for i in range(5):\n",
    "        start = i * fold_size\n",
    "        end = start + fold_size if (i < 4) else len(training_set)\n",
    "        folds.append(training_set[start:end])\n",
    "    print('Fold size:', fold_size)\n",
    "    \"\"\"\n",
    "    \n",
    "    for i in range(5):\n",
    "        train = []        \n",
    "        for j in range(5):        \n",
    "            if i != j:\n",
    "                train = train + folds[j]\n",
    "        test = folds[i]\n",
    "\n",
    "        aux = []    \n",
    "        for d in train:\n",
    "            aux = aux + d\n",
    "        train = aux    \n",
    "        \n",
    "        \"\"\"\n",
    "        aux = []    \n",
    "        for d in test:\n",
    "            aux = aux + d    \n",
    "        test = aux\n",
    "        \"\"\"\n",
    "        \n",
    "        map(list, zip(*train))\n",
    "        train_X, train_Y, train_T = [list(t) for t in zip(*train)]\n",
    "        \n",
    "        # map(list, zip(*test))\n",
    "        # test_X, test_Y, test_T = [list(t) for t in zip(*test)]\n",
    "        \n",
    "        hmm = HiddenMarkov(timesteps, naive_bayes=naive_bayes, use_features=use_features, self_train=self_train)\n",
    "        hmm.fit(train_X, train_Y)\n",
    "\n",
    "        # p = hmm.predict(test_X)\n",
    "        \n",
    "        test_Y = []\n",
    "        test_T = []\n",
    "        p = []\n",
    "        for d in test:\n",
    "            x, y, t = [list(z) for z in zip(*d)]            \n",
    "            test_Y = test_Y + y\n",
    "            test_T = test_T + t\n",
    "            p = p + hmm.predict(x)\n",
    "\n",
    "        t = test_Y\n",
    "        t = [[['O', 'B-PER', 'I-PER'][t__] for t__ in t_] for t_ in t]\n",
    "        p = [[['O', 'B-PER', 'I-PER'][p__] for p__ in p_] for p_ in p]\n",
    "        w = test_T\n",
    "\n",
    "        name = 'fold_' + str(i)\n",
    "        print('Writing', name)\n",
    "        with Path('../results/score/{}.preds.txt'.format(name)).open('wb') as f:\n",
    "            for words, preds, tags in zip(w, p, t):\n",
    "                f.write(b'\\n')\n",
    "                for word, pred, tag in zip(words, preds, tags):\n",
    "                    f.write(' '.join([word, tag, pred]).encode() + b'\\n')\n",
    "\n",
    "    print('Elapsed time: %.4f' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_hmm(0, False, False, '../data/ner_on_html')\n",
    "\n",
    "!cd .. && ./eval_model.sh\n",
    "!mkdir -p ../results/cross_validation/nb\n",
    "!mv ../results/score/fold* ../results/cross_validation/nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_hmm(2, True, True, '../data/ner_on_html')\n",
    "\n",
    "!cd .. && ./eval_model.sh\n",
    "!mkdir -p ../results/cross_validation/hmm_1_features\n",
    "!mv ../results/score/fold* ../results/cross_validation/hmm_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum Entropy, CRFs, NNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maxent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, os.path.realpath(os.path.pardir))\n",
    "\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from model.estimator import Estimator\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Disable debug logs Tensorflow.\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "estimator = Estimator()\n",
    "estimator.set_dataset_params({\n",
    "    'datadir': '../data/ner_on_html',\n",
    "    'dataset_mode': 'sentences',\n",
    "    \"model\": \"maxent\",  \n",
    "    \"epochs\": 5,\n",
    "    \"batch_size\": 10,\n",
    "    \"use_features\": False,\n",
    "    \"word_embeddings\": \"one_hot\",\n",
    "    \"char_representation\": \"none\",\n",
    "    \"decoder\": \"crf\",  \n",
    "    \"loss\": \"cross_entropy\"\n",
    "})\n",
    "estimator.train_cv()\n",
    "\n",
    "!cd .. && ./eval_model.sh\n",
    "!mkdir -p ../results/cross_validation/maxent\n",
    "!mv ../results/score/fold* ../results/cross_validation/maxent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, os.path.realpath(os.path.pardir))\n",
    "\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from model.estimator import Estimator\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Disable debug logs Tensorflow.\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "estimator = Estimator()\n",
    "estimator.set_dataset_params({\n",
    "    'datadir': '../data/ner_on_html',\n",
    "    'dataset_mode': 'sentences',\n",
    "    \"model\": \"maxent\",  \n",
    "    \"epochs\": 5,\n",
    "    \"batch_size\": 10,\n",
    "    \"use_features\": False,\n",
    "    \"word_embeddings\": \"one_hot\",\n",
    "    \"char_representation\": \"none\",\n",
    "    \"decoder\": \"crf\"\n",
    "    # \"loss\": \"cross_entropy\"\n",
    "})\n",
    "estimator.train_cv()\n",
    "\n",
    "!cd .. && ./eval_model.sh\n",
    "!mkdir -p ../results/cross_validation/crf_no_features\n",
    "!mv ../results/score/fold* ../results/cross_validation/crf_no_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CRF with features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, os.path.realpath(os.path.pardir))\n",
    "\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from model.estimator import Estimator\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Disable debug logs Tensorflow.\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "estimator = Estimator()\n",
    "estimator.set_dataset_params({\n",
    "    'datadir': '../data/ner_on_html',\n",
    "    'dataset_mode': 'sentences',\n",
    "    \"model\": \"crf\",  \n",
    "    \"epochs\": 5,\n",
    "    \"batch_size\": 10,\n",
    "    \"use_features\": True,\n",
    "    \"word_embeddings\": \"one_hot\",\n",
    "    \"char_representation\": \"none\",\n",
    "    \"decoder\": \"crf\"\n",
    "    # \"loss\": \"cross_entropy\"\n",
    "})\n",
    "estimator.train_cv()\n",
    "\n",
    "!cd .. && ./eval_model.sh\n",
    "!mkdir -p ../results/cross_validation/crf_group_a\n",
    "!mv ../results/score/fold* ../results/cross_validation/crf_group_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
