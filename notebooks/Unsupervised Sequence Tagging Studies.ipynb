{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse gazetteer matching\n",
    "\n",
    "$ P(steve=name) = \\theta $ is given\n",
    "\n",
    "$ n $ = the number of times Steve happens in the corpus\n",
    "\n",
    "$ P(steve \\not\\in G) = (1 - \\theta) ^ n $ \n",
    "\n",
    "$ P(steve \\in G) = 1 - P(steve \\not\\in G) $\n",
    "\n",
    "$ P(\\theta | steve \\in G) = \\frac{\\theta}{P(steve \\in G)} $\n",
    "\n",
    "Expected Steve count:\n",
    "\n",
    "$ E[steve] = \\theta n $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(steve is name): 0.6\n",
      "P(steve is not in gazetteer): 0.16000000000000003\n",
      "P(steve is in gazetteer): 0.84\n",
      "P(steve is name | steve is in gazetter): 0.7142857142857143\n",
      "E[num steves = name]: 1.2\n"
     ]
    }
   ],
   "source": [
    "sentence = ['Steve', 'is', 'a', 'guitarist', '.', 'Steve', 'has', 'a', 'band', '.']\n",
    "gazetteer = ['Steve']\n",
    "\n",
    "n_steves = 2\n",
    "p_steve_is_name = 0.6\n",
    "p_steve_is_not_in_gazetteer = (1 - p_steve_is_name) ** n_steves\n",
    "p_steve_is_in_gazetteer = 1 - p_steve_is_not_in_gazetteer\n",
    "p_steve_is_name_given_steve_in_gazetter = p_steve_is_name / p_steve_is_in_gazetteer\n",
    "expected_num_steves = p_steve_is_name * n_steves\n",
    "\n",
    "print('P(steve is name):', p_steve_is_name)\n",
    "print('P(steve is not in gazetteer):', p_steve_is_not_in_gazetteer)\n",
    "print('P(steve is in gazetteer):', p_steve_is_in_gazetteer)\n",
    "print('P(steve is name | steve is in gazetter):', p_steve_is_name_given_steve_in_gazetter)\n",
    "print('E[num steves = name]:', expected_num_steves)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steve with prior knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd601dc4080>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def factorial(n):\n",
    "    return 1 if n <= 1 else factorial(n - 1) * n\n",
    "\n",
    "def gamma_fn(x):\n",
    "    return factorial(x-1)\n",
    "    \n",
    "def beta_fn(x, y):\n",
    "    return (gamma_fn(x) * gamma_fn(y)) / gamma_fn(x+y) \n",
    "    \n",
    "def binomial_coefficient(n, k):\n",
    "    return factorial(n) / (factorial(k) * factorial(n-k))\n",
    "\n",
    "alpha = 1.3\n",
    "beta = 1.3\n",
    "n_steves = 3\n",
    "def steve_prior(x):\n",
    "    r = x ** (alpha-1) * (1-x) ** (beta-1)\n",
    "    return r / beta_fn(alpha, beta)\n",
    "\n",
    "def steve_likelihood(p_steve_is_name):                                   \n",
    "    p_steve_is_not_in_gazetteer = (1 - p_steve_is_name) ** n_steves\n",
    "    p_steve_is_in_gazetteer = 1 - p_steve_is_not_in_gazetteer\n",
    "    return p_steve_is_in_gazetteer\n",
    "    \n",
    "def steve_total(x):\n",
    "    return steve_prior(x) * steve_likelihood(x)\n",
    "                                   \n",
    "x = np.linspace(0, 1, num=101)\n",
    "y = list(map(steve_total, x))\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable number of mentions in gazetteer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 20\n",
      "P(steve is name): 0.2\n",
      "P(steve is not in gazetteer): 0.011529215046068483\n",
      "P(steve is in gazetteer): 0.9884707849539315\n",
      "P(steve is name | steve is in gazetter): 0.20233273764314763\n",
      "\n",
      "P(steve is name 0x): 0.011529215046068483\n",
      "P(steve is name 1x): 0.05764607523034241\n",
      "P(steve is name 2x): 0.13690942867206324\n",
      "P(steve is name 3x): 0.20536414300809488\n",
      "P(steve is name 4x): 0.21819940194610077\n",
      "P(steve is name 5x): 0.17455952155688062\n",
      "\n",
      "P(steve is name at most 0x): 0.011529215046068483\n",
      "P(steve is name at most 1x): 0.0691752902764109\n",
      "P(steve is name at most 2x): 0.20608471894847413\n",
      "P(steve is name at most 3x): 0.41144886195656905\n",
      "P(steve is name at most 4x): 0.6296482639026698\n",
      "P(steve is name at most 5x): 0.8042077854595504\n",
      "\n",
      "P(steve is in gazetteer 1x): 0.9884707849539315\n",
      "P(steve is in gazetteer 2x): 0.9308247097235891\n",
      "P(steve is in gazetteer 3x): 0.7939152810515259\n",
      "P(steve is in gazetteer 4x): 0.588551138043431\n",
      "P(steve is in gazetteer 5x): 0.3703517360973302\n",
      "\n",
      "P(steve is name | steve in gazetteer 1x): 0.20233273764314763\n",
      "P(steve is name | steve in gazetteer 2x): 0.21176672060738214\n",
      "P(steve is name | steve in gazetteer 3x): 0.2310407139768506\n",
      "P(steve is name | steve in gazetteer 4x): 0.25931838723043965\n",
      "P(steve is name | steve in gazetteer 5x): 0.2942668844468468\n"
     ]
    }
   ],
   "source": [
    "n = 20\n",
    "num_contexts = 3\n",
    "\n",
    "def binomial_steve(theta, n, k):\n",
    "    return binomial_coefficient(n, k) * theta ** k * (1-theta) ** (n-k)\n",
    "\n",
    "def cumulative_steve(theta, n, k):\n",
    "    r = 0\n",
    "    for i in range(k+1):\n",
    "        r += binomial_steve(theta, n, i)\n",
    "    return r\n",
    "    \n",
    "p_steve_is_name = 0.2\n",
    "p_steve_is_not_in_gazetteer = (1 - p_steve_is_name) ** n\n",
    "p_steve_is_in_gazetteer = 1 - p_steve_is_not_in_gazetteer\n",
    "p_steve_is_name_given_steve_in_gazetter = p_steve_is_name / p_steve_is_in_gazetteer\n",
    "\n",
    "print('n:', n)\n",
    "print('P(steve is name):', p_steve_is_name)\n",
    "print('P(steve is not in gazetteer):', p_steve_is_not_in_gazetteer)\n",
    "print('P(steve is in gazetteer):', p_steve_is_in_gazetteer)\n",
    "print('P(steve is name | steve is in gazetter):', p_steve_is_name_given_steve_in_gazetter) \n",
    "\n",
    "steve_counts = [binomial_steve(p_steve_is_name, n, i) for i in range(6)]\n",
    "steve_cums   = [cumulative_steve(p_steve_is_name, n, i) for i in range(6)]\n",
    "\n",
    "print()\n",
    "for i in range(6):\n",
    "    print('P(steve is name ' + str(i) + 'x):', steve_counts[i])\n",
    "    \n",
    "print()\n",
    "for i in range(6):    \n",
    "    print('P(steve is name at most ' + str(i) + 'x):', steve_cums[i])\n",
    "\n",
    "p_steve_is_in_gazetter_x_times = [0] + [1 - steve_cums[i-1] for i in range(1, 6)]    \n",
    "    \n",
    "print()\n",
    "for i in range(1, 6):    \n",
    "    print('P(steve is in gazetteer ' + str(i) + 'x):', p_steve_is_in_gazetter_x_times[i])\n",
    "    \n",
    "print()    \n",
    "for i in range(1, 6):    \n",
    "    num_times_in_gazetteer = i\n",
    "    k = num_times_in_gazetteer\n",
    "    \n",
    "    p_steve_is_at_most_k_minus_one = cumulative_steve(p_steve_is_name, n-1, k-2)\n",
    "    p_steve_is_at_least_k = 1 - p_steve_is_at_most_k_minus_one\n",
    "\n",
    "    p_t = (p_steve_is_at_least_k * p_steve_is_name) / p_steve_is_in_gazetter_x_times[i]\n",
    "    print('P(steve is name | steve in gazetteer ' + str(i) + 'x):', p_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.444444444444\n"
     ]
    }
   ],
   "source": [
    "n = 3\n",
    "c = 2\n",
    "\n",
    "p_steve_is_name \n",
    "\n",
    "def multinomial(x):\n",
    "    n_ = np.sum(x)\n",
    "    thetas = [1 / (c+1)] * (c+1)\n",
    "    r = factorial(n_) / np.product(list(map(factorial, x)))\n",
    "    return r * np.product(np.power(thetas, x))\n",
    "\n",
    "x1 = multinomial([1,1,1])\n",
    "x2 = multinomial([0,2,1])\n",
    "p_two_contexts = x1 + x2*2\n",
    "\n",
    "\n",
    "print(p_two_contexts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative Network\n",
    "\n",
    "$ P(steve=name) = \\theta $\n",
    "\n",
    "$ steve_G = $ number of Steves in gazetteer\n",
    "\n",
    "$ P(steve_G|\\theta) $ is a binomial distribution.\n",
    "\n",
    "$ P(\\theta) $ is a theta distribution.\n",
    "\n",
    "$ \\theta = argmax_\\theta P(steve_G|\\theta) P(\\theta) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dave 0.75\n",
      "irwin 0.5\n",
      "smith 0.75\n",
      "steve 0.5\n",
      "and 0.001996007984031936\n",
      "\n",
      "{'dave': [0.6279203978150306, 0.9999999999999996], 'irwin': [0.24122233873333326, 0.9999999999999996], 'smith': [0.9860605168336936, 0.9999999999999996], 'steve': [1.3060896811173293, 1.9999999999999991], 'and': [3.626390270716399e-68, 0.9999999999999996]}\n",
      "dave 0.7255840795630061\n",
      "irwin 0.41374077957777783\n",
      "smith 0.7972121033667386\n",
      "steve 0.5510149468528883\n",
      "and 0.00199203187250996\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence_g = 'dave adams, dave johnson and dave smith are men that went to the first '\n",
    "\n",
    "sentence = 'steve irwin is a man and steve smith was also a man but dave remains skeptical'\n",
    "\n",
    "gazetteer = {\n",
    "    'dave': (3, 1),\n",
    "    'irwin': (1, 1),\n",
    "    'smith': (3, 1),    \n",
    "    'steve': (2, 2),\n",
    "    'and': (1, 500),    \n",
    "}\n",
    "\n",
    "results = {\n",
    "    'dave':  [0, 0],\n",
    "    'irwin': [0, 0],\n",
    "    'smith': [0, 0],    \n",
    "    'steve': [0, 0],\n",
    "    'and':   [0, 0],    \n",
    "}\n",
    "\n",
    "def binomial_distribution(k, n, theta):\n",
    "    return binomial_coefficient(n,k) * theta ** k * (1-theta) ** (n-k)\n",
    "\n",
    "def beta_distribution(theta, alpha, beta):\n",
    "    r = theta ** (alpha-1) * (1-theta) ** (beta-1)\n",
    "    return r / beta_fn(alpha, beta)\n",
    "\n",
    "def map_est(k, n, alpha, beta):\n",
    "    return (k + alpha - 1) / (n + alpha + beta - 2)\n",
    "\n",
    "def tkn_theta(tkn):\n",
    "    a, b = gazetteer[tkn]\n",
    "    k, n = results[tkn]        \n",
    "    return map_est(k, n, a+1, b+1)    \n",
    "\n",
    "def print_estimates():\n",
    "    global results, gazetteer\n",
    "    for key in gazetteer:\n",
    "        a, b = gazetteer[key]\n",
    "        k, n = results[key]        \n",
    "        x = map_est(k, n, a+1, b+1)    \n",
    "        print(key, x)\n",
    "    print()\n",
    "\n",
    "def update_results(nresults):\n",
    "    for key in results:\n",
    "        results[key][0] = 0.7 * results[key][0] + 0.3 * nresults[key][0] \n",
    "        results[key][1] = 0.7 * results[key][1] + 0.3 * nresults[key][1]\n",
    "    \n",
    "print_estimates()\n",
    "    \n",
    "sentence = sentence.split()\n",
    "for n in range(1000):\n",
    "    nresults = {\n",
    "        'dave':  [0, 0],\n",
    "        'irwin': [0, 0],\n",
    "        'smith': [0, 0],    \n",
    "        'steve': [0, 0],\n",
    "        'and':   [0, 0],            \n",
    "    }\n",
    "    \n",
    "    for t in sentence:\n",
    "        if not t in gazetteer:\n",
    "            continue\n",
    "\n",
    "        p = tkn_theta(t)\n",
    "        y = np.random.choice(a=[0, 1], p=[1-p, p])\n",
    "        if y == 1:\n",
    "            nresults[t][0] += 1\n",
    "        nresults[t][1] += 1\n",
    "        \n",
    "    update_results(nresults)\n",
    "    \n",
    "print(results)\n",
    "print_estimates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'adams': 1.0, 'connor': 0.6666666666666666, 'dave': 1.0, 'john': 0.75, 'mary': 0.6666666666666666, 'smith': 0.6666666666666666, 'wick': 1.0, 'it': 0.0, 'into': 0.0, 'and': 0.0, 'match': 0.0, 'the': 0.0, 'scotsman': 0.0, 'against': 0.0, 'talked': 0.0, 'to': 0.0, 'a': 0.0, 'church': 0.0, 'magnificent': 0.0, 'is': 0.0, 'lot': 0.0, 'evan': 0.0, 'drinks': 0.0, 'erick': 0.0, 'doing': 0.0, 'whisky': 0.0, 'tennis': 0.0, 'that': 0.0, 'went': 0.0, 'won': 0.0, 'by': 0.0}\n",
      "Baseline: 0.738215506077\n",
      "Gazetteer: 0.925925930341\n",
      "0.925925930341\n",
      "{'adams': 1.0, 'connor': 0.7499999999999999, 'dave': 0.9999999999999998, 'john': 0.8, 'mary': 0.7499999999999999, 'smith': 0.7999999999999998, 'wick': 1.0, 'it': 0.0, 'into': 0.0, 'and': 0.0, 'match': 0.0, 'the': 0.0, 'scotsman': 0.0, 'against': 0.0, 'talked': 0.0, 'to': 0.0, 'a': 0.0, 'church': 0.0, 'magnificent': 0.0, 'is': 0.0, 'lot': 0.0, 'evan': 0.0, 'drinks': 0.0, 'erick': 0.0, 'doing': 0.0, 'whisky': 0.0, 'tennis': 0.0, 'that': 0.0, 'went': 0.0, 'won': 0.0, 'by': 0.0}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "\n",
    "gazetteer = [\n",
    "    'john smith',\n",
    "    'dave smith',\n",
    "    'mary adams',\n",
    "    'mary connor',\n",
    "    'john wick',\n",
    "    'john connor',\n",
    "]\n",
    "\n",
    "g_vocab = set([t for s in gazetteer for t in s.split()])\n",
    "\n",
    "def get_priors():\n",
    "    w = [t for g in gazetteer for t in g.split()]\n",
    "    w.sort()\n",
    "    f = {k: sum(1 for _ in g) for k, g in groupby(w)}\n",
    "    n = sum([f[key] for key in f])\n",
    "    \n",
    "    big_n = 17\n",
    "    f = {key:(f[key], round(big_n*f[key]/float(n))-f[key]) for key in f}  \n",
    "    return f\n",
    "\n",
    "def map_est(k, n, alpha, beta):\n",
    "    return (k + alpha - 1) / (n + alpha + beta - 2)\n",
    "\n",
    "sentences = [\n",
    "    ['dave', 'smith', 'went', 'to', 'the', 'church', 'and', 'talked', 'mary', 'into', 'doing', 'it'],\n",
    "    ['john', 'is', 'a', 'magnificent', 'scotsman', 'that', 'drinks', 'whisky', 'by', 'the', 'lot'],\n",
    "    ['evan', 'connor', 'won', 'the', 'tennis', 'match', 'against', 'erick', 'smith']\n",
    "]\n",
    "actual_labels = [\n",
    "    [1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [1, 1, 0, 0, 0, 0, 0, 1, 1]\n",
    "]\n",
    "\n",
    "vocab = list(set(t for s in sentences for t in s))\n",
    "vocab_size = len(vocab)\n",
    "embeddings_size = 15\n",
    "\n",
    "priors = get_priors() \n",
    "for w in vocab:\n",
    "    if not w in priors:\n",
    "        priors[w] = (0, 3)\n",
    "\n",
    "counts = {}\n",
    "for p in priors:\n",
    "    counts[p] = [0, 0]\n",
    "    \n",
    "def get_probs():\n",
    "    probs = {}\n",
    "    for p in priors:\n",
    "        k, n = counts[p]\n",
    "        alpha, beta = priors[p]\n",
    "        probs[p] = map_est(k, n, 1+alpha, 1+beta)\n",
    "    return probs\n",
    "\n",
    "probs = get_probs()\n",
    "\n",
    "def update_counts(new_counts):\n",
    "    global counts\n",
    "    for key in counts:\n",
    "        counts[key] = [\n",
    "            (4*counts[key][0] + new_counts[key][0]) / 5.0,\n",
    "            new_counts[key][1]\n",
    "        ]\n",
    "\n",
    "def get_random_labels(sentence):\n",
    "    labels = []\n",
    "    for t in sentence:        \n",
    "        p = probs[t]\n",
    "        y = np.random.choice(a=[0, 1], p=[1-p, p])\n",
    "        labels.append(y)  \n",
    "    return labels\n",
    "\n",
    "def get_labels_from_gazetteer(sentence):\n",
    "    labels = []\n",
    "    for t in sentence:\n",
    "        labels.append(1 if t in g_vocab else 0)\n",
    "    return labels\n",
    "\n",
    "words = tf.placeholder(tf.string, shape=(None,), name='words')\n",
    "label_ids = tf.placeholder(tf.int32, shape=(None,), name='label_ids')\n",
    "train_label_ids = tf.placeholder(tf.int32, shape=(None,), name='train_label_ids')\n",
    "\n",
    "labels = tf.one_hot(train_label_ids, 2)\n",
    "\n",
    "mapping_vocab = tf.constant(vocab)\n",
    "table = tf.contrib.lookup.index_table_from_tensor(mapping=mapping_vocab)\n",
    "word_ids = table.lookup(words)\n",
    "\n",
    "with tf.variable_scope('x', reuse=tf.AUTO_REUSE):\n",
    "    v = tf.get_variable('embeddings', [vocab_size, embeddings_size], tf.float32)\n",
    "    embeddings = tf.nn.embedding_lookup(v, word_ids)\n",
    "\n",
    "    output = tf.layers.dense(embeddings, 10)\n",
    "    logits = tf.layers.dense(output, 2)\n",
    "    pred_ids = tf.argmax(logits, axis=-1)\n",
    "    # pred_ids = 0*pred_ids\n",
    "    correct = tf.equal(tf.to_int32(pred_ids), label_ids)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=labels, logits=logits))\n",
    "    train_step = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "print(probs)\n",
    "with tf.Session() as sess:\n",
    "    tf.tables_initializer().run()\n",
    "    tf.initializers.global_variables().run()\n",
    "    \n",
    "    for _ in range(1000):\n",
    "        a = []\n",
    "        \n",
    "        new_counts = {}\n",
    "        for p in priors:\n",
    "            new_counts[p] = [0, 0]\n",
    "        \n",
    "        for i, s in enumerate(sentences):\n",
    "            acc, preds, _ = sess.run([accuracy, pred_ids, train_step], feed_dict={\n",
    "                words: [t for t in s],\n",
    "                label_ids: actual_labels[i],\n",
    "                # train_label_ids: get_labels_from_gazetteer(s)\n",
    "                train_label_ids: get_random_labels(s)\n",
    "            })\n",
    "            a.append(acc)\n",
    "            \n",
    "            for j, p in enumerate(preds):\n",
    "                if p == 1:\n",
    "                    new_counts[s[j]][0] += 1\n",
    "                new_counts[s[j]][1] += 1\n",
    "        update_counts(new_counts)\n",
    "        probs = get_probs()\n",
    "            \n",
    "        a = sum(a) / 3\n",
    "        \n",
    "    print('Baseline: 0.738215506077')\n",
    "    print('Gazetteer: 0.925925930341')\n",
    "    print(a)\n",
    "    # print(new_counts)    \n",
    "    # print(counts)\n",
    "    print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def factorial(n):\n",
    "    return 1 if n <= 1 else factorial(n - 1) * n\n",
    "\n",
    "def gamma_fn(x):\n",
    "    return factorial(x-1)\n",
    "    \n",
    "def beta_fn(x, y):\n",
    "    return (gamma_fn(x) * gamma_fn(y)) / gamma_fn(x+y) \n",
    "    \n",
    "def binomial_coefficient(n, k):\n",
    "    return factorial(n) / (factorial(k) * factorial(n-k))\n",
    "\n",
    "alpha = 1.3\n",
    "beta = 1.3\n",
    "n_steves = 3\n",
    "def steve_prior(x):\n",
    "    r = x ** (alpha-1) * (1-x) ** (beta-1)\n",
    "    return r / beta_fn(alpha, beta)\n",
    "\n",
    "def steve_likelihood(p_steve_is_name):                                   \n",
    "    p_steve_is_not_in_gazetteer = (1 - p_steve_is_name) ** n_steves\n",
    "    p_steve_is_in_gazetteer = 1 - p_steve_is_not_in_gazetteer\n",
    "    return p_steve_is_in_gazetteer\n",
    "    \n",
    "def steve_total(x):\n",
    "    return steve_prior(x) * steve_likelihood(x)\n",
    "                                   \n",
    "x = np.linspace(0, 1, num=101)\n",
    "y = list(map(steve_total, x))\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy\n",
    "\n",
    "$ H = - \\sum_{i=1}^N p(x_i) \\cdot log p(x_i) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n",
      "1.25677964945\n",
      "0.255853627185\n",
      "0.743220350553\n",
      "2.0000000000030003\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# There is a distribution with 5 possible values. P is the probability of each value.\n",
    "\n",
    "P1 = np.array([0.25, 0.25, 0.25, 0.25]) # Should have big entropy.\n",
    "P2 = np.array([0.05, 0.05, 0.2 , 0.7 ]) # Should have average entropy. \n",
    "P3 = np.array([0.01, 0.01, 0.01, 0.96]) # Should have small entropy.\n",
    "P4 = np.array([0.26, 0.26, 0.26, 0.22])\n",
    "\n",
    "def entropy(P):\n",
    "    return -np.sum(P * np.log2(P))\n",
    "\n",
    "def kl_divergence(P, Q):\n",
    "    return np.sum(P * np.log2(P/Q))\n",
    "\n",
    "print(entropy(P1))\n",
    "print(entropy(P2))\n",
    "print(entropy(P3))\n",
    "\n",
    "print(kl_divergence(P2,P1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
